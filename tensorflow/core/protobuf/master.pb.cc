// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/protobuf/master.proto

#define INTERNAL_SUPPRESS_PROTOBUF_FIELD_DEPRECATION
#include "tensorflow/core/protobuf/master.pb.h"

#include <algorithm>

#include <google/protobuf/stubs/common.h>
#include <google/protobuf/stubs/port.h>
#include <google/protobuf/stubs/once.h>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/wire_format_lite_inl.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)

namespace tensorflow {

namespace {

const ::google::protobuf::Descriptor* CreateSessionRequest_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  CreateSessionRequest_reflection_ = NULL;
const ::google::protobuf::Descriptor* CreateSessionResponse_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  CreateSessionResponse_reflection_ = NULL;
const ::google::protobuf::Descriptor* ExtendSessionRequest_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  ExtendSessionRequest_reflection_ = NULL;
const ::google::protobuf::Descriptor* ExtendSessionResponse_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  ExtendSessionResponse_reflection_ = NULL;
const ::google::protobuf::Descriptor* RunStepRequest_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  RunStepRequest_reflection_ = NULL;
const ::google::protobuf::Descriptor* RunStepResponse_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  RunStepResponse_reflection_ = NULL;
const ::google::protobuf::Descriptor* CloseSessionRequest_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  CloseSessionRequest_reflection_ = NULL;
const ::google::protobuf::Descriptor* CloseSessionResponse_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  CloseSessionResponse_reflection_ = NULL;
const ::google::protobuf::Descriptor* ResetRequest_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  ResetRequest_reflection_ = NULL;
const ::google::protobuf::Descriptor* ResetResponse_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  ResetResponse_reflection_ = NULL;
const ::google::protobuf::Descriptor* ListDevicesRequest_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  ListDevicesRequest_reflection_ = NULL;
const ::google::protobuf::Descriptor* ListDevicesResponse_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  ListDevicesResponse_reflection_ = NULL;

}  // namespace


void protobuf_AssignDesc_tensorflow_2fcore_2fprotobuf_2fmaster_2eproto() {
  protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fmaster_2eproto();
  const ::google::protobuf::FileDescriptor* file =
    ::google::protobuf::DescriptorPool::generated_pool()->FindFileByName(
      "tensorflow/core/protobuf/master.proto");
  GOOGLE_CHECK(file != NULL);
  CreateSessionRequest_descriptor_ = file->message_type(0);
  static const int CreateSessionRequest_offsets_[2] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CreateSessionRequest, graph_def_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CreateSessionRequest, config_),
  };
  CreateSessionRequest_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      CreateSessionRequest_descriptor_,
      CreateSessionRequest::default_instance_,
      CreateSessionRequest_offsets_,
      -1,
      -1,
      -1,
      sizeof(CreateSessionRequest),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CreateSessionRequest, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CreateSessionRequest, _is_default_instance_));
  CreateSessionResponse_descriptor_ = file->message_type(1);
  static const int CreateSessionResponse_offsets_[2] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CreateSessionResponse, session_handle_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CreateSessionResponse, graph_version_),
  };
  CreateSessionResponse_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      CreateSessionResponse_descriptor_,
      CreateSessionResponse::default_instance_,
      CreateSessionResponse_offsets_,
      -1,
      -1,
      -1,
      sizeof(CreateSessionResponse),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CreateSessionResponse, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CreateSessionResponse, _is_default_instance_));
  ExtendSessionRequest_descriptor_ = file->message_type(2);
  static const int ExtendSessionRequest_offsets_[3] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ExtendSessionRequest, session_handle_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ExtendSessionRequest, graph_def_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ExtendSessionRequest, current_graph_version_),
  };
  ExtendSessionRequest_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      ExtendSessionRequest_descriptor_,
      ExtendSessionRequest::default_instance_,
      ExtendSessionRequest_offsets_,
      -1,
      -1,
      -1,
      sizeof(ExtendSessionRequest),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ExtendSessionRequest, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ExtendSessionRequest, _is_default_instance_));
  ExtendSessionResponse_descriptor_ = file->message_type(3);
  static const int ExtendSessionResponse_offsets_[1] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ExtendSessionResponse, new_graph_version_),
  };
  ExtendSessionResponse_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      ExtendSessionResponse_descriptor_,
      ExtendSessionResponse::default_instance_,
      ExtendSessionResponse_offsets_,
      -1,
      -1,
      -1,
      sizeof(ExtendSessionResponse),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ExtendSessionResponse, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ExtendSessionResponse, _is_default_instance_));
  RunStepRequest_descriptor_ = file->message_type(4);
  static const int RunStepRequest_offsets_[5] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunStepRequest, session_handle_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunStepRequest, feed_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunStepRequest, fetch_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunStepRequest, target_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunStepRequest, options_),
  };
  RunStepRequest_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      RunStepRequest_descriptor_,
      RunStepRequest::default_instance_,
      RunStepRequest_offsets_,
      -1,
      -1,
      -1,
      sizeof(RunStepRequest),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunStepRequest, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunStepRequest, _is_default_instance_));
  RunStepResponse_descriptor_ = file->message_type(5);
  static const int RunStepResponse_offsets_[2] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunStepResponse, tensor_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunStepResponse, metadata_),
  };
  RunStepResponse_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      RunStepResponse_descriptor_,
      RunStepResponse::default_instance_,
      RunStepResponse_offsets_,
      -1,
      -1,
      -1,
      sizeof(RunStepResponse),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunStepResponse, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunStepResponse, _is_default_instance_));
  CloseSessionRequest_descriptor_ = file->message_type(6);
  static const int CloseSessionRequest_offsets_[1] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CloseSessionRequest, session_handle_),
  };
  CloseSessionRequest_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      CloseSessionRequest_descriptor_,
      CloseSessionRequest::default_instance_,
      CloseSessionRequest_offsets_,
      -1,
      -1,
      -1,
      sizeof(CloseSessionRequest),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CloseSessionRequest, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CloseSessionRequest, _is_default_instance_));
  CloseSessionResponse_descriptor_ = file->message_type(7);
  static const int CloseSessionResponse_offsets_[1] = {
  };
  CloseSessionResponse_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      CloseSessionResponse_descriptor_,
      CloseSessionResponse::default_instance_,
      CloseSessionResponse_offsets_,
      -1,
      -1,
      -1,
      sizeof(CloseSessionResponse),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CloseSessionResponse, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CloseSessionResponse, _is_default_instance_));
  ResetRequest_descriptor_ = file->message_type(8);
  static const int ResetRequest_offsets_[1] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ResetRequest, container_),
  };
  ResetRequest_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      ResetRequest_descriptor_,
      ResetRequest::default_instance_,
      ResetRequest_offsets_,
      -1,
      -1,
      -1,
      sizeof(ResetRequest),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ResetRequest, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ResetRequest, _is_default_instance_));
  ResetResponse_descriptor_ = file->message_type(9);
  static const int ResetResponse_offsets_[1] = {
  };
  ResetResponse_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      ResetResponse_descriptor_,
      ResetResponse::default_instance_,
      ResetResponse_offsets_,
      -1,
      -1,
      -1,
      sizeof(ResetResponse),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ResetResponse, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ResetResponse, _is_default_instance_));
  ListDevicesRequest_descriptor_ = file->message_type(10);
  static const int ListDevicesRequest_offsets_[1] = {
  };
  ListDevicesRequest_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      ListDevicesRequest_descriptor_,
      ListDevicesRequest::default_instance_,
      ListDevicesRequest_offsets_,
      -1,
      -1,
      -1,
      sizeof(ListDevicesRequest),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ListDevicesRequest, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ListDevicesRequest, _is_default_instance_));
  ListDevicesResponse_descriptor_ = file->message_type(11);
  static const int ListDevicesResponse_offsets_[2] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ListDevicesResponse, local_device_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ListDevicesResponse, remote_device_),
  };
  ListDevicesResponse_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      ListDevicesResponse_descriptor_,
      ListDevicesResponse::default_instance_,
      ListDevicesResponse_offsets_,
      -1,
      -1,
      -1,
      sizeof(ListDevicesResponse),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ListDevicesResponse, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ListDevicesResponse, _is_default_instance_));
}

namespace {

GOOGLE_PROTOBUF_DECLARE_ONCE(protobuf_AssignDescriptors_once_);
inline void protobuf_AssignDescriptorsOnce() {
  ::google::protobuf::GoogleOnceInit(&protobuf_AssignDescriptors_once_,
                 &protobuf_AssignDesc_tensorflow_2fcore_2fprotobuf_2fmaster_2eproto);
}

void protobuf_RegisterTypes(const ::std::string&) {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      CreateSessionRequest_descriptor_, &CreateSessionRequest::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      CreateSessionResponse_descriptor_, &CreateSessionResponse::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      ExtendSessionRequest_descriptor_, &ExtendSessionRequest::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      ExtendSessionResponse_descriptor_, &ExtendSessionResponse::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      RunStepRequest_descriptor_, &RunStepRequest::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      RunStepResponse_descriptor_, &RunStepResponse::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      CloseSessionRequest_descriptor_, &CloseSessionRequest::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      CloseSessionResponse_descriptor_, &CloseSessionResponse::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      ResetRequest_descriptor_, &ResetRequest::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      ResetResponse_descriptor_, &ResetResponse::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      ListDevicesRequest_descriptor_, &ListDevicesRequest::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      ListDevicesResponse_descriptor_, &ListDevicesResponse::default_instance());
}

}  // namespace

void protobuf_ShutdownFile_tensorflow_2fcore_2fprotobuf_2fmaster_2eproto() {
  delete CreateSessionRequest::default_instance_;
  delete CreateSessionRequest_reflection_;
  delete CreateSessionResponse::default_instance_;
  delete CreateSessionResponse_reflection_;
  delete ExtendSessionRequest::default_instance_;
  delete ExtendSessionRequest_reflection_;
  delete ExtendSessionResponse::default_instance_;
  delete ExtendSessionResponse_reflection_;
  delete RunStepRequest::default_instance_;
  delete RunStepRequest_reflection_;
  delete RunStepResponse::default_instance_;
  delete RunStepResponse_reflection_;
  delete CloseSessionRequest::default_instance_;
  delete CloseSessionRequest_reflection_;
  delete CloseSessionResponse::default_instance_;
  delete CloseSessionResponse_reflection_;
  delete ResetRequest::default_instance_;
  delete ResetRequest_reflection_;
  delete ResetResponse::default_instance_;
  delete ResetResponse_reflection_;
  delete ListDevicesRequest::default_instance_;
  delete ListDevicesRequest_reflection_;
  delete ListDevicesResponse::default_instance_;
  delete ListDevicesResponse_reflection_;
}

void protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fmaster_2eproto() {
  static bool already_here = false;
  if (already_here) return;
  already_here = true;
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  ::tensorflow::protobuf_AddDesc_tensorflow_2fcore_2fframework_2fdevice_5fattributes_2eproto();
  ::tensorflow::protobuf_AddDesc_tensorflow_2fcore_2fframework_2fgraph_2eproto();
  ::tensorflow::protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto();
  ::tensorflow::protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fnamed_5ftensor_2eproto();
  ::google::protobuf::DescriptorPool::InternalAddGeneratedFile(
    "\n%tensorflow/core/protobuf/master.proto\022"
    "\ntensorflow\0321tensorflow/core/framework/d"
    "evice_attributes.proto\032%tensorflow/core/"
    "framework/graph.proto\032%tensorflow/core/p"
    "rotobuf/config.proto\032+tensorflow/core/pr"
    "otobuf/named_tensor.proto\"h\n\024CreateSessi"
    "onRequest\022\'\n\tgraph_def\030\001 \001(\0132\024.tensorflo"
    "w.GraphDef\022\'\n\006config\030\002 \001(\0132\027.tensorflow."
    "ConfigProto\"F\n\025CreateSessionResponse\022\026\n\016"
    "session_handle\030\001 \001(\t\022\025\n\rgraph_version\030\002 "
    "\001(\003\"v\n\024ExtendSessionRequest\022\026\n\016session_h"
    "andle\030\001 \001(\t\022\'\n\tgraph_def\030\002 \001(\0132\024.tensorf"
    "low.GraphDef\022\035\n\025current_graph_version\030\003 "
    "\001(\003\"2\n\025ExtendSessionResponse\022\031\n\021new_grap"
    "h_version\030\004 \001(\003\"\234\001\n\016RunStepRequest\022\026\n\016se"
    "ssion_handle\030\001 \001(\t\022*\n\004feed\030\002 \003(\0132\034.tenso"
    "rflow.NamedTensorProto\022\r\n\005fetch\030\003 \003(\t\022\016\n"
    "\006target\030\004 \003(\t\022\'\n\007options\030\005 \001(\0132\026.tensorf"
    "low.RunOptions\"j\n\017RunStepResponse\022,\n\006ten"
    "sor\030\001 \003(\0132\034.tensorflow.NamedTensorProto\022"
    ")\n\010metadata\030\002 \001(\0132\027.tensorflow.RunMetada"
    "ta\"-\n\023CloseSessionRequest\022\026\n\016session_han"
    "dle\030\001 \001(\t\"\026\n\024CloseSessionResponse\"!\n\014Res"
    "etRequest\022\021\n\tcontainer\030\001 \003(\t\"\017\n\rResetRes"
    "ponse\"\024\n\022ListDevicesRequest\"~\n\023ListDevic"
    "esResponse\0222\n\014local_device\030\001 \003(\0132\034.tenso"
    "rflow.DeviceAttributes\0223\n\rremote_device\030"
    "\002 \003(\0132\034.tensorflow.DeviceAttributesB8\n\032o"
    "rg.tensorflow.distruntimeB\030DistributedRu"
    "ntimeProtosP\001b\006proto3", 1181);
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedFile(
    "tensorflow/core/protobuf/master.proto", &protobuf_RegisterTypes);
  CreateSessionRequest::default_instance_ = new CreateSessionRequest();
  CreateSessionResponse::default_instance_ = new CreateSessionResponse();
  ExtendSessionRequest::default_instance_ = new ExtendSessionRequest();
  ExtendSessionResponse::default_instance_ = new ExtendSessionResponse();
  RunStepRequest::default_instance_ = new RunStepRequest();
  RunStepResponse::default_instance_ = new RunStepResponse();
  CloseSessionRequest::default_instance_ = new CloseSessionRequest();
  CloseSessionResponse::default_instance_ = new CloseSessionResponse();
  ResetRequest::default_instance_ = new ResetRequest();
  ResetResponse::default_instance_ = new ResetResponse();
  ListDevicesRequest::default_instance_ = new ListDevicesRequest();
  ListDevicesResponse::default_instance_ = new ListDevicesResponse();
  CreateSessionRequest::default_instance_->InitAsDefaultInstance();
  CreateSessionResponse::default_instance_->InitAsDefaultInstance();
  ExtendSessionRequest::default_instance_->InitAsDefaultInstance();
  ExtendSessionResponse::default_instance_->InitAsDefaultInstance();
  RunStepRequest::default_instance_->InitAsDefaultInstance();
  RunStepResponse::default_instance_->InitAsDefaultInstance();
  CloseSessionRequest::default_instance_->InitAsDefaultInstance();
  CloseSessionResponse::default_instance_->InitAsDefaultInstance();
  ResetRequest::default_instance_->InitAsDefaultInstance();
  ResetResponse::default_instance_->InitAsDefaultInstance();
  ListDevicesRequest::default_instance_->InitAsDefaultInstance();
  ListDevicesResponse::default_instance_->InitAsDefaultInstance();
  ::google::protobuf::internal::OnShutdown(&protobuf_ShutdownFile_tensorflow_2fcore_2fprotobuf_2fmaster_2eproto);
}

// Force AddDescriptors() to be called at static initialization time.
struct StaticDescriptorInitializer_tensorflow_2fcore_2fprotobuf_2fmaster_2eproto {
  StaticDescriptorInitializer_tensorflow_2fcore_2fprotobuf_2fmaster_2eproto() {
    protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fmaster_2eproto();
  }
} static_descriptor_initializer_tensorflow_2fcore_2fprotobuf_2fmaster_2eproto_;

namespace {

static void MergeFromFail(int line) GOOGLE_ATTRIBUTE_COLD;
static void MergeFromFail(int line) {
  GOOGLE_CHECK(false) << __FILE__ << ":" << line;
}

}  // namespace


// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int CreateSessionRequest::kGraphDefFieldNumber;
const int CreateSessionRequest::kConfigFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

CreateSessionRequest::CreateSessionRequest()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.CreateSessionRequest)
}

void CreateSessionRequest::InitAsDefaultInstance() {
  _is_default_instance_ = true;
  graph_def_ = const_cast< ::tensorflow::GraphDef*>(&::tensorflow::GraphDef::default_instance());
  config_ = const_cast< ::tensorflow::ConfigProto*>(&::tensorflow::ConfigProto::default_instance());
}

CreateSessionRequest::CreateSessionRequest(const CreateSessionRequest& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.CreateSessionRequest)
}

void CreateSessionRequest::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  graph_def_ = NULL;
  config_ = NULL;
}

CreateSessionRequest::~CreateSessionRequest() {
  // @@protoc_insertion_point(destructor:tensorflow.CreateSessionRequest)
  SharedDtor();
}

void CreateSessionRequest::SharedDtor() {
  if (this != default_instance_) {
    delete graph_def_;
    delete config_;
  }
}

void CreateSessionRequest::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* CreateSessionRequest::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return CreateSessionRequest_descriptor_;
}

const CreateSessionRequest& CreateSessionRequest::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fmaster_2eproto();
  return *default_instance_;
}

CreateSessionRequest* CreateSessionRequest::default_instance_ = NULL;

CreateSessionRequest* CreateSessionRequest::New(::google::protobuf::Arena* arena) const {
  CreateSessionRequest* n = new CreateSessionRequest;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void CreateSessionRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.CreateSessionRequest)
  if (GetArenaNoVirtual() == NULL && graph_def_ != NULL) delete graph_def_;
  graph_def_ = NULL;
  if (GetArenaNoVirtual() == NULL && config_ != NULL) delete config_;
  config_ = NULL;
}

bool CreateSessionRequest::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.CreateSessionRequest)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional .tensorflow.GraphDef graph_def = 1;
      case 1: {
        if (tag == 10) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_graph_def()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_config;
        break;
      }

      // optional .tensorflow.ConfigProto config = 2;
      case 2: {
        if (tag == 18) {
         parse_config:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_config()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.CreateSessionRequest)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.CreateSessionRequest)
  return false;
#undef DO_
}

void CreateSessionRequest::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.CreateSessionRequest)
  // optional .tensorflow.GraphDef graph_def = 1;
  if (this->has_graph_def()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, *this->graph_def_, output);
  }

  // optional .tensorflow.ConfigProto config = 2;
  if (this->has_config()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, *this->config_, output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.CreateSessionRequest)
}

::google::protobuf::uint8* CreateSessionRequest::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.CreateSessionRequest)
  // optional .tensorflow.GraphDef graph_def = 1;
  if (this->has_graph_def()) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        1, *this->graph_def_, target);
  }

  // optional .tensorflow.ConfigProto config = 2;
  if (this->has_config()) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        2, *this->config_, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.CreateSessionRequest)
  return target;
}

int CreateSessionRequest::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.CreateSessionRequest)
  int total_size = 0;

  // optional .tensorflow.GraphDef graph_def = 1;
  if (this->has_graph_def()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->graph_def_);
  }

  // optional .tensorflow.ConfigProto config = 2;
  if (this->has_config()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->config_);
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void CreateSessionRequest::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.CreateSessionRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const CreateSessionRequest* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const CreateSessionRequest>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.CreateSessionRequest)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.CreateSessionRequest)
    MergeFrom(*source);
  }
}

void CreateSessionRequest::MergeFrom(const CreateSessionRequest& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.CreateSessionRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  if (from.has_graph_def()) {
    mutable_graph_def()->::tensorflow::GraphDef::MergeFrom(from.graph_def());
  }
  if (from.has_config()) {
    mutable_config()->::tensorflow::ConfigProto::MergeFrom(from.config());
  }
}

void CreateSessionRequest::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.CreateSessionRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void CreateSessionRequest::CopyFrom(const CreateSessionRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.CreateSessionRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool CreateSessionRequest::IsInitialized() const {

  return true;
}

void CreateSessionRequest::Swap(CreateSessionRequest* other) {
  if (other == this) return;
  InternalSwap(other);
}
void CreateSessionRequest::InternalSwap(CreateSessionRequest* other) {
  std::swap(graph_def_, other->graph_def_);
  std::swap(config_, other->config_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata CreateSessionRequest::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = CreateSessionRequest_descriptor_;
  metadata.reflection = CreateSessionRequest_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// CreateSessionRequest

// optional .tensorflow.GraphDef graph_def = 1;
bool CreateSessionRequest::has_graph_def() const {
  return !_is_default_instance_ && graph_def_ != NULL;
}
void CreateSessionRequest::clear_graph_def() {
  if (GetArenaNoVirtual() == NULL && graph_def_ != NULL) delete graph_def_;
  graph_def_ = NULL;
}
const ::tensorflow::GraphDef& CreateSessionRequest::graph_def() const {
  // @@protoc_insertion_point(field_get:tensorflow.CreateSessionRequest.graph_def)
  return graph_def_ != NULL ? *graph_def_ : *default_instance_->graph_def_;
}
::tensorflow::GraphDef* CreateSessionRequest::mutable_graph_def() {
  
  if (graph_def_ == NULL) {
    graph_def_ = new ::tensorflow::GraphDef;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.CreateSessionRequest.graph_def)
  return graph_def_;
}
::tensorflow::GraphDef* CreateSessionRequest::release_graph_def() {
  // @@protoc_insertion_point(field_release:tensorflow.CreateSessionRequest.graph_def)
  
  ::tensorflow::GraphDef* temp = graph_def_;
  graph_def_ = NULL;
  return temp;
}
void CreateSessionRequest::set_allocated_graph_def(::tensorflow::GraphDef* graph_def) {
  delete graph_def_;
  graph_def_ = graph_def;
  if (graph_def) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.CreateSessionRequest.graph_def)
}

// optional .tensorflow.ConfigProto config = 2;
bool CreateSessionRequest::has_config() const {
  return !_is_default_instance_ && config_ != NULL;
}
void CreateSessionRequest::clear_config() {
  if (GetArenaNoVirtual() == NULL && config_ != NULL) delete config_;
  config_ = NULL;
}
const ::tensorflow::ConfigProto& CreateSessionRequest::config() const {
  // @@protoc_insertion_point(field_get:tensorflow.CreateSessionRequest.config)
  return config_ != NULL ? *config_ : *default_instance_->config_;
}
::tensorflow::ConfigProto* CreateSessionRequest::mutable_config() {
  
  if (config_ == NULL) {
    config_ = new ::tensorflow::ConfigProto;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.CreateSessionRequest.config)
  return config_;
}
::tensorflow::ConfigProto* CreateSessionRequest::release_config() {
  // @@protoc_insertion_point(field_release:tensorflow.CreateSessionRequest.config)
  
  ::tensorflow::ConfigProto* temp = config_;
  config_ = NULL;
  return temp;
}
void CreateSessionRequest::set_allocated_config(::tensorflow::ConfigProto* config) {
  delete config_;
  config_ = config;
  if (config) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.CreateSessionRequest.config)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int CreateSessionResponse::kSessionHandleFieldNumber;
const int CreateSessionResponse::kGraphVersionFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

CreateSessionResponse::CreateSessionResponse()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.CreateSessionResponse)
}

void CreateSessionResponse::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

CreateSessionResponse::CreateSessionResponse(const CreateSessionResponse& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.CreateSessionResponse)
}

void CreateSessionResponse::SharedCtor() {
    _is_default_instance_ = false;
  ::google::protobuf::internal::GetEmptyString();
  _cached_size_ = 0;
  session_handle_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  graph_version_ = GOOGLE_LONGLONG(0);
}

CreateSessionResponse::~CreateSessionResponse() {
  // @@protoc_insertion_point(destructor:tensorflow.CreateSessionResponse)
  SharedDtor();
}

void CreateSessionResponse::SharedDtor() {
  session_handle_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (this != default_instance_) {
  }
}

void CreateSessionResponse::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* CreateSessionResponse::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return CreateSessionResponse_descriptor_;
}

const CreateSessionResponse& CreateSessionResponse::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fmaster_2eproto();
  return *default_instance_;
}

CreateSessionResponse* CreateSessionResponse::default_instance_ = NULL;

CreateSessionResponse* CreateSessionResponse::New(::google::protobuf::Arena* arena) const {
  CreateSessionResponse* n = new CreateSessionResponse;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void CreateSessionResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.CreateSessionResponse)
  session_handle_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  graph_version_ = GOOGLE_LONGLONG(0);
}

bool CreateSessionResponse::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.CreateSessionResponse)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional string session_handle = 1;
      case 1: {
        if (tag == 10) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_session_handle()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->session_handle().data(), this->session_handle().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.CreateSessionResponse.session_handle"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(16)) goto parse_graph_version;
        break;
      }

      // optional int64 graph_version = 2;
      case 2: {
        if (tag == 16) {
         parse_graph_version:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 input, &graph_version_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.CreateSessionResponse)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.CreateSessionResponse)
  return false;
#undef DO_
}

void CreateSessionResponse::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.CreateSessionResponse)
  // optional string session_handle = 1;
  if (this->session_handle().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->session_handle().data(), this->session_handle().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.CreateSessionResponse.session_handle");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      1, this->session_handle(), output);
  }

  // optional int64 graph_version = 2;
  if (this->graph_version() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt64(2, this->graph_version(), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.CreateSessionResponse)
}

::google::protobuf::uint8* CreateSessionResponse::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.CreateSessionResponse)
  // optional string session_handle = 1;
  if (this->session_handle().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->session_handle().data(), this->session_handle().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.CreateSessionResponse.session_handle");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        1, this->session_handle(), target);
  }

  // optional int64 graph_version = 2;
  if (this->graph_version() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt64ToArray(2, this->graph_version(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.CreateSessionResponse)
  return target;
}

int CreateSessionResponse::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.CreateSessionResponse)
  int total_size = 0;

  // optional string session_handle = 1;
  if (this->session_handle().size() > 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->session_handle());
  }

  // optional int64 graph_version = 2;
  if (this->graph_version() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int64Size(
        this->graph_version());
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void CreateSessionResponse::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.CreateSessionResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const CreateSessionResponse* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const CreateSessionResponse>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.CreateSessionResponse)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.CreateSessionResponse)
    MergeFrom(*source);
  }
}

void CreateSessionResponse::MergeFrom(const CreateSessionResponse& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.CreateSessionResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  if (from.session_handle().size() > 0) {

    session_handle_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.session_handle_);
  }
  if (from.graph_version() != 0) {
    set_graph_version(from.graph_version());
  }
}

void CreateSessionResponse::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.CreateSessionResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void CreateSessionResponse::CopyFrom(const CreateSessionResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.CreateSessionResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool CreateSessionResponse::IsInitialized() const {

  return true;
}

void CreateSessionResponse::Swap(CreateSessionResponse* other) {
  if (other == this) return;
  InternalSwap(other);
}
void CreateSessionResponse::InternalSwap(CreateSessionResponse* other) {
  session_handle_.Swap(&other->session_handle_);
  std::swap(graph_version_, other->graph_version_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata CreateSessionResponse::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = CreateSessionResponse_descriptor_;
  metadata.reflection = CreateSessionResponse_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// CreateSessionResponse

// optional string session_handle = 1;
void CreateSessionResponse::clear_session_handle() {
  session_handle_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 const ::std::string& CreateSessionResponse::session_handle() const {
  // @@protoc_insertion_point(field_get:tensorflow.CreateSessionResponse.session_handle)
  return session_handle_.GetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void CreateSessionResponse::set_session_handle(const ::std::string& value) {
  
  session_handle_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:tensorflow.CreateSessionResponse.session_handle)
}
 void CreateSessionResponse::set_session_handle(const char* value) {
  
  session_handle_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:tensorflow.CreateSessionResponse.session_handle)
}
 void CreateSessionResponse::set_session_handle(const char* value, size_t size) {
  
  session_handle_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:tensorflow.CreateSessionResponse.session_handle)
}
 ::std::string* CreateSessionResponse::mutable_session_handle() {
  
  // @@protoc_insertion_point(field_mutable:tensorflow.CreateSessionResponse.session_handle)
  return session_handle_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 ::std::string* CreateSessionResponse::release_session_handle() {
  // @@protoc_insertion_point(field_release:tensorflow.CreateSessionResponse.session_handle)
  
  return session_handle_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void CreateSessionResponse::set_allocated_session_handle(::std::string* session_handle) {
  if (session_handle != NULL) {
    
  } else {
    
  }
  session_handle_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), session_handle);
  // @@protoc_insertion_point(field_set_allocated:tensorflow.CreateSessionResponse.session_handle)
}

// optional int64 graph_version = 2;
void CreateSessionResponse::clear_graph_version() {
  graph_version_ = GOOGLE_LONGLONG(0);
}
 ::google::protobuf::int64 CreateSessionResponse::graph_version() const {
  // @@protoc_insertion_point(field_get:tensorflow.CreateSessionResponse.graph_version)
  return graph_version_;
}
 void CreateSessionResponse::set_graph_version(::google::protobuf::int64 value) {
  
  graph_version_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.CreateSessionResponse.graph_version)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int ExtendSessionRequest::kSessionHandleFieldNumber;
const int ExtendSessionRequest::kGraphDefFieldNumber;
const int ExtendSessionRequest::kCurrentGraphVersionFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

ExtendSessionRequest::ExtendSessionRequest()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.ExtendSessionRequest)
}

void ExtendSessionRequest::InitAsDefaultInstance() {
  _is_default_instance_ = true;
  graph_def_ = const_cast< ::tensorflow::GraphDef*>(&::tensorflow::GraphDef::default_instance());
}

ExtendSessionRequest::ExtendSessionRequest(const ExtendSessionRequest& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.ExtendSessionRequest)
}

void ExtendSessionRequest::SharedCtor() {
    _is_default_instance_ = false;
  ::google::protobuf::internal::GetEmptyString();
  _cached_size_ = 0;
  session_handle_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  graph_def_ = NULL;
  current_graph_version_ = GOOGLE_LONGLONG(0);
}

ExtendSessionRequest::~ExtendSessionRequest() {
  // @@protoc_insertion_point(destructor:tensorflow.ExtendSessionRequest)
  SharedDtor();
}

void ExtendSessionRequest::SharedDtor() {
  session_handle_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (this != default_instance_) {
    delete graph_def_;
  }
}

void ExtendSessionRequest::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* ExtendSessionRequest::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return ExtendSessionRequest_descriptor_;
}

const ExtendSessionRequest& ExtendSessionRequest::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fmaster_2eproto();
  return *default_instance_;
}

ExtendSessionRequest* ExtendSessionRequest::default_instance_ = NULL;

ExtendSessionRequest* ExtendSessionRequest::New(::google::protobuf::Arena* arena) const {
  ExtendSessionRequest* n = new ExtendSessionRequest;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void ExtendSessionRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.ExtendSessionRequest)
  session_handle_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (GetArenaNoVirtual() == NULL && graph_def_ != NULL) delete graph_def_;
  graph_def_ = NULL;
  current_graph_version_ = GOOGLE_LONGLONG(0);
}

bool ExtendSessionRequest::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.ExtendSessionRequest)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional string session_handle = 1;
      case 1: {
        if (tag == 10) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_session_handle()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->session_handle().data(), this->session_handle().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.ExtendSessionRequest.session_handle"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_graph_def;
        break;
      }

      // optional .tensorflow.GraphDef graph_def = 2;
      case 2: {
        if (tag == 18) {
         parse_graph_def:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_graph_def()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(24)) goto parse_current_graph_version;
        break;
      }

      // optional int64 current_graph_version = 3;
      case 3: {
        if (tag == 24) {
         parse_current_graph_version:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 input, &current_graph_version_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.ExtendSessionRequest)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.ExtendSessionRequest)
  return false;
#undef DO_
}

void ExtendSessionRequest::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.ExtendSessionRequest)
  // optional string session_handle = 1;
  if (this->session_handle().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->session_handle().data(), this->session_handle().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.ExtendSessionRequest.session_handle");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      1, this->session_handle(), output);
  }

  // optional .tensorflow.GraphDef graph_def = 2;
  if (this->has_graph_def()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, *this->graph_def_, output);
  }

  // optional int64 current_graph_version = 3;
  if (this->current_graph_version() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt64(3, this->current_graph_version(), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.ExtendSessionRequest)
}

::google::protobuf::uint8* ExtendSessionRequest::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.ExtendSessionRequest)
  // optional string session_handle = 1;
  if (this->session_handle().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->session_handle().data(), this->session_handle().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.ExtendSessionRequest.session_handle");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        1, this->session_handle(), target);
  }

  // optional .tensorflow.GraphDef graph_def = 2;
  if (this->has_graph_def()) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        2, *this->graph_def_, target);
  }

  // optional int64 current_graph_version = 3;
  if (this->current_graph_version() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt64ToArray(3, this->current_graph_version(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.ExtendSessionRequest)
  return target;
}

int ExtendSessionRequest::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.ExtendSessionRequest)
  int total_size = 0;

  // optional string session_handle = 1;
  if (this->session_handle().size() > 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->session_handle());
  }

  // optional .tensorflow.GraphDef graph_def = 2;
  if (this->has_graph_def()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->graph_def_);
  }

  // optional int64 current_graph_version = 3;
  if (this->current_graph_version() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int64Size(
        this->current_graph_version());
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void ExtendSessionRequest::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.ExtendSessionRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const ExtendSessionRequest* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const ExtendSessionRequest>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.ExtendSessionRequest)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.ExtendSessionRequest)
    MergeFrom(*source);
  }
}

void ExtendSessionRequest::MergeFrom(const ExtendSessionRequest& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.ExtendSessionRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  if (from.session_handle().size() > 0) {

    session_handle_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.session_handle_);
  }
  if (from.has_graph_def()) {
    mutable_graph_def()->::tensorflow::GraphDef::MergeFrom(from.graph_def());
  }
  if (from.current_graph_version() != 0) {
    set_current_graph_version(from.current_graph_version());
  }
}

void ExtendSessionRequest::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.ExtendSessionRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void ExtendSessionRequest::CopyFrom(const ExtendSessionRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.ExtendSessionRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ExtendSessionRequest::IsInitialized() const {

  return true;
}

void ExtendSessionRequest::Swap(ExtendSessionRequest* other) {
  if (other == this) return;
  InternalSwap(other);
}
void ExtendSessionRequest::InternalSwap(ExtendSessionRequest* other) {
  session_handle_.Swap(&other->session_handle_);
  std::swap(graph_def_, other->graph_def_);
  std::swap(current_graph_version_, other->current_graph_version_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata ExtendSessionRequest::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = ExtendSessionRequest_descriptor_;
  metadata.reflection = ExtendSessionRequest_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// ExtendSessionRequest

// optional string session_handle = 1;
void ExtendSessionRequest::clear_session_handle() {
  session_handle_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 const ::std::string& ExtendSessionRequest::session_handle() const {
  // @@protoc_insertion_point(field_get:tensorflow.ExtendSessionRequest.session_handle)
  return session_handle_.GetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void ExtendSessionRequest::set_session_handle(const ::std::string& value) {
  
  session_handle_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:tensorflow.ExtendSessionRequest.session_handle)
}
 void ExtendSessionRequest::set_session_handle(const char* value) {
  
  session_handle_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:tensorflow.ExtendSessionRequest.session_handle)
}
 void ExtendSessionRequest::set_session_handle(const char* value, size_t size) {
  
  session_handle_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:tensorflow.ExtendSessionRequest.session_handle)
}
 ::std::string* ExtendSessionRequest::mutable_session_handle() {
  
  // @@protoc_insertion_point(field_mutable:tensorflow.ExtendSessionRequest.session_handle)
  return session_handle_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 ::std::string* ExtendSessionRequest::release_session_handle() {
  // @@protoc_insertion_point(field_release:tensorflow.ExtendSessionRequest.session_handle)
  
  return session_handle_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void ExtendSessionRequest::set_allocated_session_handle(::std::string* session_handle) {
  if (session_handle != NULL) {
    
  } else {
    
  }
  session_handle_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), session_handle);
  // @@protoc_insertion_point(field_set_allocated:tensorflow.ExtendSessionRequest.session_handle)
}

// optional .tensorflow.GraphDef graph_def = 2;
bool ExtendSessionRequest::has_graph_def() const {
  return !_is_default_instance_ && graph_def_ != NULL;
}
void ExtendSessionRequest::clear_graph_def() {
  if (GetArenaNoVirtual() == NULL && graph_def_ != NULL) delete graph_def_;
  graph_def_ = NULL;
}
const ::tensorflow::GraphDef& ExtendSessionRequest::graph_def() const {
  // @@protoc_insertion_point(field_get:tensorflow.ExtendSessionRequest.graph_def)
  return graph_def_ != NULL ? *graph_def_ : *default_instance_->graph_def_;
}
::tensorflow::GraphDef* ExtendSessionRequest::mutable_graph_def() {
  
  if (graph_def_ == NULL) {
    graph_def_ = new ::tensorflow::GraphDef;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.ExtendSessionRequest.graph_def)
  return graph_def_;
}
::tensorflow::GraphDef* ExtendSessionRequest::release_graph_def() {
  // @@protoc_insertion_point(field_release:tensorflow.ExtendSessionRequest.graph_def)
  
  ::tensorflow::GraphDef* temp = graph_def_;
  graph_def_ = NULL;
  return temp;
}
void ExtendSessionRequest::set_allocated_graph_def(::tensorflow::GraphDef* graph_def) {
  delete graph_def_;
  graph_def_ = graph_def;
  if (graph_def) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.ExtendSessionRequest.graph_def)
}

// optional int64 current_graph_version = 3;
void ExtendSessionRequest::clear_current_graph_version() {
  current_graph_version_ = GOOGLE_LONGLONG(0);
}
 ::google::protobuf::int64 ExtendSessionRequest::current_graph_version() const {
  // @@protoc_insertion_point(field_get:tensorflow.ExtendSessionRequest.current_graph_version)
  return current_graph_version_;
}
 void ExtendSessionRequest::set_current_graph_version(::google::protobuf::int64 value) {
  
  current_graph_version_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.ExtendSessionRequest.current_graph_version)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int ExtendSessionResponse::kNewGraphVersionFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

ExtendSessionResponse::ExtendSessionResponse()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.ExtendSessionResponse)
}

void ExtendSessionResponse::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

ExtendSessionResponse::ExtendSessionResponse(const ExtendSessionResponse& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.ExtendSessionResponse)
}

void ExtendSessionResponse::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  new_graph_version_ = GOOGLE_LONGLONG(0);
}

ExtendSessionResponse::~ExtendSessionResponse() {
  // @@protoc_insertion_point(destructor:tensorflow.ExtendSessionResponse)
  SharedDtor();
}

void ExtendSessionResponse::SharedDtor() {
  if (this != default_instance_) {
  }
}

void ExtendSessionResponse::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* ExtendSessionResponse::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return ExtendSessionResponse_descriptor_;
}

const ExtendSessionResponse& ExtendSessionResponse::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fmaster_2eproto();
  return *default_instance_;
}

ExtendSessionResponse* ExtendSessionResponse::default_instance_ = NULL;

ExtendSessionResponse* ExtendSessionResponse::New(::google::protobuf::Arena* arena) const {
  ExtendSessionResponse* n = new ExtendSessionResponse;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void ExtendSessionResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.ExtendSessionResponse)
  new_graph_version_ = GOOGLE_LONGLONG(0);
}

bool ExtendSessionResponse::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.ExtendSessionResponse)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional int64 new_graph_version = 4;
      case 4: {
        if (tag == 32) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 input, &new_graph_version_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.ExtendSessionResponse)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.ExtendSessionResponse)
  return false;
#undef DO_
}

void ExtendSessionResponse::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.ExtendSessionResponse)
  // optional int64 new_graph_version = 4;
  if (this->new_graph_version() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt64(4, this->new_graph_version(), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.ExtendSessionResponse)
}

::google::protobuf::uint8* ExtendSessionResponse::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.ExtendSessionResponse)
  // optional int64 new_graph_version = 4;
  if (this->new_graph_version() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt64ToArray(4, this->new_graph_version(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.ExtendSessionResponse)
  return target;
}

int ExtendSessionResponse::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.ExtendSessionResponse)
  int total_size = 0;

  // optional int64 new_graph_version = 4;
  if (this->new_graph_version() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int64Size(
        this->new_graph_version());
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void ExtendSessionResponse::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.ExtendSessionResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const ExtendSessionResponse* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const ExtendSessionResponse>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.ExtendSessionResponse)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.ExtendSessionResponse)
    MergeFrom(*source);
  }
}

void ExtendSessionResponse::MergeFrom(const ExtendSessionResponse& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.ExtendSessionResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  if (from.new_graph_version() != 0) {
    set_new_graph_version(from.new_graph_version());
  }
}

void ExtendSessionResponse::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.ExtendSessionResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void ExtendSessionResponse::CopyFrom(const ExtendSessionResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.ExtendSessionResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ExtendSessionResponse::IsInitialized() const {

  return true;
}

void ExtendSessionResponse::Swap(ExtendSessionResponse* other) {
  if (other == this) return;
  InternalSwap(other);
}
void ExtendSessionResponse::InternalSwap(ExtendSessionResponse* other) {
  std::swap(new_graph_version_, other->new_graph_version_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata ExtendSessionResponse::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = ExtendSessionResponse_descriptor_;
  metadata.reflection = ExtendSessionResponse_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// ExtendSessionResponse

// optional int64 new_graph_version = 4;
void ExtendSessionResponse::clear_new_graph_version() {
  new_graph_version_ = GOOGLE_LONGLONG(0);
}
 ::google::protobuf::int64 ExtendSessionResponse::new_graph_version() const {
  // @@protoc_insertion_point(field_get:tensorflow.ExtendSessionResponse.new_graph_version)
  return new_graph_version_;
}
 void ExtendSessionResponse::set_new_graph_version(::google::protobuf::int64 value) {
  
  new_graph_version_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.ExtendSessionResponse.new_graph_version)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int RunStepRequest::kSessionHandleFieldNumber;
const int RunStepRequest::kFeedFieldNumber;
const int RunStepRequest::kFetchFieldNumber;
const int RunStepRequest::kTargetFieldNumber;
const int RunStepRequest::kOptionsFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

RunStepRequest::RunStepRequest()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.RunStepRequest)
}

void RunStepRequest::InitAsDefaultInstance() {
  _is_default_instance_ = true;
  options_ = const_cast< ::tensorflow::RunOptions*>(&::tensorflow::RunOptions::default_instance());
}

RunStepRequest::RunStepRequest(const RunStepRequest& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.RunStepRequest)
}

void RunStepRequest::SharedCtor() {
    _is_default_instance_ = false;
  ::google::protobuf::internal::GetEmptyString();
  _cached_size_ = 0;
  session_handle_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  options_ = NULL;
}

RunStepRequest::~RunStepRequest() {
  // @@protoc_insertion_point(destructor:tensorflow.RunStepRequest)
  SharedDtor();
}

void RunStepRequest::SharedDtor() {
  session_handle_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (this != default_instance_) {
    delete options_;
  }
}

void RunStepRequest::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* RunStepRequest::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return RunStepRequest_descriptor_;
}

const RunStepRequest& RunStepRequest::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fmaster_2eproto();
  return *default_instance_;
}

RunStepRequest* RunStepRequest::default_instance_ = NULL;

RunStepRequest* RunStepRequest::New(::google::protobuf::Arena* arena) const {
  RunStepRequest* n = new RunStepRequest;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void RunStepRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.RunStepRequest)
  session_handle_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (GetArenaNoVirtual() == NULL && options_ != NULL) delete options_;
  options_ = NULL;
  feed_.Clear();
  fetch_.Clear();
  target_.Clear();
}

bool RunStepRequest::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.RunStepRequest)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional string session_handle = 1;
      case 1: {
        if (tag == 10) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_session_handle()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->session_handle().data(), this->session_handle().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.RunStepRequest.session_handle"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_feed;
        break;
      }

      // repeated .tensorflow.NamedTensorProto feed = 2;
      case 2: {
        if (tag == 18) {
         parse_feed:
          DO_(input->IncrementRecursionDepth());
         parse_loop_feed:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_feed()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_loop_feed;
        input->UnsafeDecrementRecursionDepth();
        if (input->ExpectTag(26)) goto parse_fetch;
        break;
      }

      // repeated string fetch = 3;
      case 3: {
        if (tag == 26) {
         parse_fetch:
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->add_fetch()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->fetch(this->fetch_size() - 1).data(),
            this->fetch(this->fetch_size() - 1).length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.RunStepRequest.fetch"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(26)) goto parse_fetch;
        if (input->ExpectTag(34)) goto parse_target;
        break;
      }

      // repeated string target = 4;
      case 4: {
        if (tag == 34) {
         parse_target:
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->add_target()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->target(this->target_size() - 1).data(),
            this->target(this->target_size() - 1).length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.RunStepRequest.target"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(34)) goto parse_target;
        if (input->ExpectTag(42)) goto parse_options;
        break;
      }

      // optional .tensorflow.RunOptions options = 5;
      case 5: {
        if (tag == 42) {
         parse_options:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_options()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.RunStepRequest)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.RunStepRequest)
  return false;
#undef DO_
}

void RunStepRequest::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.RunStepRequest)
  // optional string session_handle = 1;
  if (this->session_handle().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->session_handle().data(), this->session_handle().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.RunStepRequest.session_handle");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      1, this->session_handle(), output);
  }

  // repeated .tensorflow.NamedTensorProto feed = 2;
  for (unsigned int i = 0, n = this->feed_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, this->feed(i), output);
  }

  // repeated string fetch = 3;
  for (int i = 0; i < this->fetch_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->fetch(i).data(), this->fetch(i).length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.RunStepRequest.fetch");
    ::google::protobuf::internal::WireFormatLite::WriteString(
      3, this->fetch(i), output);
  }

  // repeated string target = 4;
  for (int i = 0; i < this->target_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->target(i).data(), this->target(i).length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.RunStepRequest.target");
    ::google::protobuf::internal::WireFormatLite::WriteString(
      4, this->target(i), output);
  }

  // optional .tensorflow.RunOptions options = 5;
  if (this->has_options()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      5, *this->options_, output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.RunStepRequest)
}

::google::protobuf::uint8* RunStepRequest::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.RunStepRequest)
  // optional string session_handle = 1;
  if (this->session_handle().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->session_handle().data(), this->session_handle().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.RunStepRequest.session_handle");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        1, this->session_handle(), target);
  }

  // repeated .tensorflow.NamedTensorProto feed = 2;
  for (unsigned int i = 0, n = this->feed_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        2, this->feed(i), target);
  }

  // repeated string fetch = 3;
  for (int i = 0; i < this->fetch_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->fetch(i).data(), this->fetch(i).length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.RunStepRequest.fetch");
    target = ::google::protobuf::internal::WireFormatLite::
      WriteStringToArray(3, this->fetch(i), target);
  }

  // repeated string target = 4;
  for (int i = 0; i < this->target_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->target(i).data(), this->target(i).length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.RunStepRequest.target");
    target = ::google::protobuf::internal::WireFormatLite::
      WriteStringToArray(4, this->target(i), target);
  }

  // optional .tensorflow.RunOptions options = 5;
  if (this->has_options()) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        5, *this->options_, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.RunStepRequest)
  return target;
}

int RunStepRequest::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.RunStepRequest)
  int total_size = 0;

  // optional string session_handle = 1;
  if (this->session_handle().size() > 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->session_handle());
  }

  // optional .tensorflow.RunOptions options = 5;
  if (this->has_options()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->options_);
  }

  // repeated .tensorflow.NamedTensorProto feed = 2;
  total_size += 1 * this->feed_size();
  for (int i = 0; i < this->feed_size(); i++) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        this->feed(i));
  }

  // repeated string fetch = 3;
  total_size += 1 * this->fetch_size();
  for (int i = 0; i < this->fetch_size(); i++) {
    total_size += ::google::protobuf::internal::WireFormatLite::StringSize(
      this->fetch(i));
  }

  // repeated string target = 4;
  total_size += 1 * this->target_size();
  for (int i = 0; i < this->target_size(); i++) {
    total_size += ::google::protobuf::internal::WireFormatLite::StringSize(
      this->target(i));
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void RunStepRequest::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.RunStepRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const RunStepRequest* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const RunStepRequest>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.RunStepRequest)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.RunStepRequest)
    MergeFrom(*source);
  }
}

void RunStepRequest::MergeFrom(const RunStepRequest& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.RunStepRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  feed_.MergeFrom(from.feed_);
  fetch_.MergeFrom(from.fetch_);
  target_.MergeFrom(from.target_);
  if (from.session_handle().size() > 0) {

    session_handle_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.session_handle_);
  }
  if (from.has_options()) {
    mutable_options()->::tensorflow::RunOptions::MergeFrom(from.options());
  }
}

void RunStepRequest::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.RunStepRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void RunStepRequest::CopyFrom(const RunStepRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.RunStepRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool RunStepRequest::IsInitialized() const {

  return true;
}

void RunStepRequest::Swap(RunStepRequest* other) {
  if (other == this) return;
  InternalSwap(other);
}
void RunStepRequest::InternalSwap(RunStepRequest* other) {
  session_handle_.Swap(&other->session_handle_);
  feed_.UnsafeArenaSwap(&other->feed_);
  fetch_.UnsafeArenaSwap(&other->fetch_);
  target_.UnsafeArenaSwap(&other->target_);
  std::swap(options_, other->options_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata RunStepRequest::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = RunStepRequest_descriptor_;
  metadata.reflection = RunStepRequest_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// RunStepRequest

// optional string session_handle = 1;
void RunStepRequest::clear_session_handle() {
  session_handle_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 const ::std::string& RunStepRequest::session_handle() const {
  // @@protoc_insertion_point(field_get:tensorflow.RunStepRequest.session_handle)
  return session_handle_.GetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void RunStepRequest::set_session_handle(const ::std::string& value) {
  
  session_handle_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:tensorflow.RunStepRequest.session_handle)
}
 void RunStepRequest::set_session_handle(const char* value) {
  
  session_handle_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:tensorflow.RunStepRequest.session_handle)
}
 void RunStepRequest::set_session_handle(const char* value, size_t size) {
  
  session_handle_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:tensorflow.RunStepRequest.session_handle)
}
 ::std::string* RunStepRequest::mutable_session_handle() {
  
  // @@protoc_insertion_point(field_mutable:tensorflow.RunStepRequest.session_handle)
  return session_handle_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 ::std::string* RunStepRequest::release_session_handle() {
  // @@protoc_insertion_point(field_release:tensorflow.RunStepRequest.session_handle)
  
  return session_handle_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void RunStepRequest::set_allocated_session_handle(::std::string* session_handle) {
  if (session_handle != NULL) {
    
  } else {
    
  }
  session_handle_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), session_handle);
  // @@protoc_insertion_point(field_set_allocated:tensorflow.RunStepRequest.session_handle)
}

// repeated .tensorflow.NamedTensorProto feed = 2;
int RunStepRequest::feed_size() const {
  return feed_.size();
}
void RunStepRequest::clear_feed() {
  feed_.Clear();
}
const ::tensorflow::NamedTensorProto& RunStepRequest::feed(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.RunStepRequest.feed)
  return feed_.Get(index);
}
::tensorflow::NamedTensorProto* RunStepRequest::mutable_feed(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.RunStepRequest.feed)
  return feed_.Mutable(index);
}
::tensorflow::NamedTensorProto* RunStepRequest::add_feed() {
  // @@protoc_insertion_point(field_add:tensorflow.RunStepRequest.feed)
  return feed_.Add();
}
::google::protobuf::RepeatedPtrField< ::tensorflow::NamedTensorProto >*
RunStepRequest::mutable_feed() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.RunStepRequest.feed)
  return &feed_;
}
const ::google::protobuf::RepeatedPtrField< ::tensorflow::NamedTensorProto >&
RunStepRequest::feed() const {
  // @@protoc_insertion_point(field_list:tensorflow.RunStepRequest.feed)
  return feed_;
}

// repeated string fetch = 3;
int RunStepRequest::fetch_size() const {
  return fetch_.size();
}
void RunStepRequest::clear_fetch() {
  fetch_.Clear();
}
 const ::std::string& RunStepRequest::fetch(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.RunStepRequest.fetch)
  return fetch_.Get(index);
}
 ::std::string* RunStepRequest::mutable_fetch(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.RunStepRequest.fetch)
  return fetch_.Mutable(index);
}
 void RunStepRequest::set_fetch(int index, const ::std::string& value) {
  // @@protoc_insertion_point(field_set:tensorflow.RunStepRequest.fetch)
  fetch_.Mutable(index)->assign(value);
}
 void RunStepRequest::set_fetch(int index, const char* value) {
  fetch_.Mutable(index)->assign(value);
  // @@protoc_insertion_point(field_set_char:tensorflow.RunStepRequest.fetch)
}
 void RunStepRequest::set_fetch(int index, const char* value, size_t size) {
  fetch_.Mutable(index)->assign(
    reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:tensorflow.RunStepRequest.fetch)
}
 ::std::string* RunStepRequest::add_fetch() {
  // @@protoc_insertion_point(field_add_mutable:tensorflow.RunStepRequest.fetch)
  return fetch_.Add();
}
 void RunStepRequest::add_fetch(const ::std::string& value) {
  fetch_.Add()->assign(value);
  // @@protoc_insertion_point(field_add:tensorflow.RunStepRequest.fetch)
}
 void RunStepRequest::add_fetch(const char* value) {
  fetch_.Add()->assign(value);
  // @@protoc_insertion_point(field_add_char:tensorflow.RunStepRequest.fetch)
}
 void RunStepRequest::add_fetch(const char* value, size_t size) {
  fetch_.Add()->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_add_pointer:tensorflow.RunStepRequest.fetch)
}
 const ::google::protobuf::RepeatedPtrField< ::std::string>&
RunStepRequest::fetch() const {
  // @@protoc_insertion_point(field_list:tensorflow.RunStepRequest.fetch)
  return fetch_;
}
 ::google::protobuf::RepeatedPtrField< ::std::string>*
RunStepRequest::mutable_fetch() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.RunStepRequest.fetch)
  return &fetch_;
}

// repeated string target = 4;
int RunStepRequest::target_size() const {
  return target_.size();
}
void RunStepRequest::clear_target() {
  target_.Clear();
}
 const ::std::string& RunStepRequest::target(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.RunStepRequest.target)
  return target_.Get(index);
}
 ::std::string* RunStepRequest::mutable_target(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.RunStepRequest.target)
  return target_.Mutable(index);
}
 void RunStepRequest::set_target(int index, const ::std::string& value) {
  // @@protoc_insertion_point(field_set:tensorflow.RunStepRequest.target)
  target_.Mutable(index)->assign(value);
}
 void RunStepRequest::set_target(int index, const char* value) {
  target_.Mutable(index)->assign(value);
  // @@protoc_insertion_point(field_set_char:tensorflow.RunStepRequest.target)
}
 void RunStepRequest::set_target(int index, const char* value, size_t size) {
  target_.Mutable(index)->assign(
    reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:tensorflow.RunStepRequest.target)
}
 ::std::string* RunStepRequest::add_target() {
  // @@protoc_insertion_point(field_add_mutable:tensorflow.RunStepRequest.target)
  return target_.Add();
}
 void RunStepRequest::add_target(const ::std::string& value) {
  target_.Add()->assign(value);
  // @@protoc_insertion_point(field_add:tensorflow.RunStepRequest.target)
}
 void RunStepRequest::add_target(const char* value) {
  target_.Add()->assign(value);
  // @@protoc_insertion_point(field_add_char:tensorflow.RunStepRequest.target)
}
 void RunStepRequest::add_target(const char* value, size_t size) {
  target_.Add()->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_add_pointer:tensorflow.RunStepRequest.target)
}
 const ::google::protobuf::RepeatedPtrField< ::std::string>&
RunStepRequest::target() const {
  // @@protoc_insertion_point(field_list:tensorflow.RunStepRequest.target)
  return target_;
}
 ::google::protobuf::RepeatedPtrField< ::std::string>*
RunStepRequest::mutable_target() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.RunStepRequest.target)
  return &target_;
}

// optional .tensorflow.RunOptions options = 5;
bool RunStepRequest::has_options() const {
  return !_is_default_instance_ && options_ != NULL;
}
void RunStepRequest::clear_options() {
  if (GetArenaNoVirtual() == NULL && options_ != NULL) delete options_;
  options_ = NULL;
}
const ::tensorflow::RunOptions& RunStepRequest::options() const {
  // @@protoc_insertion_point(field_get:tensorflow.RunStepRequest.options)
  return options_ != NULL ? *options_ : *default_instance_->options_;
}
::tensorflow::RunOptions* RunStepRequest::mutable_options() {
  
  if (options_ == NULL) {
    options_ = new ::tensorflow::RunOptions;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.RunStepRequest.options)
  return options_;
}
::tensorflow::RunOptions* RunStepRequest::release_options() {
  // @@protoc_insertion_point(field_release:tensorflow.RunStepRequest.options)
  
  ::tensorflow::RunOptions* temp = options_;
  options_ = NULL;
  return temp;
}
void RunStepRequest::set_allocated_options(::tensorflow::RunOptions* options) {
  delete options_;
  options_ = options;
  if (options) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.RunStepRequest.options)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int RunStepResponse::kTensorFieldNumber;
const int RunStepResponse::kMetadataFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

RunStepResponse::RunStepResponse()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.RunStepResponse)
}

void RunStepResponse::InitAsDefaultInstance() {
  _is_default_instance_ = true;
  metadata_ = const_cast< ::tensorflow::RunMetadata*>(&::tensorflow::RunMetadata::default_instance());
}

RunStepResponse::RunStepResponse(const RunStepResponse& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.RunStepResponse)
}

void RunStepResponse::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  metadata_ = NULL;
}

RunStepResponse::~RunStepResponse() {
  // @@protoc_insertion_point(destructor:tensorflow.RunStepResponse)
  SharedDtor();
}

void RunStepResponse::SharedDtor() {
  if (this != default_instance_) {
    delete metadata_;
  }
}

void RunStepResponse::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* RunStepResponse::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return RunStepResponse_descriptor_;
}

const RunStepResponse& RunStepResponse::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fmaster_2eproto();
  return *default_instance_;
}

RunStepResponse* RunStepResponse::default_instance_ = NULL;

RunStepResponse* RunStepResponse::New(::google::protobuf::Arena* arena) const {
  RunStepResponse* n = new RunStepResponse;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void RunStepResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.RunStepResponse)
  if (GetArenaNoVirtual() == NULL && metadata_ != NULL) delete metadata_;
  metadata_ = NULL;
  tensor_.Clear();
}

bool RunStepResponse::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.RunStepResponse)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // repeated .tensorflow.NamedTensorProto tensor = 1;
      case 1: {
        if (tag == 10) {
          DO_(input->IncrementRecursionDepth());
         parse_loop_tensor:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_tensor()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(10)) goto parse_loop_tensor;
        input->UnsafeDecrementRecursionDepth();
        if (input->ExpectTag(18)) goto parse_metadata;
        break;
      }

      // optional .tensorflow.RunMetadata metadata = 2;
      case 2: {
        if (tag == 18) {
         parse_metadata:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_metadata()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.RunStepResponse)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.RunStepResponse)
  return false;
#undef DO_
}

void RunStepResponse::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.RunStepResponse)
  // repeated .tensorflow.NamedTensorProto tensor = 1;
  for (unsigned int i = 0, n = this->tensor_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, this->tensor(i), output);
  }

  // optional .tensorflow.RunMetadata metadata = 2;
  if (this->has_metadata()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, *this->metadata_, output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.RunStepResponse)
}

::google::protobuf::uint8* RunStepResponse::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.RunStepResponse)
  // repeated .tensorflow.NamedTensorProto tensor = 1;
  for (unsigned int i = 0, n = this->tensor_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        1, this->tensor(i), target);
  }

  // optional .tensorflow.RunMetadata metadata = 2;
  if (this->has_metadata()) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        2, *this->metadata_, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.RunStepResponse)
  return target;
}

int RunStepResponse::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.RunStepResponse)
  int total_size = 0;

  // optional .tensorflow.RunMetadata metadata = 2;
  if (this->has_metadata()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->metadata_);
  }

  // repeated .tensorflow.NamedTensorProto tensor = 1;
  total_size += 1 * this->tensor_size();
  for (int i = 0; i < this->tensor_size(); i++) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        this->tensor(i));
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void RunStepResponse::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.RunStepResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const RunStepResponse* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const RunStepResponse>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.RunStepResponse)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.RunStepResponse)
    MergeFrom(*source);
  }
}

void RunStepResponse::MergeFrom(const RunStepResponse& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.RunStepResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  tensor_.MergeFrom(from.tensor_);
  if (from.has_metadata()) {
    mutable_metadata()->::tensorflow::RunMetadata::MergeFrom(from.metadata());
  }
}

void RunStepResponse::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.RunStepResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void RunStepResponse::CopyFrom(const RunStepResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.RunStepResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool RunStepResponse::IsInitialized() const {

  return true;
}

void RunStepResponse::Swap(RunStepResponse* other) {
  if (other == this) return;
  InternalSwap(other);
}
void RunStepResponse::InternalSwap(RunStepResponse* other) {
  tensor_.UnsafeArenaSwap(&other->tensor_);
  std::swap(metadata_, other->metadata_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata RunStepResponse::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = RunStepResponse_descriptor_;
  metadata.reflection = RunStepResponse_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// RunStepResponse

// repeated .tensorflow.NamedTensorProto tensor = 1;
int RunStepResponse::tensor_size() const {
  return tensor_.size();
}
void RunStepResponse::clear_tensor() {
  tensor_.Clear();
}
const ::tensorflow::NamedTensorProto& RunStepResponse::tensor(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.RunStepResponse.tensor)
  return tensor_.Get(index);
}
::tensorflow::NamedTensorProto* RunStepResponse::mutable_tensor(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.RunStepResponse.tensor)
  return tensor_.Mutable(index);
}
::tensorflow::NamedTensorProto* RunStepResponse::add_tensor() {
  // @@protoc_insertion_point(field_add:tensorflow.RunStepResponse.tensor)
  return tensor_.Add();
}
::google::protobuf::RepeatedPtrField< ::tensorflow::NamedTensorProto >*
RunStepResponse::mutable_tensor() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.RunStepResponse.tensor)
  return &tensor_;
}
const ::google::protobuf::RepeatedPtrField< ::tensorflow::NamedTensorProto >&
RunStepResponse::tensor() const {
  // @@protoc_insertion_point(field_list:tensorflow.RunStepResponse.tensor)
  return tensor_;
}

// optional .tensorflow.RunMetadata metadata = 2;
bool RunStepResponse::has_metadata() const {
  return !_is_default_instance_ && metadata_ != NULL;
}
void RunStepResponse::clear_metadata() {
  if (GetArenaNoVirtual() == NULL && metadata_ != NULL) delete metadata_;
  metadata_ = NULL;
}
const ::tensorflow::RunMetadata& RunStepResponse::metadata() const {
  // @@protoc_insertion_point(field_get:tensorflow.RunStepResponse.metadata)
  return metadata_ != NULL ? *metadata_ : *default_instance_->metadata_;
}
::tensorflow::RunMetadata* RunStepResponse::mutable_metadata() {
  
  if (metadata_ == NULL) {
    metadata_ = new ::tensorflow::RunMetadata;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.RunStepResponse.metadata)
  return metadata_;
}
::tensorflow::RunMetadata* RunStepResponse::release_metadata() {
  // @@protoc_insertion_point(field_release:tensorflow.RunStepResponse.metadata)
  
  ::tensorflow::RunMetadata* temp = metadata_;
  metadata_ = NULL;
  return temp;
}
void RunStepResponse::set_allocated_metadata(::tensorflow::RunMetadata* metadata) {
  delete metadata_;
  metadata_ = metadata;
  if (metadata) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.RunStepResponse.metadata)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int CloseSessionRequest::kSessionHandleFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

CloseSessionRequest::CloseSessionRequest()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.CloseSessionRequest)
}

void CloseSessionRequest::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

CloseSessionRequest::CloseSessionRequest(const CloseSessionRequest& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.CloseSessionRequest)
}

void CloseSessionRequest::SharedCtor() {
    _is_default_instance_ = false;
  ::google::protobuf::internal::GetEmptyString();
  _cached_size_ = 0;
  session_handle_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}

CloseSessionRequest::~CloseSessionRequest() {
  // @@protoc_insertion_point(destructor:tensorflow.CloseSessionRequest)
  SharedDtor();
}

void CloseSessionRequest::SharedDtor() {
  session_handle_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (this != default_instance_) {
  }
}

void CloseSessionRequest::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* CloseSessionRequest::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return CloseSessionRequest_descriptor_;
}

const CloseSessionRequest& CloseSessionRequest::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fmaster_2eproto();
  return *default_instance_;
}

CloseSessionRequest* CloseSessionRequest::default_instance_ = NULL;

CloseSessionRequest* CloseSessionRequest::New(::google::protobuf::Arena* arena) const {
  CloseSessionRequest* n = new CloseSessionRequest;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void CloseSessionRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.CloseSessionRequest)
  session_handle_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}

bool CloseSessionRequest::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.CloseSessionRequest)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional string session_handle = 1;
      case 1: {
        if (tag == 10) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_session_handle()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->session_handle().data(), this->session_handle().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.CloseSessionRequest.session_handle"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.CloseSessionRequest)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.CloseSessionRequest)
  return false;
#undef DO_
}

void CloseSessionRequest::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.CloseSessionRequest)
  // optional string session_handle = 1;
  if (this->session_handle().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->session_handle().data(), this->session_handle().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.CloseSessionRequest.session_handle");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      1, this->session_handle(), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.CloseSessionRequest)
}

::google::protobuf::uint8* CloseSessionRequest::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.CloseSessionRequest)
  // optional string session_handle = 1;
  if (this->session_handle().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->session_handle().data(), this->session_handle().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.CloseSessionRequest.session_handle");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        1, this->session_handle(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.CloseSessionRequest)
  return target;
}

int CloseSessionRequest::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.CloseSessionRequest)
  int total_size = 0;

  // optional string session_handle = 1;
  if (this->session_handle().size() > 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->session_handle());
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void CloseSessionRequest::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.CloseSessionRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const CloseSessionRequest* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const CloseSessionRequest>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.CloseSessionRequest)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.CloseSessionRequest)
    MergeFrom(*source);
  }
}

void CloseSessionRequest::MergeFrom(const CloseSessionRequest& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.CloseSessionRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  if (from.session_handle().size() > 0) {

    session_handle_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.session_handle_);
  }
}

void CloseSessionRequest::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.CloseSessionRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void CloseSessionRequest::CopyFrom(const CloseSessionRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.CloseSessionRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool CloseSessionRequest::IsInitialized() const {

  return true;
}

void CloseSessionRequest::Swap(CloseSessionRequest* other) {
  if (other == this) return;
  InternalSwap(other);
}
void CloseSessionRequest::InternalSwap(CloseSessionRequest* other) {
  session_handle_.Swap(&other->session_handle_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata CloseSessionRequest::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = CloseSessionRequest_descriptor_;
  metadata.reflection = CloseSessionRequest_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// CloseSessionRequest

// optional string session_handle = 1;
void CloseSessionRequest::clear_session_handle() {
  session_handle_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 const ::std::string& CloseSessionRequest::session_handle() const {
  // @@protoc_insertion_point(field_get:tensorflow.CloseSessionRequest.session_handle)
  return session_handle_.GetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void CloseSessionRequest::set_session_handle(const ::std::string& value) {
  
  session_handle_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:tensorflow.CloseSessionRequest.session_handle)
}
 void CloseSessionRequest::set_session_handle(const char* value) {
  
  session_handle_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:tensorflow.CloseSessionRequest.session_handle)
}
 void CloseSessionRequest::set_session_handle(const char* value, size_t size) {
  
  session_handle_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:tensorflow.CloseSessionRequest.session_handle)
}
 ::std::string* CloseSessionRequest::mutable_session_handle() {
  
  // @@protoc_insertion_point(field_mutable:tensorflow.CloseSessionRequest.session_handle)
  return session_handle_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 ::std::string* CloseSessionRequest::release_session_handle() {
  // @@protoc_insertion_point(field_release:tensorflow.CloseSessionRequest.session_handle)
  
  return session_handle_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void CloseSessionRequest::set_allocated_session_handle(::std::string* session_handle) {
  if (session_handle != NULL) {
    
  } else {
    
  }
  session_handle_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), session_handle);
  // @@protoc_insertion_point(field_set_allocated:tensorflow.CloseSessionRequest.session_handle)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

CloseSessionResponse::CloseSessionResponse()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.CloseSessionResponse)
}

void CloseSessionResponse::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

CloseSessionResponse::CloseSessionResponse(const CloseSessionResponse& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.CloseSessionResponse)
}

void CloseSessionResponse::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
}

CloseSessionResponse::~CloseSessionResponse() {
  // @@protoc_insertion_point(destructor:tensorflow.CloseSessionResponse)
  SharedDtor();
}

void CloseSessionResponse::SharedDtor() {
  if (this != default_instance_) {
  }
}

void CloseSessionResponse::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* CloseSessionResponse::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return CloseSessionResponse_descriptor_;
}

const CloseSessionResponse& CloseSessionResponse::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fmaster_2eproto();
  return *default_instance_;
}

CloseSessionResponse* CloseSessionResponse::default_instance_ = NULL;

CloseSessionResponse* CloseSessionResponse::New(::google::protobuf::Arena* arena) const {
  CloseSessionResponse* n = new CloseSessionResponse;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void CloseSessionResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.CloseSessionResponse)
}

bool CloseSessionResponse::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.CloseSessionResponse)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
  handle_unusual:
    if (tag == 0 ||
        ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
        ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
      goto success;
    }
    DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.CloseSessionResponse)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.CloseSessionResponse)
  return false;
#undef DO_
}

void CloseSessionResponse::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.CloseSessionResponse)
  // @@protoc_insertion_point(serialize_end:tensorflow.CloseSessionResponse)
}

::google::protobuf::uint8* CloseSessionResponse::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.CloseSessionResponse)
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.CloseSessionResponse)
  return target;
}

int CloseSessionResponse::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.CloseSessionResponse)
  int total_size = 0;

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void CloseSessionResponse::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.CloseSessionResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const CloseSessionResponse* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const CloseSessionResponse>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.CloseSessionResponse)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.CloseSessionResponse)
    MergeFrom(*source);
  }
}

void CloseSessionResponse::MergeFrom(const CloseSessionResponse& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.CloseSessionResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
}

void CloseSessionResponse::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.CloseSessionResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void CloseSessionResponse::CopyFrom(const CloseSessionResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.CloseSessionResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool CloseSessionResponse::IsInitialized() const {

  return true;
}

void CloseSessionResponse::Swap(CloseSessionResponse* other) {
  if (other == this) return;
  InternalSwap(other);
}
void CloseSessionResponse::InternalSwap(CloseSessionResponse* other) {
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata CloseSessionResponse::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = CloseSessionResponse_descriptor_;
  metadata.reflection = CloseSessionResponse_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// CloseSessionResponse

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int ResetRequest::kContainerFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

ResetRequest::ResetRequest()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.ResetRequest)
}

void ResetRequest::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

ResetRequest::ResetRequest(const ResetRequest& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.ResetRequest)
}

void ResetRequest::SharedCtor() {
    _is_default_instance_ = false;
  ::google::protobuf::internal::GetEmptyString();
  _cached_size_ = 0;
}

ResetRequest::~ResetRequest() {
  // @@protoc_insertion_point(destructor:tensorflow.ResetRequest)
  SharedDtor();
}

void ResetRequest::SharedDtor() {
  if (this != default_instance_) {
  }
}

void ResetRequest::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* ResetRequest::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return ResetRequest_descriptor_;
}

const ResetRequest& ResetRequest::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fmaster_2eproto();
  return *default_instance_;
}

ResetRequest* ResetRequest::default_instance_ = NULL;

ResetRequest* ResetRequest::New(::google::protobuf::Arena* arena) const {
  ResetRequest* n = new ResetRequest;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void ResetRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.ResetRequest)
  container_.Clear();
}

bool ResetRequest::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.ResetRequest)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // repeated string container = 1;
      case 1: {
        if (tag == 10) {
         parse_container:
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->add_container()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->container(this->container_size() - 1).data(),
            this->container(this->container_size() - 1).length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.ResetRequest.container"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(10)) goto parse_container;
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.ResetRequest)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.ResetRequest)
  return false;
#undef DO_
}

void ResetRequest::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.ResetRequest)
  // repeated string container = 1;
  for (int i = 0; i < this->container_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->container(i).data(), this->container(i).length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.ResetRequest.container");
    ::google::protobuf::internal::WireFormatLite::WriteString(
      1, this->container(i), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.ResetRequest)
}

::google::protobuf::uint8* ResetRequest::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.ResetRequest)
  // repeated string container = 1;
  for (int i = 0; i < this->container_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->container(i).data(), this->container(i).length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.ResetRequest.container");
    target = ::google::protobuf::internal::WireFormatLite::
      WriteStringToArray(1, this->container(i), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.ResetRequest)
  return target;
}

int ResetRequest::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.ResetRequest)
  int total_size = 0;

  // repeated string container = 1;
  total_size += 1 * this->container_size();
  for (int i = 0; i < this->container_size(); i++) {
    total_size += ::google::protobuf::internal::WireFormatLite::StringSize(
      this->container(i));
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void ResetRequest::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.ResetRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const ResetRequest* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const ResetRequest>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.ResetRequest)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.ResetRequest)
    MergeFrom(*source);
  }
}

void ResetRequest::MergeFrom(const ResetRequest& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.ResetRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  container_.MergeFrom(from.container_);
}

void ResetRequest::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.ResetRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void ResetRequest::CopyFrom(const ResetRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.ResetRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ResetRequest::IsInitialized() const {

  return true;
}

void ResetRequest::Swap(ResetRequest* other) {
  if (other == this) return;
  InternalSwap(other);
}
void ResetRequest::InternalSwap(ResetRequest* other) {
  container_.UnsafeArenaSwap(&other->container_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata ResetRequest::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = ResetRequest_descriptor_;
  metadata.reflection = ResetRequest_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// ResetRequest

// repeated string container = 1;
int ResetRequest::container_size() const {
  return container_.size();
}
void ResetRequest::clear_container() {
  container_.Clear();
}
 const ::std::string& ResetRequest::container(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.ResetRequest.container)
  return container_.Get(index);
}
 ::std::string* ResetRequest::mutable_container(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.ResetRequest.container)
  return container_.Mutable(index);
}
 void ResetRequest::set_container(int index, const ::std::string& value) {
  // @@protoc_insertion_point(field_set:tensorflow.ResetRequest.container)
  container_.Mutable(index)->assign(value);
}
 void ResetRequest::set_container(int index, const char* value) {
  container_.Mutable(index)->assign(value);
  // @@protoc_insertion_point(field_set_char:tensorflow.ResetRequest.container)
}
 void ResetRequest::set_container(int index, const char* value, size_t size) {
  container_.Mutable(index)->assign(
    reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:tensorflow.ResetRequest.container)
}
 ::std::string* ResetRequest::add_container() {
  // @@protoc_insertion_point(field_add_mutable:tensorflow.ResetRequest.container)
  return container_.Add();
}
 void ResetRequest::add_container(const ::std::string& value) {
  container_.Add()->assign(value);
  // @@protoc_insertion_point(field_add:tensorflow.ResetRequest.container)
}
 void ResetRequest::add_container(const char* value) {
  container_.Add()->assign(value);
  // @@protoc_insertion_point(field_add_char:tensorflow.ResetRequest.container)
}
 void ResetRequest::add_container(const char* value, size_t size) {
  container_.Add()->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_add_pointer:tensorflow.ResetRequest.container)
}
 const ::google::protobuf::RepeatedPtrField< ::std::string>&
ResetRequest::container() const {
  // @@protoc_insertion_point(field_list:tensorflow.ResetRequest.container)
  return container_;
}
 ::google::protobuf::RepeatedPtrField< ::std::string>*
ResetRequest::mutable_container() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.ResetRequest.container)
  return &container_;
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

ResetResponse::ResetResponse()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.ResetResponse)
}

void ResetResponse::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

ResetResponse::ResetResponse(const ResetResponse& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.ResetResponse)
}

void ResetResponse::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
}

ResetResponse::~ResetResponse() {
  // @@protoc_insertion_point(destructor:tensorflow.ResetResponse)
  SharedDtor();
}

void ResetResponse::SharedDtor() {
  if (this != default_instance_) {
  }
}

void ResetResponse::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* ResetResponse::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return ResetResponse_descriptor_;
}

const ResetResponse& ResetResponse::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fmaster_2eproto();
  return *default_instance_;
}

ResetResponse* ResetResponse::default_instance_ = NULL;

ResetResponse* ResetResponse::New(::google::protobuf::Arena* arena) const {
  ResetResponse* n = new ResetResponse;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void ResetResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.ResetResponse)
}

bool ResetResponse::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.ResetResponse)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
  handle_unusual:
    if (tag == 0 ||
        ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
        ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
      goto success;
    }
    DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.ResetResponse)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.ResetResponse)
  return false;
#undef DO_
}

void ResetResponse::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.ResetResponse)
  // @@protoc_insertion_point(serialize_end:tensorflow.ResetResponse)
}

::google::protobuf::uint8* ResetResponse::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.ResetResponse)
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.ResetResponse)
  return target;
}

int ResetResponse::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.ResetResponse)
  int total_size = 0;

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void ResetResponse::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.ResetResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const ResetResponse* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const ResetResponse>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.ResetResponse)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.ResetResponse)
    MergeFrom(*source);
  }
}

void ResetResponse::MergeFrom(const ResetResponse& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.ResetResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
}

void ResetResponse::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.ResetResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void ResetResponse::CopyFrom(const ResetResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.ResetResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ResetResponse::IsInitialized() const {

  return true;
}

void ResetResponse::Swap(ResetResponse* other) {
  if (other == this) return;
  InternalSwap(other);
}
void ResetResponse::InternalSwap(ResetResponse* other) {
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata ResetResponse::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = ResetResponse_descriptor_;
  metadata.reflection = ResetResponse_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// ResetResponse

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

ListDevicesRequest::ListDevicesRequest()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.ListDevicesRequest)
}

void ListDevicesRequest::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

ListDevicesRequest::ListDevicesRequest(const ListDevicesRequest& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.ListDevicesRequest)
}

void ListDevicesRequest::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
}

ListDevicesRequest::~ListDevicesRequest() {
  // @@protoc_insertion_point(destructor:tensorflow.ListDevicesRequest)
  SharedDtor();
}

void ListDevicesRequest::SharedDtor() {
  if (this != default_instance_) {
  }
}

void ListDevicesRequest::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* ListDevicesRequest::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return ListDevicesRequest_descriptor_;
}

const ListDevicesRequest& ListDevicesRequest::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fmaster_2eproto();
  return *default_instance_;
}

ListDevicesRequest* ListDevicesRequest::default_instance_ = NULL;

ListDevicesRequest* ListDevicesRequest::New(::google::protobuf::Arena* arena) const {
  ListDevicesRequest* n = new ListDevicesRequest;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void ListDevicesRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.ListDevicesRequest)
}

bool ListDevicesRequest::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.ListDevicesRequest)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
  handle_unusual:
    if (tag == 0 ||
        ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
        ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
      goto success;
    }
    DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.ListDevicesRequest)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.ListDevicesRequest)
  return false;
#undef DO_
}

void ListDevicesRequest::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.ListDevicesRequest)
  // @@protoc_insertion_point(serialize_end:tensorflow.ListDevicesRequest)
}

::google::protobuf::uint8* ListDevicesRequest::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.ListDevicesRequest)
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.ListDevicesRequest)
  return target;
}

int ListDevicesRequest::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.ListDevicesRequest)
  int total_size = 0;

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void ListDevicesRequest::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.ListDevicesRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const ListDevicesRequest* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const ListDevicesRequest>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.ListDevicesRequest)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.ListDevicesRequest)
    MergeFrom(*source);
  }
}

void ListDevicesRequest::MergeFrom(const ListDevicesRequest& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.ListDevicesRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
}

void ListDevicesRequest::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.ListDevicesRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void ListDevicesRequest::CopyFrom(const ListDevicesRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.ListDevicesRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ListDevicesRequest::IsInitialized() const {

  return true;
}

void ListDevicesRequest::Swap(ListDevicesRequest* other) {
  if (other == this) return;
  InternalSwap(other);
}
void ListDevicesRequest::InternalSwap(ListDevicesRequest* other) {
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata ListDevicesRequest::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = ListDevicesRequest_descriptor_;
  metadata.reflection = ListDevicesRequest_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// ListDevicesRequest

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int ListDevicesResponse::kLocalDeviceFieldNumber;
const int ListDevicesResponse::kRemoteDeviceFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

ListDevicesResponse::ListDevicesResponse()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.ListDevicesResponse)
}

void ListDevicesResponse::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

ListDevicesResponse::ListDevicesResponse(const ListDevicesResponse& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.ListDevicesResponse)
}

void ListDevicesResponse::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
}

ListDevicesResponse::~ListDevicesResponse() {
  // @@protoc_insertion_point(destructor:tensorflow.ListDevicesResponse)
  SharedDtor();
}

void ListDevicesResponse::SharedDtor() {
  if (this != default_instance_) {
  }
}

void ListDevicesResponse::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* ListDevicesResponse::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return ListDevicesResponse_descriptor_;
}

const ListDevicesResponse& ListDevicesResponse::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fmaster_2eproto();
  return *default_instance_;
}

ListDevicesResponse* ListDevicesResponse::default_instance_ = NULL;

ListDevicesResponse* ListDevicesResponse::New(::google::protobuf::Arena* arena) const {
  ListDevicesResponse* n = new ListDevicesResponse;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void ListDevicesResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.ListDevicesResponse)
  local_device_.Clear();
  remote_device_.Clear();
}

bool ListDevicesResponse::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.ListDevicesResponse)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // repeated .tensorflow.DeviceAttributes local_device = 1;
      case 1: {
        if (tag == 10) {
          DO_(input->IncrementRecursionDepth());
         parse_loop_local_device:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_local_device()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(10)) goto parse_loop_local_device;
        if (input->ExpectTag(18)) goto parse_loop_remote_device;
        input->UnsafeDecrementRecursionDepth();
        break;
      }

      // repeated .tensorflow.DeviceAttributes remote_device = 2;
      case 2: {
        if (tag == 18) {
          DO_(input->IncrementRecursionDepth());
         parse_loop_remote_device:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_remote_device()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_loop_remote_device;
        input->UnsafeDecrementRecursionDepth();
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.ListDevicesResponse)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.ListDevicesResponse)
  return false;
#undef DO_
}

void ListDevicesResponse::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.ListDevicesResponse)
  // repeated .tensorflow.DeviceAttributes local_device = 1;
  for (unsigned int i = 0, n = this->local_device_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, this->local_device(i), output);
  }

  // repeated .tensorflow.DeviceAttributes remote_device = 2;
  for (unsigned int i = 0, n = this->remote_device_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, this->remote_device(i), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.ListDevicesResponse)
}

::google::protobuf::uint8* ListDevicesResponse::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.ListDevicesResponse)
  // repeated .tensorflow.DeviceAttributes local_device = 1;
  for (unsigned int i = 0, n = this->local_device_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        1, this->local_device(i), target);
  }

  // repeated .tensorflow.DeviceAttributes remote_device = 2;
  for (unsigned int i = 0, n = this->remote_device_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        2, this->remote_device(i), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.ListDevicesResponse)
  return target;
}

int ListDevicesResponse::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.ListDevicesResponse)
  int total_size = 0;

  // repeated .tensorflow.DeviceAttributes local_device = 1;
  total_size += 1 * this->local_device_size();
  for (int i = 0; i < this->local_device_size(); i++) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        this->local_device(i));
  }

  // repeated .tensorflow.DeviceAttributes remote_device = 2;
  total_size += 1 * this->remote_device_size();
  for (int i = 0; i < this->remote_device_size(); i++) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        this->remote_device(i));
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void ListDevicesResponse::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.ListDevicesResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const ListDevicesResponse* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const ListDevicesResponse>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.ListDevicesResponse)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.ListDevicesResponse)
    MergeFrom(*source);
  }
}

void ListDevicesResponse::MergeFrom(const ListDevicesResponse& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.ListDevicesResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  local_device_.MergeFrom(from.local_device_);
  remote_device_.MergeFrom(from.remote_device_);
}

void ListDevicesResponse::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.ListDevicesResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void ListDevicesResponse::CopyFrom(const ListDevicesResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.ListDevicesResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ListDevicesResponse::IsInitialized() const {

  return true;
}

void ListDevicesResponse::Swap(ListDevicesResponse* other) {
  if (other == this) return;
  InternalSwap(other);
}
void ListDevicesResponse::InternalSwap(ListDevicesResponse* other) {
  local_device_.UnsafeArenaSwap(&other->local_device_);
  remote_device_.UnsafeArenaSwap(&other->remote_device_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata ListDevicesResponse::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = ListDevicesResponse_descriptor_;
  metadata.reflection = ListDevicesResponse_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// ListDevicesResponse

// repeated .tensorflow.DeviceAttributes local_device = 1;
int ListDevicesResponse::local_device_size() const {
  return local_device_.size();
}
void ListDevicesResponse::clear_local_device() {
  local_device_.Clear();
}
const ::tensorflow::DeviceAttributes& ListDevicesResponse::local_device(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.ListDevicesResponse.local_device)
  return local_device_.Get(index);
}
::tensorflow::DeviceAttributes* ListDevicesResponse::mutable_local_device(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.ListDevicesResponse.local_device)
  return local_device_.Mutable(index);
}
::tensorflow::DeviceAttributes* ListDevicesResponse::add_local_device() {
  // @@protoc_insertion_point(field_add:tensorflow.ListDevicesResponse.local_device)
  return local_device_.Add();
}
::google::protobuf::RepeatedPtrField< ::tensorflow::DeviceAttributes >*
ListDevicesResponse::mutable_local_device() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.ListDevicesResponse.local_device)
  return &local_device_;
}
const ::google::protobuf::RepeatedPtrField< ::tensorflow::DeviceAttributes >&
ListDevicesResponse::local_device() const {
  // @@protoc_insertion_point(field_list:tensorflow.ListDevicesResponse.local_device)
  return local_device_;
}

// repeated .tensorflow.DeviceAttributes remote_device = 2;
int ListDevicesResponse::remote_device_size() const {
  return remote_device_.size();
}
void ListDevicesResponse::clear_remote_device() {
  remote_device_.Clear();
}
const ::tensorflow::DeviceAttributes& ListDevicesResponse::remote_device(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.ListDevicesResponse.remote_device)
  return remote_device_.Get(index);
}
::tensorflow::DeviceAttributes* ListDevicesResponse::mutable_remote_device(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.ListDevicesResponse.remote_device)
  return remote_device_.Mutable(index);
}
::tensorflow::DeviceAttributes* ListDevicesResponse::add_remote_device() {
  // @@protoc_insertion_point(field_add:tensorflow.ListDevicesResponse.remote_device)
  return remote_device_.Add();
}
::google::protobuf::RepeatedPtrField< ::tensorflow::DeviceAttributes >*
ListDevicesResponse::mutable_remote_device() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.ListDevicesResponse.remote_device)
  return &remote_device_;
}
const ::google::protobuf::RepeatedPtrField< ::tensorflow::DeviceAttributes >&
ListDevicesResponse::remote_device() const {
  // @@protoc_insertion_point(field_list:tensorflow.ListDevicesResponse.remote_device)
  return remote_device_;
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// @@protoc_insertion_point(namespace_scope)

}  // namespace tensorflow

// @@protoc_insertion_point(global_scope)
