// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/protobuf/worker.proto

#define INTERNAL_SUPPRESS_PROTOBUF_FIELD_DEPRECATION
#include "tensorflow/core/protobuf/worker.pb.h"

#include <algorithm>

#include <google/protobuf/stubs/common.h>
#include <google/protobuf/stubs/port.h>
#include <google/protobuf/stubs/once.h>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/wire_format_lite_inl.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)

namespace tensorflow {

namespace {

const ::google::protobuf::Descriptor* GetStatusRequest_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  GetStatusRequest_reflection_ = NULL;
const ::google::protobuf::Descriptor* GetStatusResponse_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  GetStatusResponse_reflection_ = NULL;
const ::google::protobuf::Descriptor* RegisterGraphRequest_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  RegisterGraphRequest_reflection_ = NULL;
const ::google::protobuf::Descriptor* RegisterGraphResponse_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  RegisterGraphResponse_reflection_ = NULL;
const ::google::protobuf::Descriptor* DeregisterGraphRequest_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  DeregisterGraphRequest_reflection_ = NULL;
const ::google::protobuf::Descriptor* DeregisterGraphResponse_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  DeregisterGraphResponse_reflection_ = NULL;
const ::google::protobuf::Descriptor* CleanupAllRequest_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  CleanupAllRequest_reflection_ = NULL;
const ::google::protobuf::Descriptor* CleanupAllResponse_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  CleanupAllResponse_reflection_ = NULL;
const ::google::protobuf::Descriptor* NamedTensor_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  NamedTensor_reflection_ = NULL;
const ::google::protobuf::Descriptor* ExecutorOpts_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  ExecutorOpts_reflection_ = NULL;
const ::google::protobuf::Descriptor* RunGraphRequest_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  RunGraphRequest_reflection_ = NULL;
const ::google::protobuf::Descriptor* RunGraphResponse_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  RunGraphResponse_reflection_ = NULL;
const ::google::protobuf::Descriptor* CleanupGraphRequest_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  CleanupGraphRequest_reflection_ = NULL;
const ::google::protobuf::Descriptor* CleanupGraphResponse_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  CleanupGraphResponse_reflection_ = NULL;
const ::google::protobuf::Descriptor* RecvTensorRequest_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  RecvTensorRequest_reflection_ = NULL;
const ::google::protobuf::Descriptor* RecvTensorResponse_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  RecvTensorResponse_reflection_ = NULL;
const ::google::protobuf::Descriptor* LoggingRequest_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  LoggingRequest_reflection_ = NULL;
const ::google::protobuf::Descriptor* LabeledStepStats_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  LabeledStepStats_reflection_ = NULL;
const ::google::protobuf::Descriptor* LoggingResponse_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  LoggingResponse_reflection_ = NULL;
const ::google::protobuf::Descriptor* TraceOpts_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  TraceOpts_reflection_ = NULL;
const ::google::protobuf::Descriptor* TracingRequest_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  TracingRequest_reflection_ = NULL;
const ::google::protobuf::Descriptor* TracingResponse_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  TracingResponse_reflection_ = NULL;

}  // namespace


void protobuf_AssignDesc_tensorflow_2fcore_2fprotobuf_2fworker_2eproto() {
  protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fworker_2eproto();
  const ::google::protobuf::FileDescriptor* file =
    ::google::protobuf::DescriptorPool::generated_pool()->FindFileByName(
      "tensorflow/core/protobuf/worker.proto");
  GOOGLE_CHECK(file != NULL);
  GetStatusRequest_descriptor_ = file->message_type(0);
  static const int GetStatusRequest_offsets_[1] = {
  };
  GetStatusRequest_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      GetStatusRequest_descriptor_,
      GetStatusRequest::default_instance_,
      GetStatusRequest_offsets_,
      -1,
      -1,
      -1,
      sizeof(GetStatusRequest),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GetStatusRequest, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GetStatusRequest, _is_default_instance_));
  GetStatusResponse_descriptor_ = file->message_type(1);
  static const int GetStatusResponse_offsets_[1] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GetStatusResponse, device_attributes_),
  };
  GetStatusResponse_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      GetStatusResponse_descriptor_,
      GetStatusResponse::default_instance_,
      GetStatusResponse_offsets_,
      -1,
      -1,
      -1,
      sizeof(GetStatusResponse),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GetStatusResponse, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GetStatusResponse, _is_default_instance_));
  RegisterGraphRequest_descriptor_ = file->message_type(2);
  static const int RegisterGraphRequest_offsets_[4] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RegisterGraphRequest, session_handle_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RegisterGraphRequest, graph_def_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RegisterGraphRequest, has_control_flow_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RegisterGraphRequest, graph_options_),
  };
  RegisterGraphRequest_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      RegisterGraphRequest_descriptor_,
      RegisterGraphRequest::default_instance_,
      RegisterGraphRequest_offsets_,
      -1,
      -1,
      -1,
      sizeof(RegisterGraphRequest),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RegisterGraphRequest, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RegisterGraphRequest, _is_default_instance_));
  RegisterGraphResponse_descriptor_ = file->message_type(3);
  static const int RegisterGraphResponse_offsets_[1] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RegisterGraphResponse, graph_handle_),
  };
  RegisterGraphResponse_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      RegisterGraphResponse_descriptor_,
      RegisterGraphResponse::default_instance_,
      RegisterGraphResponse_offsets_,
      -1,
      -1,
      -1,
      sizeof(RegisterGraphResponse),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RegisterGraphResponse, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RegisterGraphResponse, _is_default_instance_));
  DeregisterGraphRequest_descriptor_ = file->message_type(4);
  static const int DeregisterGraphRequest_offsets_[1] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(DeregisterGraphRequest, graph_handle_),
  };
  DeregisterGraphRequest_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      DeregisterGraphRequest_descriptor_,
      DeregisterGraphRequest::default_instance_,
      DeregisterGraphRequest_offsets_,
      -1,
      -1,
      -1,
      sizeof(DeregisterGraphRequest),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(DeregisterGraphRequest, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(DeregisterGraphRequest, _is_default_instance_));
  DeregisterGraphResponse_descriptor_ = file->message_type(5);
  static const int DeregisterGraphResponse_offsets_[1] = {
  };
  DeregisterGraphResponse_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      DeregisterGraphResponse_descriptor_,
      DeregisterGraphResponse::default_instance_,
      DeregisterGraphResponse_offsets_,
      -1,
      -1,
      -1,
      sizeof(DeregisterGraphResponse),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(DeregisterGraphResponse, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(DeregisterGraphResponse, _is_default_instance_));
  CleanupAllRequest_descriptor_ = file->message_type(6);
  static const int CleanupAllRequest_offsets_[1] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CleanupAllRequest, container_),
  };
  CleanupAllRequest_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      CleanupAllRequest_descriptor_,
      CleanupAllRequest::default_instance_,
      CleanupAllRequest_offsets_,
      -1,
      -1,
      -1,
      sizeof(CleanupAllRequest),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CleanupAllRequest, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CleanupAllRequest, _is_default_instance_));
  CleanupAllResponse_descriptor_ = file->message_type(7);
  static const int CleanupAllResponse_offsets_[1] = {
  };
  CleanupAllResponse_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      CleanupAllResponse_descriptor_,
      CleanupAllResponse::default_instance_,
      CleanupAllResponse_offsets_,
      -1,
      -1,
      -1,
      sizeof(CleanupAllResponse),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CleanupAllResponse, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CleanupAllResponse, _is_default_instance_));
  NamedTensor_descriptor_ = file->message_type(8);
  static const int NamedTensor_offsets_[2] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NamedTensor, key_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NamedTensor, val_),
  };
  NamedTensor_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      NamedTensor_descriptor_,
      NamedTensor::default_instance_,
      NamedTensor_offsets_,
      -1,
      -1,
      -1,
      sizeof(NamedTensor),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NamedTensor, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NamedTensor, _is_default_instance_));
  ExecutorOpts_descriptor_ = file->message_type(9);
  static const int ExecutorOpts_offsets_[2] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ExecutorOpts, record_costs_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ExecutorOpts, record_timeline_),
  };
  ExecutorOpts_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      ExecutorOpts_descriptor_,
      ExecutorOpts::default_instance_,
      ExecutorOpts_offsets_,
      -1,
      -1,
      -1,
      sizeof(ExecutorOpts),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ExecutorOpts, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ExecutorOpts, _is_default_instance_));
  RunGraphRequest_descriptor_ = file->message_type(10);
  static const int RunGraphRequest_offsets_[5] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunGraphRequest, graph_handle_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunGraphRequest, step_id_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunGraphRequest, exec_opts_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunGraphRequest, send_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunGraphRequest, recv_key_),
  };
  RunGraphRequest_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      RunGraphRequest_descriptor_,
      RunGraphRequest::default_instance_,
      RunGraphRequest_offsets_,
      -1,
      -1,
      -1,
      sizeof(RunGraphRequest),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunGraphRequest, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunGraphRequest, _is_default_instance_));
  RunGraphResponse_descriptor_ = file->message_type(11);
  static const int RunGraphResponse_offsets_[2] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunGraphResponse, recv_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunGraphResponse, step_stats_),
  };
  RunGraphResponse_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      RunGraphResponse_descriptor_,
      RunGraphResponse::default_instance_,
      RunGraphResponse_offsets_,
      -1,
      -1,
      -1,
      sizeof(RunGraphResponse),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunGraphResponse, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunGraphResponse, _is_default_instance_));
  CleanupGraphRequest_descriptor_ = file->message_type(12);
  static const int CleanupGraphRequest_offsets_[1] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CleanupGraphRequest, step_id_),
  };
  CleanupGraphRequest_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      CleanupGraphRequest_descriptor_,
      CleanupGraphRequest::default_instance_,
      CleanupGraphRequest_offsets_,
      -1,
      -1,
      -1,
      sizeof(CleanupGraphRequest),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CleanupGraphRequest, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CleanupGraphRequest, _is_default_instance_));
  CleanupGraphResponse_descriptor_ = file->message_type(13);
  static const int CleanupGraphResponse_offsets_[1] = {
  };
  CleanupGraphResponse_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      CleanupGraphResponse_descriptor_,
      CleanupGraphResponse::default_instance_,
      CleanupGraphResponse_offsets_,
      -1,
      -1,
      -1,
      sizeof(CleanupGraphResponse),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CleanupGraphResponse, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CleanupGraphResponse, _is_default_instance_));
  RecvTensorRequest_descriptor_ = file->message_type(14);
  static const int RecvTensorRequest_offsets_[5] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RecvTensorRequest, step_id_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RecvTensorRequest, rendezvous_key_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RecvTensorRequest, dma_ok_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RecvTensorRequest, client_bus_adjacency_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RecvTensorRequest, server_bus_adjacency_),
  };
  RecvTensorRequest_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      RecvTensorRequest_descriptor_,
      RecvTensorRequest::default_instance_,
      RecvTensorRequest_offsets_,
      -1,
      -1,
      -1,
      sizeof(RecvTensorRequest),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RecvTensorRequest, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RecvTensorRequest, _is_default_instance_));
  RecvTensorResponse_descriptor_ = file->message_type(15);
  static const int RecvTensorResponse_offsets_[4] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RecvTensorResponse, tensor_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RecvTensorResponse, is_dead_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RecvTensorResponse, send_start_micros_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RecvTensorResponse, transport_options_),
  };
  RecvTensorResponse_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      RecvTensorResponse_descriptor_,
      RecvTensorResponse::default_instance_,
      RecvTensorResponse_offsets_,
      -1,
      -1,
      -1,
      sizeof(RecvTensorResponse),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RecvTensorResponse, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RecvTensorResponse, _is_default_instance_));
  LoggingRequest_descriptor_ = file->message_type(16);
  static const int LoggingRequest_offsets_[3] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(LoggingRequest, rpc_logging_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(LoggingRequest, clear_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(LoggingRequest, fetch_step_id_),
  };
  LoggingRequest_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      LoggingRequest_descriptor_,
      LoggingRequest::default_instance_,
      LoggingRequest_offsets_,
      -1,
      -1,
      -1,
      sizeof(LoggingRequest),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(LoggingRequest, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(LoggingRequest, _is_default_instance_));
  LabeledStepStats_descriptor_ = file->message_type(17);
  static const int LabeledStepStats_offsets_[2] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(LabeledStepStats, step_id_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(LabeledStepStats, step_stats_),
  };
  LabeledStepStats_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      LabeledStepStats_descriptor_,
      LabeledStepStats::default_instance_,
      LabeledStepStats_offsets_,
      -1,
      -1,
      -1,
      sizeof(LabeledStepStats),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(LabeledStepStats, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(LabeledStepStats, _is_default_instance_));
  LoggingResponse_descriptor_ = file->message_type(18);
  static const int LoggingResponse_offsets_[1] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(LoggingResponse, step_),
  };
  LoggingResponse_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      LoggingResponse_descriptor_,
      LoggingResponse::default_instance_,
      LoggingResponse_offsets_,
      -1,
      -1,
      -1,
      sizeof(LoggingResponse),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(LoggingResponse, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(LoggingResponse, _is_default_instance_));
  TraceOpts_descriptor_ = file->message_type(19);
  static const int TraceOpts_offsets_[6] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(TraceOpts, duration_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(TraceOpts, use_step_profiler_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(TraceOpts, use_kernel_profiler_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(TraceOpts, use_extended_profiler_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(TraceOpts, use_gpu_profiler_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(TraceOpts, use_sample_profiler_),
  };
  TraceOpts_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      TraceOpts_descriptor_,
      TraceOpts::default_instance_,
      TraceOpts_offsets_,
      -1,
      -1,
      -1,
      sizeof(TraceOpts),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(TraceOpts, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(TraceOpts, _is_default_instance_));
  TracingRequest_descriptor_ = file->message_type(20);
  static const int TracingRequest_offsets_[1] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(TracingRequest, options_),
  };
  TracingRequest_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      TracingRequest_descriptor_,
      TracingRequest::default_instance_,
      TracingRequest_offsets_,
      -1,
      -1,
      -1,
      sizeof(TracingRequest),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(TracingRequest, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(TracingRequest, _is_default_instance_));
  TracingResponse_descriptor_ = file->message_type(21);
  static const int TracingResponse_offsets_[1] = {
  };
  TracingResponse_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      TracingResponse_descriptor_,
      TracingResponse::default_instance_,
      TracingResponse_offsets_,
      -1,
      -1,
      -1,
      sizeof(TracingResponse),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(TracingResponse, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(TracingResponse, _is_default_instance_));
}

namespace {

GOOGLE_PROTOBUF_DECLARE_ONCE(protobuf_AssignDescriptors_once_);
inline void protobuf_AssignDescriptorsOnce() {
  ::google::protobuf::GoogleOnceInit(&protobuf_AssignDescriptors_once_,
                 &protobuf_AssignDesc_tensorflow_2fcore_2fprotobuf_2fworker_2eproto);
}

void protobuf_RegisterTypes(const ::std::string&) {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      GetStatusRequest_descriptor_, &GetStatusRequest::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      GetStatusResponse_descriptor_, &GetStatusResponse::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      RegisterGraphRequest_descriptor_, &RegisterGraphRequest::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      RegisterGraphResponse_descriptor_, &RegisterGraphResponse::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      DeregisterGraphRequest_descriptor_, &DeregisterGraphRequest::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      DeregisterGraphResponse_descriptor_, &DeregisterGraphResponse::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      CleanupAllRequest_descriptor_, &CleanupAllRequest::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      CleanupAllResponse_descriptor_, &CleanupAllResponse::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      NamedTensor_descriptor_, &NamedTensor::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      ExecutorOpts_descriptor_, &ExecutorOpts::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      RunGraphRequest_descriptor_, &RunGraphRequest::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      RunGraphResponse_descriptor_, &RunGraphResponse::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      CleanupGraphRequest_descriptor_, &CleanupGraphRequest::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      CleanupGraphResponse_descriptor_, &CleanupGraphResponse::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      RecvTensorRequest_descriptor_, &RecvTensorRequest::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      RecvTensorResponse_descriptor_, &RecvTensorResponse::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      LoggingRequest_descriptor_, &LoggingRequest::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      LabeledStepStats_descriptor_, &LabeledStepStats::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      LoggingResponse_descriptor_, &LoggingResponse::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      TraceOpts_descriptor_, &TraceOpts::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      TracingRequest_descriptor_, &TracingRequest::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      TracingResponse_descriptor_, &TracingResponse::default_instance());
}

}  // namespace

void protobuf_ShutdownFile_tensorflow_2fcore_2fprotobuf_2fworker_2eproto() {
  delete GetStatusRequest::default_instance_;
  delete GetStatusRequest_reflection_;
  delete GetStatusResponse::default_instance_;
  delete GetStatusResponse_reflection_;
  delete RegisterGraphRequest::default_instance_;
  delete RegisterGraphRequest_reflection_;
  delete RegisterGraphResponse::default_instance_;
  delete RegisterGraphResponse_reflection_;
  delete DeregisterGraphRequest::default_instance_;
  delete DeregisterGraphRequest_reflection_;
  delete DeregisterGraphResponse::default_instance_;
  delete DeregisterGraphResponse_reflection_;
  delete CleanupAllRequest::default_instance_;
  delete CleanupAllRequest_reflection_;
  delete CleanupAllResponse::default_instance_;
  delete CleanupAllResponse_reflection_;
  delete NamedTensor::default_instance_;
  delete NamedTensor_reflection_;
  delete ExecutorOpts::default_instance_;
  delete ExecutorOpts_reflection_;
  delete RunGraphRequest::default_instance_;
  delete RunGraphRequest_reflection_;
  delete RunGraphResponse::default_instance_;
  delete RunGraphResponse_reflection_;
  delete CleanupGraphRequest::default_instance_;
  delete CleanupGraphRequest_reflection_;
  delete CleanupGraphResponse::default_instance_;
  delete CleanupGraphResponse_reflection_;
  delete RecvTensorRequest::default_instance_;
  delete RecvTensorRequest_reflection_;
  delete RecvTensorResponse::default_instance_;
  delete RecvTensorResponse_reflection_;
  delete LoggingRequest::default_instance_;
  delete LoggingRequest_reflection_;
  delete LabeledStepStats::default_instance_;
  delete LabeledStepStats_reflection_;
  delete LoggingResponse::default_instance_;
  delete LoggingResponse_reflection_;
  delete TraceOpts::default_instance_;
  delete TraceOpts_reflection_;
  delete TracingRequest::default_instance_;
  delete TracingRequest_reflection_;
  delete TracingResponse::default_instance_;
  delete TracingResponse_reflection_;
}

void protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fworker_2eproto() {
  static bool already_here = false;
  if (already_here) return;
  already_here = true;
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  ::google::protobuf::protobuf_AddDesc_google_2fprotobuf_2fany_2eproto();
  ::tensorflow::protobuf_AddDesc_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto();
  ::tensorflow::protobuf_AddDesc_tensorflow_2fcore_2fframework_2fdevice_5fattributes_2eproto();
  ::tensorflow::protobuf_AddDesc_tensorflow_2fcore_2fframework_2fgraph_2eproto();
  ::tensorflow::protobuf_AddDesc_tensorflow_2fcore_2fframework_2ftensor_2eproto();
  ::tensorflow::protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto();
  ::google::protobuf::DescriptorPool::InternalAddGeneratedFile(
    "\n%tensorflow/core/protobuf/worker.proto\022"
    "\ntensorflow\032\031google/protobuf/any.proto\032*"
    "tensorflow/core/framework/step_stats.pro"
    "to\0321tensorflow/core/framework/device_att"
    "ributes.proto\032%tensorflow/core/framework"
    "/graph.proto\032&tensorflow/core/framework/"
    "tensor.proto\032%tensorflow/core/protobuf/c"
    "onfig.proto\"\022\n\020GetStatusRequest\"L\n\021GetSt"
    "atusResponse\0227\n\021device_attributes\030\001 \003(\0132"
    "\034.tensorflow.DeviceAttributes\"\246\001\n\024Regist"
    "erGraphRequest\022\026\n\016session_handle\030\001 \001(\t\022\'"
    "\n\tgraph_def\030\002 \001(\0132\024.tensorflow.GraphDef\022"
    "\034\n\020has_control_flow\030\003 \001(\010B\002\030\001\022/\n\rgraph_o"
    "ptions\030\004 \001(\0132\030.tensorflow.GraphOptions\"-"
    "\n\025RegisterGraphResponse\022\024\n\014graph_handle\030"
    "\001 \001(\t\".\n\026DeregisterGraphRequest\022\024\n\014graph"
    "_handle\030\001 \001(\t\"\031\n\027DeregisterGraphResponse"
    "\"&\n\021CleanupAllRequest\022\021\n\tcontainer\030\001 \003(\t"
    "\"\024\n\022CleanupAllResponse\"@\n\013NamedTensor\022\013\n"
    "\003key\030\001 \001(\t\022$\n\003val\030\002 \001(\0132\027.tensorflow.Ten"
    "sorProto\"=\n\014ExecutorOpts\022\024\n\014record_costs"
    "\030\001 \001(\010\022\027\n\017record_timeline\030\003 \001(\010\"\236\001\n\017RunG"
    "raphRequest\022\024\n\014graph_handle\030\001 \001(\t\022\017\n\007ste"
    "p_id\030\002 \001(\003\022+\n\texec_opts\030\005 \001(\0132\030.tensorfl"
    "ow.ExecutorOpts\022%\n\004send\030\003 \003(\0132\027.tensorfl"
    "ow.NamedTensor\022\020\n\010recv_key\030\004 \003(\t\"d\n\020RunG"
    "raphResponse\022%\n\004recv\030\001 \003(\0132\027.tensorflow."
    "NamedTensor\022)\n\nstep_stats\030\002 \001(\0132\025.tensor"
    "flow.StepStats\"&\n\023CleanupGraphRequest\022\017\n"
    "\007step_id\030\001 \001(\003\"\026\n\024CleanupGraphResponse\"\274"
    "\001\n\021RecvTensorRequest\022\017\n\007step_id\030\001 \001(\003\022\026\n"
    "\016rendezvous_key\030\002 \001(\t\022\016\n\006dma_ok\030\003 \001(\010\0226\n"
    "\024client_bus_adjacency\030\004 \001(\0162\030.tensorflow"
    ".BusAdjacency\0226\n\024server_bus_adjacency\030\005 "
    "\001(\0162\030.tensorflow.BusAdjacency\"\232\001\n\022RecvTe"
    "nsorResponse\022\'\n\006tensor\030\001 \001(\0132\027.tensorflo"
    "w.TensorProto\022\017\n\007is_dead\030\002 \001(\010\022\031\n\021send_s"
    "tart_micros\030\003 \001(\003\022/\n\021transport_options\030\004"
    " \001(\0132\024.google.protobuf.Any\"K\n\016LoggingReq"
    "uest\022\023\n\013rpc_logging\030\001 \001(\010\022\r\n\005clear\030\002 \001(\010"
    "\022\025\n\rfetch_step_id\030\003 \003(\003\"N\n\020LabeledStepSt"
    "ats\022\017\n\007step_id\030\001 \001(\003\022)\n\nstep_stats\030\002 \001(\013"
    "2\025.tensorflow.StepStats\"=\n\017LoggingRespon"
    "se\022*\n\004step\030\001 \003(\0132\034.tensorflow.LabeledSte"
    "pStats\"\253\001\n\tTraceOpts\022\020\n\010duration\030\001 \001(\001\022\031"
    "\n\021use_step_profiler\030\002 \001(\010\022\033\n\023use_kernel_"
    "profiler\030\003 \001(\010\022\035\n\025use_extended_profiler\030"
    "\004 \001(\010\022\030\n\020use_gpu_profiler\030\005 \001(\010\022\033\n\023use_s"
    "ample_profiler\030\006 \001(\010\"8\n\016TracingRequest\022&"
    "\n\007options\030\001 \001(\0132\025.tensorflow.TraceOpts\"\021"
    "\n\017TracingResponseB,\n\032org.tensorflow.dist"
    "runtimeB\014WorkerProtosP\001b\006proto3", 2071);
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedFile(
    "tensorflow/core/protobuf/worker.proto", &protobuf_RegisterTypes);
  GetStatusRequest::default_instance_ = new GetStatusRequest();
  GetStatusResponse::default_instance_ = new GetStatusResponse();
  RegisterGraphRequest::default_instance_ = new RegisterGraphRequest();
  RegisterGraphResponse::default_instance_ = new RegisterGraphResponse();
  DeregisterGraphRequest::default_instance_ = new DeregisterGraphRequest();
  DeregisterGraphResponse::default_instance_ = new DeregisterGraphResponse();
  CleanupAllRequest::default_instance_ = new CleanupAllRequest();
  CleanupAllResponse::default_instance_ = new CleanupAllResponse();
  NamedTensor::default_instance_ = new NamedTensor();
  ExecutorOpts::default_instance_ = new ExecutorOpts();
  RunGraphRequest::default_instance_ = new RunGraphRequest();
  RunGraphResponse::default_instance_ = new RunGraphResponse();
  CleanupGraphRequest::default_instance_ = new CleanupGraphRequest();
  CleanupGraphResponse::default_instance_ = new CleanupGraphResponse();
  RecvTensorRequest::default_instance_ = new RecvTensorRequest();
  RecvTensorResponse::default_instance_ = new RecvTensorResponse();
  LoggingRequest::default_instance_ = new LoggingRequest();
  LabeledStepStats::default_instance_ = new LabeledStepStats();
  LoggingResponse::default_instance_ = new LoggingResponse();
  TraceOpts::default_instance_ = new TraceOpts();
  TracingRequest::default_instance_ = new TracingRequest();
  TracingResponse::default_instance_ = new TracingResponse();
  GetStatusRequest::default_instance_->InitAsDefaultInstance();
  GetStatusResponse::default_instance_->InitAsDefaultInstance();
  RegisterGraphRequest::default_instance_->InitAsDefaultInstance();
  RegisterGraphResponse::default_instance_->InitAsDefaultInstance();
  DeregisterGraphRequest::default_instance_->InitAsDefaultInstance();
  DeregisterGraphResponse::default_instance_->InitAsDefaultInstance();
  CleanupAllRequest::default_instance_->InitAsDefaultInstance();
  CleanupAllResponse::default_instance_->InitAsDefaultInstance();
  NamedTensor::default_instance_->InitAsDefaultInstance();
  ExecutorOpts::default_instance_->InitAsDefaultInstance();
  RunGraphRequest::default_instance_->InitAsDefaultInstance();
  RunGraphResponse::default_instance_->InitAsDefaultInstance();
  CleanupGraphRequest::default_instance_->InitAsDefaultInstance();
  CleanupGraphResponse::default_instance_->InitAsDefaultInstance();
  RecvTensorRequest::default_instance_->InitAsDefaultInstance();
  RecvTensorResponse::default_instance_->InitAsDefaultInstance();
  LoggingRequest::default_instance_->InitAsDefaultInstance();
  LabeledStepStats::default_instance_->InitAsDefaultInstance();
  LoggingResponse::default_instance_->InitAsDefaultInstance();
  TraceOpts::default_instance_->InitAsDefaultInstance();
  TracingRequest::default_instance_->InitAsDefaultInstance();
  TracingResponse::default_instance_->InitAsDefaultInstance();
  ::google::protobuf::internal::OnShutdown(&protobuf_ShutdownFile_tensorflow_2fcore_2fprotobuf_2fworker_2eproto);
}

// Force AddDescriptors() to be called at static initialization time.
struct StaticDescriptorInitializer_tensorflow_2fcore_2fprotobuf_2fworker_2eproto {
  StaticDescriptorInitializer_tensorflow_2fcore_2fprotobuf_2fworker_2eproto() {
    protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fworker_2eproto();
  }
} static_descriptor_initializer_tensorflow_2fcore_2fprotobuf_2fworker_2eproto_;

namespace {

static void MergeFromFail(int line) GOOGLE_ATTRIBUTE_COLD;
static void MergeFromFail(int line) {
  GOOGLE_CHECK(false) << __FILE__ << ":" << line;
}

}  // namespace


// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

GetStatusRequest::GetStatusRequest()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.GetStatusRequest)
}

void GetStatusRequest::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

GetStatusRequest::GetStatusRequest(const GetStatusRequest& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.GetStatusRequest)
}

void GetStatusRequest::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
}

GetStatusRequest::~GetStatusRequest() {
  // @@protoc_insertion_point(destructor:tensorflow.GetStatusRequest)
  SharedDtor();
}

void GetStatusRequest::SharedDtor() {
  if (this != default_instance_) {
  }
}

void GetStatusRequest::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* GetStatusRequest::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return GetStatusRequest_descriptor_;
}

const GetStatusRequest& GetStatusRequest::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fworker_2eproto();
  return *default_instance_;
}

GetStatusRequest* GetStatusRequest::default_instance_ = NULL;

GetStatusRequest* GetStatusRequest::New(::google::protobuf::Arena* arena) const {
  GetStatusRequest* n = new GetStatusRequest;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void GetStatusRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.GetStatusRequest)
}

bool GetStatusRequest::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.GetStatusRequest)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
  handle_unusual:
    if (tag == 0 ||
        ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
        ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
      goto success;
    }
    DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.GetStatusRequest)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.GetStatusRequest)
  return false;
#undef DO_
}

void GetStatusRequest::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.GetStatusRequest)
  // @@protoc_insertion_point(serialize_end:tensorflow.GetStatusRequest)
}

::google::protobuf::uint8* GetStatusRequest::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.GetStatusRequest)
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.GetStatusRequest)
  return target;
}

int GetStatusRequest::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.GetStatusRequest)
  int total_size = 0;

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void GetStatusRequest::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.GetStatusRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const GetStatusRequest* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const GetStatusRequest>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.GetStatusRequest)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.GetStatusRequest)
    MergeFrom(*source);
  }
}

void GetStatusRequest::MergeFrom(const GetStatusRequest& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.GetStatusRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
}

void GetStatusRequest::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.GetStatusRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void GetStatusRequest::CopyFrom(const GetStatusRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.GetStatusRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool GetStatusRequest::IsInitialized() const {

  return true;
}

void GetStatusRequest::Swap(GetStatusRequest* other) {
  if (other == this) return;
  InternalSwap(other);
}
void GetStatusRequest::InternalSwap(GetStatusRequest* other) {
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata GetStatusRequest::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = GetStatusRequest_descriptor_;
  metadata.reflection = GetStatusRequest_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// GetStatusRequest

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int GetStatusResponse::kDeviceAttributesFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

GetStatusResponse::GetStatusResponse()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.GetStatusResponse)
}

void GetStatusResponse::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

GetStatusResponse::GetStatusResponse(const GetStatusResponse& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.GetStatusResponse)
}

void GetStatusResponse::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
}

GetStatusResponse::~GetStatusResponse() {
  // @@protoc_insertion_point(destructor:tensorflow.GetStatusResponse)
  SharedDtor();
}

void GetStatusResponse::SharedDtor() {
  if (this != default_instance_) {
  }
}

void GetStatusResponse::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* GetStatusResponse::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return GetStatusResponse_descriptor_;
}

const GetStatusResponse& GetStatusResponse::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fworker_2eproto();
  return *default_instance_;
}

GetStatusResponse* GetStatusResponse::default_instance_ = NULL;

GetStatusResponse* GetStatusResponse::New(::google::protobuf::Arena* arena) const {
  GetStatusResponse* n = new GetStatusResponse;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void GetStatusResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.GetStatusResponse)
  device_attributes_.Clear();
}

bool GetStatusResponse::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.GetStatusResponse)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // repeated .tensorflow.DeviceAttributes device_attributes = 1;
      case 1: {
        if (tag == 10) {
          DO_(input->IncrementRecursionDepth());
         parse_loop_device_attributes:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_device_attributes()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(10)) goto parse_loop_device_attributes;
        input->UnsafeDecrementRecursionDepth();
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.GetStatusResponse)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.GetStatusResponse)
  return false;
#undef DO_
}

void GetStatusResponse::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.GetStatusResponse)
  // repeated .tensorflow.DeviceAttributes device_attributes = 1;
  for (unsigned int i = 0, n = this->device_attributes_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, this->device_attributes(i), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.GetStatusResponse)
}

::google::protobuf::uint8* GetStatusResponse::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.GetStatusResponse)
  // repeated .tensorflow.DeviceAttributes device_attributes = 1;
  for (unsigned int i = 0, n = this->device_attributes_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        1, this->device_attributes(i), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.GetStatusResponse)
  return target;
}

int GetStatusResponse::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.GetStatusResponse)
  int total_size = 0;

  // repeated .tensorflow.DeviceAttributes device_attributes = 1;
  total_size += 1 * this->device_attributes_size();
  for (int i = 0; i < this->device_attributes_size(); i++) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        this->device_attributes(i));
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void GetStatusResponse::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.GetStatusResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const GetStatusResponse* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const GetStatusResponse>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.GetStatusResponse)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.GetStatusResponse)
    MergeFrom(*source);
  }
}

void GetStatusResponse::MergeFrom(const GetStatusResponse& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.GetStatusResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  device_attributes_.MergeFrom(from.device_attributes_);
}

void GetStatusResponse::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.GetStatusResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void GetStatusResponse::CopyFrom(const GetStatusResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.GetStatusResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool GetStatusResponse::IsInitialized() const {

  return true;
}

void GetStatusResponse::Swap(GetStatusResponse* other) {
  if (other == this) return;
  InternalSwap(other);
}
void GetStatusResponse::InternalSwap(GetStatusResponse* other) {
  device_attributes_.UnsafeArenaSwap(&other->device_attributes_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata GetStatusResponse::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = GetStatusResponse_descriptor_;
  metadata.reflection = GetStatusResponse_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// GetStatusResponse

// repeated .tensorflow.DeviceAttributes device_attributes = 1;
int GetStatusResponse::device_attributes_size() const {
  return device_attributes_.size();
}
void GetStatusResponse::clear_device_attributes() {
  device_attributes_.Clear();
}
const ::tensorflow::DeviceAttributes& GetStatusResponse::device_attributes(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.GetStatusResponse.device_attributes)
  return device_attributes_.Get(index);
}
::tensorflow::DeviceAttributes* GetStatusResponse::mutable_device_attributes(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.GetStatusResponse.device_attributes)
  return device_attributes_.Mutable(index);
}
::tensorflow::DeviceAttributes* GetStatusResponse::add_device_attributes() {
  // @@protoc_insertion_point(field_add:tensorflow.GetStatusResponse.device_attributes)
  return device_attributes_.Add();
}
::google::protobuf::RepeatedPtrField< ::tensorflow::DeviceAttributes >*
GetStatusResponse::mutable_device_attributes() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.GetStatusResponse.device_attributes)
  return &device_attributes_;
}
const ::google::protobuf::RepeatedPtrField< ::tensorflow::DeviceAttributes >&
GetStatusResponse::device_attributes() const {
  // @@protoc_insertion_point(field_list:tensorflow.GetStatusResponse.device_attributes)
  return device_attributes_;
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int RegisterGraphRequest::kSessionHandleFieldNumber;
const int RegisterGraphRequest::kGraphDefFieldNumber;
const int RegisterGraphRequest::kHasControlFlowFieldNumber;
const int RegisterGraphRequest::kGraphOptionsFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

RegisterGraphRequest::RegisterGraphRequest()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.RegisterGraphRequest)
}

void RegisterGraphRequest::InitAsDefaultInstance() {
  _is_default_instance_ = true;
  graph_def_ = const_cast< ::tensorflow::GraphDef*>(&::tensorflow::GraphDef::default_instance());
  graph_options_ = const_cast< ::tensorflow::GraphOptions*>(&::tensorflow::GraphOptions::default_instance());
}

RegisterGraphRequest::RegisterGraphRequest(const RegisterGraphRequest& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.RegisterGraphRequest)
}

void RegisterGraphRequest::SharedCtor() {
    _is_default_instance_ = false;
  ::google::protobuf::internal::GetEmptyString();
  _cached_size_ = 0;
  session_handle_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  graph_def_ = NULL;
  has_control_flow_ = false;
  graph_options_ = NULL;
}

RegisterGraphRequest::~RegisterGraphRequest() {
  // @@protoc_insertion_point(destructor:tensorflow.RegisterGraphRequest)
  SharedDtor();
}

void RegisterGraphRequest::SharedDtor() {
  session_handle_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (this != default_instance_) {
    delete graph_def_;
    delete graph_options_;
  }
}

void RegisterGraphRequest::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* RegisterGraphRequest::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return RegisterGraphRequest_descriptor_;
}

const RegisterGraphRequest& RegisterGraphRequest::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fworker_2eproto();
  return *default_instance_;
}

RegisterGraphRequest* RegisterGraphRequest::default_instance_ = NULL;

RegisterGraphRequest* RegisterGraphRequest::New(::google::protobuf::Arena* arena) const {
  RegisterGraphRequest* n = new RegisterGraphRequest;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void RegisterGraphRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.RegisterGraphRequest)
  session_handle_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (GetArenaNoVirtual() == NULL && graph_def_ != NULL) delete graph_def_;
  graph_def_ = NULL;
  has_control_flow_ = false;
  if (GetArenaNoVirtual() == NULL && graph_options_ != NULL) delete graph_options_;
  graph_options_ = NULL;
}

bool RegisterGraphRequest::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.RegisterGraphRequest)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional string session_handle = 1;
      case 1: {
        if (tag == 10) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_session_handle()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->session_handle().data(), this->session_handle().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.RegisterGraphRequest.session_handle"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_graph_def;
        break;
      }

      // optional .tensorflow.GraphDef graph_def = 2;
      case 2: {
        if (tag == 18) {
         parse_graph_def:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_graph_def()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(24)) goto parse_has_control_flow;
        break;
      }

      // optional bool has_control_flow = 3 [deprecated = true];
      case 3: {
        if (tag == 24) {
         parse_has_control_flow:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &has_control_flow_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(34)) goto parse_graph_options;
        break;
      }

      // optional .tensorflow.GraphOptions graph_options = 4;
      case 4: {
        if (tag == 34) {
         parse_graph_options:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_graph_options()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.RegisterGraphRequest)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.RegisterGraphRequest)
  return false;
#undef DO_
}

void RegisterGraphRequest::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.RegisterGraphRequest)
  // optional string session_handle = 1;
  if (this->session_handle().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->session_handle().data(), this->session_handle().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.RegisterGraphRequest.session_handle");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      1, this->session_handle(), output);
  }

  // optional .tensorflow.GraphDef graph_def = 2;
  if (this->has_graph_def()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, *this->graph_def_, output);
  }

  // optional bool has_control_flow = 3 [deprecated = true];
  if (this->has_control_flow() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(3, this->has_control_flow(), output);
  }

  // optional .tensorflow.GraphOptions graph_options = 4;
  if (this->has_graph_options()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      4, *this->graph_options_, output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.RegisterGraphRequest)
}

::google::protobuf::uint8* RegisterGraphRequest::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.RegisterGraphRequest)
  // optional string session_handle = 1;
  if (this->session_handle().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->session_handle().data(), this->session_handle().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.RegisterGraphRequest.session_handle");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        1, this->session_handle(), target);
  }

  // optional .tensorflow.GraphDef graph_def = 2;
  if (this->has_graph_def()) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        2, *this->graph_def_, target);
  }

  // optional bool has_control_flow = 3 [deprecated = true];
  if (this->has_control_flow() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(3, this->has_control_flow(), target);
  }

  // optional .tensorflow.GraphOptions graph_options = 4;
  if (this->has_graph_options()) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        4, *this->graph_options_, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.RegisterGraphRequest)
  return target;
}

int RegisterGraphRequest::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.RegisterGraphRequest)
  int total_size = 0;

  // optional string session_handle = 1;
  if (this->session_handle().size() > 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->session_handle());
  }

  // optional .tensorflow.GraphDef graph_def = 2;
  if (this->has_graph_def()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->graph_def_);
  }

  // optional bool has_control_flow = 3 [deprecated = true];
  if (this->has_control_flow() != 0) {
    total_size += 1 + 1;
  }

  // optional .tensorflow.GraphOptions graph_options = 4;
  if (this->has_graph_options()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->graph_options_);
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void RegisterGraphRequest::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.RegisterGraphRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const RegisterGraphRequest* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const RegisterGraphRequest>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.RegisterGraphRequest)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.RegisterGraphRequest)
    MergeFrom(*source);
  }
}

void RegisterGraphRequest::MergeFrom(const RegisterGraphRequest& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.RegisterGraphRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  if (from.session_handle().size() > 0) {

    session_handle_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.session_handle_);
  }
  if (from.has_graph_def()) {
    mutable_graph_def()->::tensorflow::GraphDef::MergeFrom(from.graph_def());
  }
  if (from.has_control_flow() != 0) {
    set_has_control_flow(from.has_control_flow());
  }
  if (from.has_graph_options()) {
    mutable_graph_options()->::tensorflow::GraphOptions::MergeFrom(from.graph_options());
  }
}

void RegisterGraphRequest::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.RegisterGraphRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void RegisterGraphRequest::CopyFrom(const RegisterGraphRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.RegisterGraphRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool RegisterGraphRequest::IsInitialized() const {

  return true;
}

void RegisterGraphRequest::Swap(RegisterGraphRequest* other) {
  if (other == this) return;
  InternalSwap(other);
}
void RegisterGraphRequest::InternalSwap(RegisterGraphRequest* other) {
  session_handle_.Swap(&other->session_handle_);
  std::swap(graph_def_, other->graph_def_);
  std::swap(has_control_flow_, other->has_control_flow_);
  std::swap(graph_options_, other->graph_options_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata RegisterGraphRequest::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = RegisterGraphRequest_descriptor_;
  metadata.reflection = RegisterGraphRequest_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// RegisterGraphRequest

// optional string session_handle = 1;
void RegisterGraphRequest::clear_session_handle() {
  session_handle_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 const ::std::string& RegisterGraphRequest::session_handle() const {
  // @@protoc_insertion_point(field_get:tensorflow.RegisterGraphRequest.session_handle)
  return session_handle_.GetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void RegisterGraphRequest::set_session_handle(const ::std::string& value) {
  
  session_handle_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:tensorflow.RegisterGraphRequest.session_handle)
}
 void RegisterGraphRequest::set_session_handle(const char* value) {
  
  session_handle_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:tensorflow.RegisterGraphRequest.session_handle)
}
 void RegisterGraphRequest::set_session_handle(const char* value, size_t size) {
  
  session_handle_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:tensorflow.RegisterGraphRequest.session_handle)
}
 ::std::string* RegisterGraphRequest::mutable_session_handle() {
  
  // @@protoc_insertion_point(field_mutable:tensorflow.RegisterGraphRequest.session_handle)
  return session_handle_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 ::std::string* RegisterGraphRequest::release_session_handle() {
  // @@protoc_insertion_point(field_release:tensorflow.RegisterGraphRequest.session_handle)
  
  return session_handle_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void RegisterGraphRequest::set_allocated_session_handle(::std::string* session_handle) {
  if (session_handle != NULL) {
    
  } else {
    
  }
  session_handle_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), session_handle);
  // @@protoc_insertion_point(field_set_allocated:tensorflow.RegisterGraphRequest.session_handle)
}

// optional .tensorflow.GraphDef graph_def = 2;
bool RegisterGraphRequest::has_graph_def() const {
  return !_is_default_instance_ && graph_def_ != NULL;
}
void RegisterGraphRequest::clear_graph_def() {
  if (GetArenaNoVirtual() == NULL && graph_def_ != NULL) delete graph_def_;
  graph_def_ = NULL;
}
const ::tensorflow::GraphDef& RegisterGraphRequest::graph_def() const {
  // @@protoc_insertion_point(field_get:tensorflow.RegisterGraphRequest.graph_def)
  return graph_def_ != NULL ? *graph_def_ : *default_instance_->graph_def_;
}
::tensorflow::GraphDef* RegisterGraphRequest::mutable_graph_def() {
  
  if (graph_def_ == NULL) {
    graph_def_ = new ::tensorflow::GraphDef;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.RegisterGraphRequest.graph_def)
  return graph_def_;
}
::tensorflow::GraphDef* RegisterGraphRequest::release_graph_def() {
  // @@protoc_insertion_point(field_release:tensorflow.RegisterGraphRequest.graph_def)
  
  ::tensorflow::GraphDef* temp = graph_def_;
  graph_def_ = NULL;
  return temp;
}
void RegisterGraphRequest::set_allocated_graph_def(::tensorflow::GraphDef* graph_def) {
  delete graph_def_;
  graph_def_ = graph_def;
  if (graph_def) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.RegisterGraphRequest.graph_def)
}

// optional bool has_control_flow = 3 [deprecated = true];
void RegisterGraphRequest::clear_has_control_flow() {
  has_control_flow_ = false;
}
 bool RegisterGraphRequest::has_control_flow() const {
  // @@protoc_insertion_point(field_get:tensorflow.RegisterGraphRequest.has_control_flow)
  return has_control_flow_;
}
 void RegisterGraphRequest::set_has_control_flow(bool value) {
  
  has_control_flow_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.RegisterGraphRequest.has_control_flow)
}

// optional .tensorflow.GraphOptions graph_options = 4;
bool RegisterGraphRequest::has_graph_options() const {
  return !_is_default_instance_ && graph_options_ != NULL;
}
void RegisterGraphRequest::clear_graph_options() {
  if (GetArenaNoVirtual() == NULL && graph_options_ != NULL) delete graph_options_;
  graph_options_ = NULL;
}
const ::tensorflow::GraphOptions& RegisterGraphRequest::graph_options() const {
  // @@protoc_insertion_point(field_get:tensorflow.RegisterGraphRequest.graph_options)
  return graph_options_ != NULL ? *graph_options_ : *default_instance_->graph_options_;
}
::tensorflow::GraphOptions* RegisterGraphRequest::mutable_graph_options() {
  
  if (graph_options_ == NULL) {
    graph_options_ = new ::tensorflow::GraphOptions;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.RegisterGraphRequest.graph_options)
  return graph_options_;
}
::tensorflow::GraphOptions* RegisterGraphRequest::release_graph_options() {
  // @@protoc_insertion_point(field_release:tensorflow.RegisterGraphRequest.graph_options)
  
  ::tensorflow::GraphOptions* temp = graph_options_;
  graph_options_ = NULL;
  return temp;
}
void RegisterGraphRequest::set_allocated_graph_options(::tensorflow::GraphOptions* graph_options) {
  delete graph_options_;
  graph_options_ = graph_options;
  if (graph_options) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.RegisterGraphRequest.graph_options)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int RegisterGraphResponse::kGraphHandleFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

RegisterGraphResponse::RegisterGraphResponse()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.RegisterGraphResponse)
}

void RegisterGraphResponse::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

RegisterGraphResponse::RegisterGraphResponse(const RegisterGraphResponse& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.RegisterGraphResponse)
}

void RegisterGraphResponse::SharedCtor() {
    _is_default_instance_ = false;
  ::google::protobuf::internal::GetEmptyString();
  _cached_size_ = 0;
  graph_handle_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}

RegisterGraphResponse::~RegisterGraphResponse() {
  // @@protoc_insertion_point(destructor:tensorflow.RegisterGraphResponse)
  SharedDtor();
}

void RegisterGraphResponse::SharedDtor() {
  graph_handle_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (this != default_instance_) {
  }
}

void RegisterGraphResponse::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* RegisterGraphResponse::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return RegisterGraphResponse_descriptor_;
}

const RegisterGraphResponse& RegisterGraphResponse::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fworker_2eproto();
  return *default_instance_;
}

RegisterGraphResponse* RegisterGraphResponse::default_instance_ = NULL;

RegisterGraphResponse* RegisterGraphResponse::New(::google::protobuf::Arena* arena) const {
  RegisterGraphResponse* n = new RegisterGraphResponse;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void RegisterGraphResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.RegisterGraphResponse)
  graph_handle_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}

bool RegisterGraphResponse::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.RegisterGraphResponse)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional string graph_handle = 1;
      case 1: {
        if (tag == 10) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_graph_handle()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->graph_handle().data(), this->graph_handle().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.RegisterGraphResponse.graph_handle"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.RegisterGraphResponse)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.RegisterGraphResponse)
  return false;
#undef DO_
}

void RegisterGraphResponse::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.RegisterGraphResponse)
  // optional string graph_handle = 1;
  if (this->graph_handle().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->graph_handle().data(), this->graph_handle().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.RegisterGraphResponse.graph_handle");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      1, this->graph_handle(), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.RegisterGraphResponse)
}

::google::protobuf::uint8* RegisterGraphResponse::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.RegisterGraphResponse)
  // optional string graph_handle = 1;
  if (this->graph_handle().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->graph_handle().data(), this->graph_handle().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.RegisterGraphResponse.graph_handle");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        1, this->graph_handle(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.RegisterGraphResponse)
  return target;
}

int RegisterGraphResponse::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.RegisterGraphResponse)
  int total_size = 0;

  // optional string graph_handle = 1;
  if (this->graph_handle().size() > 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->graph_handle());
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void RegisterGraphResponse::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.RegisterGraphResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const RegisterGraphResponse* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const RegisterGraphResponse>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.RegisterGraphResponse)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.RegisterGraphResponse)
    MergeFrom(*source);
  }
}

void RegisterGraphResponse::MergeFrom(const RegisterGraphResponse& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.RegisterGraphResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  if (from.graph_handle().size() > 0) {

    graph_handle_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.graph_handle_);
  }
}

void RegisterGraphResponse::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.RegisterGraphResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void RegisterGraphResponse::CopyFrom(const RegisterGraphResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.RegisterGraphResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool RegisterGraphResponse::IsInitialized() const {

  return true;
}

void RegisterGraphResponse::Swap(RegisterGraphResponse* other) {
  if (other == this) return;
  InternalSwap(other);
}
void RegisterGraphResponse::InternalSwap(RegisterGraphResponse* other) {
  graph_handle_.Swap(&other->graph_handle_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata RegisterGraphResponse::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = RegisterGraphResponse_descriptor_;
  metadata.reflection = RegisterGraphResponse_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// RegisterGraphResponse

// optional string graph_handle = 1;
void RegisterGraphResponse::clear_graph_handle() {
  graph_handle_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 const ::std::string& RegisterGraphResponse::graph_handle() const {
  // @@protoc_insertion_point(field_get:tensorflow.RegisterGraphResponse.graph_handle)
  return graph_handle_.GetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void RegisterGraphResponse::set_graph_handle(const ::std::string& value) {
  
  graph_handle_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:tensorflow.RegisterGraphResponse.graph_handle)
}
 void RegisterGraphResponse::set_graph_handle(const char* value) {
  
  graph_handle_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:tensorflow.RegisterGraphResponse.graph_handle)
}
 void RegisterGraphResponse::set_graph_handle(const char* value, size_t size) {
  
  graph_handle_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:tensorflow.RegisterGraphResponse.graph_handle)
}
 ::std::string* RegisterGraphResponse::mutable_graph_handle() {
  
  // @@protoc_insertion_point(field_mutable:tensorflow.RegisterGraphResponse.graph_handle)
  return graph_handle_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 ::std::string* RegisterGraphResponse::release_graph_handle() {
  // @@protoc_insertion_point(field_release:tensorflow.RegisterGraphResponse.graph_handle)
  
  return graph_handle_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void RegisterGraphResponse::set_allocated_graph_handle(::std::string* graph_handle) {
  if (graph_handle != NULL) {
    
  } else {
    
  }
  graph_handle_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), graph_handle);
  // @@protoc_insertion_point(field_set_allocated:tensorflow.RegisterGraphResponse.graph_handle)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int DeregisterGraphRequest::kGraphHandleFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

DeregisterGraphRequest::DeregisterGraphRequest()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.DeregisterGraphRequest)
}

void DeregisterGraphRequest::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

DeregisterGraphRequest::DeregisterGraphRequest(const DeregisterGraphRequest& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.DeregisterGraphRequest)
}

void DeregisterGraphRequest::SharedCtor() {
    _is_default_instance_ = false;
  ::google::protobuf::internal::GetEmptyString();
  _cached_size_ = 0;
  graph_handle_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}

DeregisterGraphRequest::~DeregisterGraphRequest() {
  // @@protoc_insertion_point(destructor:tensorflow.DeregisterGraphRequest)
  SharedDtor();
}

void DeregisterGraphRequest::SharedDtor() {
  graph_handle_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (this != default_instance_) {
  }
}

void DeregisterGraphRequest::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* DeregisterGraphRequest::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return DeregisterGraphRequest_descriptor_;
}

const DeregisterGraphRequest& DeregisterGraphRequest::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fworker_2eproto();
  return *default_instance_;
}

DeregisterGraphRequest* DeregisterGraphRequest::default_instance_ = NULL;

DeregisterGraphRequest* DeregisterGraphRequest::New(::google::protobuf::Arena* arena) const {
  DeregisterGraphRequest* n = new DeregisterGraphRequest;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void DeregisterGraphRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.DeregisterGraphRequest)
  graph_handle_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}

bool DeregisterGraphRequest::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.DeregisterGraphRequest)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional string graph_handle = 1;
      case 1: {
        if (tag == 10) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_graph_handle()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->graph_handle().data(), this->graph_handle().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.DeregisterGraphRequest.graph_handle"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.DeregisterGraphRequest)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.DeregisterGraphRequest)
  return false;
#undef DO_
}

void DeregisterGraphRequest::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.DeregisterGraphRequest)
  // optional string graph_handle = 1;
  if (this->graph_handle().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->graph_handle().data(), this->graph_handle().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.DeregisterGraphRequest.graph_handle");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      1, this->graph_handle(), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.DeregisterGraphRequest)
}

::google::protobuf::uint8* DeregisterGraphRequest::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.DeregisterGraphRequest)
  // optional string graph_handle = 1;
  if (this->graph_handle().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->graph_handle().data(), this->graph_handle().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.DeregisterGraphRequest.graph_handle");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        1, this->graph_handle(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.DeregisterGraphRequest)
  return target;
}

int DeregisterGraphRequest::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.DeregisterGraphRequest)
  int total_size = 0;

  // optional string graph_handle = 1;
  if (this->graph_handle().size() > 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->graph_handle());
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void DeregisterGraphRequest::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.DeregisterGraphRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const DeregisterGraphRequest* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const DeregisterGraphRequest>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.DeregisterGraphRequest)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.DeregisterGraphRequest)
    MergeFrom(*source);
  }
}

void DeregisterGraphRequest::MergeFrom(const DeregisterGraphRequest& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.DeregisterGraphRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  if (from.graph_handle().size() > 0) {

    graph_handle_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.graph_handle_);
  }
}

void DeregisterGraphRequest::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.DeregisterGraphRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void DeregisterGraphRequest::CopyFrom(const DeregisterGraphRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.DeregisterGraphRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool DeregisterGraphRequest::IsInitialized() const {

  return true;
}

void DeregisterGraphRequest::Swap(DeregisterGraphRequest* other) {
  if (other == this) return;
  InternalSwap(other);
}
void DeregisterGraphRequest::InternalSwap(DeregisterGraphRequest* other) {
  graph_handle_.Swap(&other->graph_handle_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata DeregisterGraphRequest::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = DeregisterGraphRequest_descriptor_;
  metadata.reflection = DeregisterGraphRequest_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// DeregisterGraphRequest

// optional string graph_handle = 1;
void DeregisterGraphRequest::clear_graph_handle() {
  graph_handle_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 const ::std::string& DeregisterGraphRequest::graph_handle() const {
  // @@protoc_insertion_point(field_get:tensorflow.DeregisterGraphRequest.graph_handle)
  return graph_handle_.GetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void DeregisterGraphRequest::set_graph_handle(const ::std::string& value) {
  
  graph_handle_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:tensorflow.DeregisterGraphRequest.graph_handle)
}
 void DeregisterGraphRequest::set_graph_handle(const char* value) {
  
  graph_handle_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:tensorflow.DeregisterGraphRequest.graph_handle)
}
 void DeregisterGraphRequest::set_graph_handle(const char* value, size_t size) {
  
  graph_handle_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:tensorflow.DeregisterGraphRequest.graph_handle)
}
 ::std::string* DeregisterGraphRequest::mutable_graph_handle() {
  
  // @@protoc_insertion_point(field_mutable:tensorflow.DeregisterGraphRequest.graph_handle)
  return graph_handle_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 ::std::string* DeregisterGraphRequest::release_graph_handle() {
  // @@protoc_insertion_point(field_release:tensorflow.DeregisterGraphRequest.graph_handle)
  
  return graph_handle_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void DeregisterGraphRequest::set_allocated_graph_handle(::std::string* graph_handle) {
  if (graph_handle != NULL) {
    
  } else {
    
  }
  graph_handle_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), graph_handle);
  // @@protoc_insertion_point(field_set_allocated:tensorflow.DeregisterGraphRequest.graph_handle)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

DeregisterGraphResponse::DeregisterGraphResponse()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.DeregisterGraphResponse)
}

void DeregisterGraphResponse::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

DeregisterGraphResponse::DeregisterGraphResponse(const DeregisterGraphResponse& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.DeregisterGraphResponse)
}

void DeregisterGraphResponse::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
}

DeregisterGraphResponse::~DeregisterGraphResponse() {
  // @@protoc_insertion_point(destructor:tensorflow.DeregisterGraphResponse)
  SharedDtor();
}

void DeregisterGraphResponse::SharedDtor() {
  if (this != default_instance_) {
  }
}

void DeregisterGraphResponse::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* DeregisterGraphResponse::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return DeregisterGraphResponse_descriptor_;
}

const DeregisterGraphResponse& DeregisterGraphResponse::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fworker_2eproto();
  return *default_instance_;
}

DeregisterGraphResponse* DeregisterGraphResponse::default_instance_ = NULL;

DeregisterGraphResponse* DeregisterGraphResponse::New(::google::protobuf::Arena* arena) const {
  DeregisterGraphResponse* n = new DeregisterGraphResponse;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void DeregisterGraphResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.DeregisterGraphResponse)
}

bool DeregisterGraphResponse::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.DeregisterGraphResponse)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
  handle_unusual:
    if (tag == 0 ||
        ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
        ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
      goto success;
    }
    DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.DeregisterGraphResponse)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.DeregisterGraphResponse)
  return false;
#undef DO_
}

void DeregisterGraphResponse::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.DeregisterGraphResponse)
  // @@protoc_insertion_point(serialize_end:tensorflow.DeregisterGraphResponse)
}

::google::protobuf::uint8* DeregisterGraphResponse::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.DeregisterGraphResponse)
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.DeregisterGraphResponse)
  return target;
}

int DeregisterGraphResponse::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.DeregisterGraphResponse)
  int total_size = 0;

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void DeregisterGraphResponse::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.DeregisterGraphResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const DeregisterGraphResponse* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const DeregisterGraphResponse>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.DeregisterGraphResponse)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.DeregisterGraphResponse)
    MergeFrom(*source);
  }
}

void DeregisterGraphResponse::MergeFrom(const DeregisterGraphResponse& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.DeregisterGraphResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
}

void DeregisterGraphResponse::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.DeregisterGraphResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void DeregisterGraphResponse::CopyFrom(const DeregisterGraphResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.DeregisterGraphResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool DeregisterGraphResponse::IsInitialized() const {

  return true;
}

void DeregisterGraphResponse::Swap(DeregisterGraphResponse* other) {
  if (other == this) return;
  InternalSwap(other);
}
void DeregisterGraphResponse::InternalSwap(DeregisterGraphResponse* other) {
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata DeregisterGraphResponse::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = DeregisterGraphResponse_descriptor_;
  metadata.reflection = DeregisterGraphResponse_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// DeregisterGraphResponse

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int CleanupAllRequest::kContainerFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

CleanupAllRequest::CleanupAllRequest()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.CleanupAllRequest)
}

void CleanupAllRequest::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

CleanupAllRequest::CleanupAllRequest(const CleanupAllRequest& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.CleanupAllRequest)
}

void CleanupAllRequest::SharedCtor() {
    _is_default_instance_ = false;
  ::google::protobuf::internal::GetEmptyString();
  _cached_size_ = 0;
}

CleanupAllRequest::~CleanupAllRequest() {
  // @@protoc_insertion_point(destructor:tensorflow.CleanupAllRequest)
  SharedDtor();
}

void CleanupAllRequest::SharedDtor() {
  if (this != default_instance_) {
  }
}

void CleanupAllRequest::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* CleanupAllRequest::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return CleanupAllRequest_descriptor_;
}

const CleanupAllRequest& CleanupAllRequest::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fworker_2eproto();
  return *default_instance_;
}

CleanupAllRequest* CleanupAllRequest::default_instance_ = NULL;

CleanupAllRequest* CleanupAllRequest::New(::google::protobuf::Arena* arena) const {
  CleanupAllRequest* n = new CleanupAllRequest;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void CleanupAllRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.CleanupAllRequest)
  container_.Clear();
}

bool CleanupAllRequest::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.CleanupAllRequest)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // repeated string container = 1;
      case 1: {
        if (tag == 10) {
         parse_container:
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->add_container()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->container(this->container_size() - 1).data(),
            this->container(this->container_size() - 1).length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.CleanupAllRequest.container"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(10)) goto parse_container;
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.CleanupAllRequest)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.CleanupAllRequest)
  return false;
#undef DO_
}

void CleanupAllRequest::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.CleanupAllRequest)
  // repeated string container = 1;
  for (int i = 0; i < this->container_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->container(i).data(), this->container(i).length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.CleanupAllRequest.container");
    ::google::protobuf::internal::WireFormatLite::WriteString(
      1, this->container(i), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.CleanupAllRequest)
}

::google::protobuf::uint8* CleanupAllRequest::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.CleanupAllRequest)
  // repeated string container = 1;
  for (int i = 0; i < this->container_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->container(i).data(), this->container(i).length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.CleanupAllRequest.container");
    target = ::google::protobuf::internal::WireFormatLite::
      WriteStringToArray(1, this->container(i), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.CleanupAllRequest)
  return target;
}

int CleanupAllRequest::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.CleanupAllRequest)
  int total_size = 0;

  // repeated string container = 1;
  total_size += 1 * this->container_size();
  for (int i = 0; i < this->container_size(); i++) {
    total_size += ::google::protobuf::internal::WireFormatLite::StringSize(
      this->container(i));
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void CleanupAllRequest::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.CleanupAllRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const CleanupAllRequest* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const CleanupAllRequest>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.CleanupAllRequest)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.CleanupAllRequest)
    MergeFrom(*source);
  }
}

void CleanupAllRequest::MergeFrom(const CleanupAllRequest& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.CleanupAllRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  container_.MergeFrom(from.container_);
}

void CleanupAllRequest::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.CleanupAllRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void CleanupAllRequest::CopyFrom(const CleanupAllRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.CleanupAllRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool CleanupAllRequest::IsInitialized() const {

  return true;
}

void CleanupAllRequest::Swap(CleanupAllRequest* other) {
  if (other == this) return;
  InternalSwap(other);
}
void CleanupAllRequest::InternalSwap(CleanupAllRequest* other) {
  container_.UnsafeArenaSwap(&other->container_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata CleanupAllRequest::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = CleanupAllRequest_descriptor_;
  metadata.reflection = CleanupAllRequest_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// CleanupAllRequest

// repeated string container = 1;
int CleanupAllRequest::container_size() const {
  return container_.size();
}
void CleanupAllRequest::clear_container() {
  container_.Clear();
}
 const ::std::string& CleanupAllRequest::container(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.CleanupAllRequest.container)
  return container_.Get(index);
}
 ::std::string* CleanupAllRequest::mutable_container(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.CleanupAllRequest.container)
  return container_.Mutable(index);
}
 void CleanupAllRequest::set_container(int index, const ::std::string& value) {
  // @@protoc_insertion_point(field_set:tensorflow.CleanupAllRequest.container)
  container_.Mutable(index)->assign(value);
}
 void CleanupAllRequest::set_container(int index, const char* value) {
  container_.Mutable(index)->assign(value);
  // @@protoc_insertion_point(field_set_char:tensorflow.CleanupAllRequest.container)
}
 void CleanupAllRequest::set_container(int index, const char* value, size_t size) {
  container_.Mutable(index)->assign(
    reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:tensorflow.CleanupAllRequest.container)
}
 ::std::string* CleanupAllRequest::add_container() {
  // @@protoc_insertion_point(field_add_mutable:tensorflow.CleanupAllRequest.container)
  return container_.Add();
}
 void CleanupAllRequest::add_container(const ::std::string& value) {
  container_.Add()->assign(value);
  // @@protoc_insertion_point(field_add:tensorflow.CleanupAllRequest.container)
}
 void CleanupAllRequest::add_container(const char* value) {
  container_.Add()->assign(value);
  // @@protoc_insertion_point(field_add_char:tensorflow.CleanupAllRequest.container)
}
 void CleanupAllRequest::add_container(const char* value, size_t size) {
  container_.Add()->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_add_pointer:tensorflow.CleanupAllRequest.container)
}
 const ::google::protobuf::RepeatedPtrField< ::std::string>&
CleanupAllRequest::container() const {
  // @@protoc_insertion_point(field_list:tensorflow.CleanupAllRequest.container)
  return container_;
}
 ::google::protobuf::RepeatedPtrField< ::std::string>*
CleanupAllRequest::mutable_container() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.CleanupAllRequest.container)
  return &container_;
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

CleanupAllResponse::CleanupAllResponse()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.CleanupAllResponse)
}

void CleanupAllResponse::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

CleanupAllResponse::CleanupAllResponse(const CleanupAllResponse& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.CleanupAllResponse)
}

void CleanupAllResponse::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
}

CleanupAllResponse::~CleanupAllResponse() {
  // @@protoc_insertion_point(destructor:tensorflow.CleanupAllResponse)
  SharedDtor();
}

void CleanupAllResponse::SharedDtor() {
  if (this != default_instance_) {
  }
}

void CleanupAllResponse::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* CleanupAllResponse::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return CleanupAllResponse_descriptor_;
}

const CleanupAllResponse& CleanupAllResponse::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fworker_2eproto();
  return *default_instance_;
}

CleanupAllResponse* CleanupAllResponse::default_instance_ = NULL;

CleanupAllResponse* CleanupAllResponse::New(::google::protobuf::Arena* arena) const {
  CleanupAllResponse* n = new CleanupAllResponse;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void CleanupAllResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.CleanupAllResponse)
}

bool CleanupAllResponse::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.CleanupAllResponse)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
  handle_unusual:
    if (tag == 0 ||
        ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
        ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
      goto success;
    }
    DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.CleanupAllResponse)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.CleanupAllResponse)
  return false;
#undef DO_
}

void CleanupAllResponse::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.CleanupAllResponse)
  // @@protoc_insertion_point(serialize_end:tensorflow.CleanupAllResponse)
}

::google::protobuf::uint8* CleanupAllResponse::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.CleanupAllResponse)
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.CleanupAllResponse)
  return target;
}

int CleanupAllResponse::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.CleanupAllResponse)
  int total_size = 0;

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void CleanupAllResponse::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.CleanupAllResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const CleanupAllResponse* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const CleanupAllResponse>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.CleanupAllResponse)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.CleanupAllResponse)
    MergeFrom(*source);
  }
}

void CleanupAllResponse::MergeFrom(const CleanupAllResponse& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.CleanupAllResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
}

void CleanupAllResponse::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.CleanupAllResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void CleanupAllResponse::CopyFrom(const CleanupAllResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.CleanupAllResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool CleanupAllResponse::IsInitialized() const {

  return true;
}

void CleanupAllResponse::Swap(CleanupAllResponse* other) {
  if (other == this) return;
  InternalSwap(other);
}
void CleanupAllResponse::InternalSwap(CleanupAllResponse* other) {
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata CleanupAllResponse::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = CleanupAllResponse_descriptor_;
  metadata.reflection = CleanupAllResponse_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// CleanupAllResponse

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int NamedTensor::kKeyFieldNumber;
const int NamedTensor::kValFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

NamedTensor::NamedTensor()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.NamedTensor)
}

void NamedTensor::InitAsDefaultInstance() {
  _is_default_instance_ = true;
  val_ = const_cast< ::tensorflow::TensorProto*>(&::tensorflow::TensorProto::default_instance());
}

NamedTensor::NamedTensor(const NamedTensor& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.NamedTensor)
}

void NamedTensor::SharedCtor() {
    _is_default_instance_ = false;
  ::google::protobuf::internal::GetEmptyString();
  _cached_size_ = 0;
  key_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  val_ = NULL;
}

NamedTensor::~NamedTensor() {
  // @@protoc_insertion_point(destructor:tensorflow.NamedTensor)
  SharedDtor();
}

void NamedTensor::SharedDtor() {
  key_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (this != default_instance_) {
    delete val_;
  }
}

void NamedTensor::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* NamedTensor::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return NamedTensor_descriptor_;
}

const NamedTensor& NamedTensor::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fworker_2eproto();
  return *default_instance_;
}

NamedTensor* NamedTensor::default_instance_ = NULL;

NamedTensor* NamedTensor::New(::google::protobuf::Arena* arena) const {
  NamedTensor* n = new NamedTensor;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void NamedTensor::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.NamedTensor)
  key_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (GetArenaNoVirtual() == NULL && val_ != NULL) delete val_;
  val_ = NULL;
}

bool NamedTensor::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.NamedTensor)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional string key = 1;
      case 1: {
        if (tag == 10) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_key()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->key().data(), this->key().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.NamedTensor.key"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_val;
        break;
      }

      // optional .tensorflow.TensorProto val = 2;
      case 2: {
        if (tag == 18) {
         parse_val:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_val()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.NamedTensor)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.NamedTensor)
  return false;
#undef DO_
}

void NamedTensor::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.NamedTensor)
  // optional string key = 1;
  if (this->key().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->key().data(), this->key().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.NamedTensor.key");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      1, this->key(), output);
  }

  // optional .tensorflow.TensorProto val = 2;
  if (this->has_val()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, *this->val_, output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.NamedTensor)
}

::google::protobuf::uint8* NamedTensor::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.NamedTensor)
  // optional string key = 1;
  if (this->key().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->key().data(), this->key().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.NamedTensor.key");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        1, this->key(), target);
  }

  // optional .tensorflow.TensorProto val = 2;
  if (this->has_val()) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        2, *this->val_, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.NamedTensor)
  return target;
}

int NamedTensor::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.NamedTensor)
  int total_size = 0;

  // optional string key = 1;
  if (this->key().size() > 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->key());
  }

  // optional .tensorflow.TensorProto val = 2;
  if (this->has_val()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->val_);
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void NamedTensor::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.NamedTensor)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const NamedTensor* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const NamedTensor>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.NamedTensor)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.NamedTensor)
    MergeFrom(*source);
  }
}

void NamedTensor::MergeFrom(const NamedTensor& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.NamedTensor)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  if (from.key().size() > 0) {

    key_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.key_);
  }
  if (from.has_val()) {
    mutable_val()->::tensorflow::TensorProto::MergeFrom(from.val());
  }
}

void NamedTensor::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.NamedTensor)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void NamedTensor::CopyFrom(const NamedTensor& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.NamedTensor)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool NamedTensor::IsInitialized() const {

  return true;
}

void NamedTensor::Swap(NamedTensor* other) {
  if (other == this) return;
  InternalSwap(other);
}
void NamedTensor::InternalSwap(NamedTensor* other) {
  key_.Swap(&other->key_);
  std::swap(val_, other->val_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata NamedTensor::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = NamedTensor_descriptor_;
  metadata.reflection = NamedTensor_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// NamedTensor

// optional string key = 1;
void NamedTensor::clear_key() {
  key_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 const ::std::string& NamedTensor::key() const {
  // @@protoc_insertion_point(field_get:tensorflow.NamedTensor.key)
  return key_.GetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void NamedTensor::set_key(const ::std::string& value) {
  
  key_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:tensorflow.NamedTensor.key)
}
 void NamedTensor::set_key(const char* value) {
  
  key_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:tensorflow.NamedTensor.key)
}
 void NamedTensor::set_key(const char* value, size_t size) {
  
  key_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:tensorflow.NamedTensor.key)
}
 ::std::string* NamedTensor::mutable_key() {
  
  // @@protoc_insertion_point(field_mutable:tensorflow.NamedTensor.key)
  return key_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 ::std::string* NamedTensor::release_key() {
  // @@protoc_insertion_point(field_release:tensorflow.NamedTensor.key)
  
  return key_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void NamedTensor::set_allocated_key(::std::string* key) {
  if (key != NULL) {
    
  } else {
    
  }
  key_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), key);
  // @@protoc_insertion_point(field_set_allocated:tensorflow.NamedTensor.key)
}

// optional .tensorflow.TensorProto val = 2;
bool NamedTensor::has_val() const {
  return !_is_default_instance_ && val_ != NULL;
}
void NamedTensor::clear_val() {
  if (GetArenaNoVirtual() == NULL && val_ != NULL) delete val_;
  val_ = NULL;
}
const ::tensorflow::TensorProto& NamedTensor::val() const {
  // @@protoc_insertion_point(field_get:tensorflow.NamedTensor.val)
  return val_ != NULL ? *val_ : *default_instance_->val_;
}
::tensorflow::TensorProto* NamedTensor::mutable_val() {
  
  if (val_ == NULL) {
    val_ = new ::tensorflow::TensorProto;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.NamedTensor.val)
  return val_;
}
::tensorflow::TensorProto* NamedTensor::release_val() {
  // @@protoc_insertion_point(field_release:tensorflow.NamedTensor.val)
  
  ::tensorflow::TensorProto* temp = val_;
  val_ = NULL;
  return temp;
}
void NamedTensor::set_allocated_val(::tensorflow::TensorProto* val) {
  delete val_;
  val_ = val;
  if (val) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.NamedTensor.val)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int ExecutorOpts::kRecordCostsFieldNumber;
const int ExecutorOpts::kRecordTimelineFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

ExecutorOpts::ExecutorOpts()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.ExecutorOpts)
}

void ExecutorOpts::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

ExecutorOpts::ExecutorOpts(const ExecutorOpts& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.ExecutorOpts)
}

void ExecutorOpts::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  record_costs_ = false;
  record_timeline_ = false;
}

ExecutorOpts::~ExecutorOpts() {
  // @@protoc_insertion_point(destructor:tensorflow.ExecutorOpts)
  SharedDtor();
}

void ExecutorOpts::SharedDtor() {
  if (this != default_instance_) {
  }
}

void ExecutorOpts::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* ExecutorOpts::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return ExecutorOpts_descriptor_;
}

const ExecutorOpts& ExecutorOpts::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fworker_2eproto();
  return *default_instance_;
}

ExecutorOpts* ExecutorOpts::default_instance_ = NULL;

ExecutorOpts* ExecutorOpts::New(::google::protobuf::Arena* arena) const {
  ExecutorOpts* n = new ExecutorOpts;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void ExecutorOpts::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.ExecutorOpts)
#if defined(__clang__)
#define ZR_HELPER_(f) \
  _Pragma("clang diagnostic push") \
  _Pragma("clang diagnostic ignored \"-Winvalid-offsetof\"") \
  __builtin_offsetof(ExecutorOpts, f) \
  _Pragma("clang diagnostic pop")
#else
#define ZR_HELPER_(f) reinterpret_cast<char*>(\
  &reinterpret_cast<ExecutorOpts*>(16)->f)
#endif

#define ZR_(first, last) do {\
  ::memset(&first, 0,\
           ZR_HELPER_(last) - ZR_HELPER_(first) + sizeof(last));\
} while (0)

  ZR_(record_costs_, record_timeline_);

#undef ZR_HELPER_
#undef ZR_

}

bool ExecutorOpts::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.ExecutorOpts)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional bool record_costs = 1;
      case 1: {
        if (tag == 8) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &record_costs_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(24)) goto parse_record_timeline;
        break;
      }

      // optional bool record_timeline = 3;
      case 3: {
        if (tag == 24) {
         parse_record_timeline:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &record_timeline_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.ExecutorOpts)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.ExecutorOpts)
  return false;
#undef DO_
}

void ExecutorOpts::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.ExecutorOpts)
  // optional bool record_costs = 1;
  if (this->record_costs() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(1, this->record_costs(), output);
  }

  // optional bool record_timeline = 3;
  if (this->record_timeline() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(3, this->record_timeline(), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.ExecutorOpts)
}

::google::protobuf::uint8* ExecutorOpts::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.ExecutorOpts)
  // optional bool record_costs = 1;
  if (this->record_costs() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(1, this->record_costs(), target);
  }

  // optional bool record_timeline = 3;
  if (this->record_timeline() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(3, this->record_timeline(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.ExecutorOpts)
  return target;
}

int ExecutorOpts::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.ExecutorOpts)
  int total_size = 0;

  // optional bool record_costs = 1;
  if (this->record_costs() != 0) {
    total_size += 1 + 1;
  }

  // optional bool record_timeline = 3;
  if (this->record_timeline() != 0) {
    total_size += 1 + 1;
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void ExecutorOpts::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.ExecutorOpts)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const ExecutorOpts* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const ExecutorOpts>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.ExecutorOpts)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.ExecutorOpts)
    MergeFrom(*source);
  }
}

void ExecutorOpts::MergeFrom(const ExecutorOpts& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.ExecutorOpts)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  if (from.record_costs() != 0) {
    set_record_costs(from.record_costs());
  }
  if (from.record_timeline() != 0) {
    set_record_timeline(from.record_timeline());
  }
}

void ExecutorOpts::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.ExecutorOpts)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void ExecutorOpts::CopyFrom(const ExecutorOpts& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.ExecutorOpts)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ExecutorOpts::IsInitialized() const {

  return true;
}

void ExecutorOpts::Swap(ExecutorOpts* other) {
  if (other == this) return;
  InternalSwap(other);
}
void ExecutorOpts::InternalSwap(ExecutorOpts* other) {
  std::swap(record_costs_, other->record_costs_);
  std::swap(record_timeline_, other->record_timeline_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata ExecutorOpts::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = ExecutorOpts_descriptor_;
  metadata.reflection = ExecutorOpts_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// ExecutorOpts

// optional bool record_costs = 1;
void ExecutorOpts::clear_record_costs() {
  record_costs_ = false;
}
 bool ExecutorOpts::record_costs() const {
  // @@protoc_insertion_point(field_get:tensorflow.ExecutorOpts.record_costs)
  return record_costs_;
}
 void ExecutorOpts::set_record_costs(bool value) {
  
  record_costs_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.ExecutorOpts.record_costs)
}

// optional bool record_timeline = 3;
void ExecutorOpts::clear_record_timeline() {
  record_timeline_ = false;
}
 bool ExecutorOpts::record_timeline() const {
  // @@protoc_insertion_point(field_get:tensorflow.ExecutorOpts.record_timeline)
  return record_timeline_;
}
 void ExecutorOpts::set_record_timeline(bool value) {
  
  record_timeline_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.ExecutorOpts.record_timeline)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int RunGraphRequest::kGraphHandleFieldNumber;
const int RunGraphRequest::kStepIdFieldNumber;
const int RunGraphRequest::kExecOptsFieldNumber;
const int RunGraphRequest::kSendFieldNumber;
const int RunGraphRequest::kRecvKeyFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

RunGraphRequest::RunGraphRequest()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.RunGraphRequest)
}

void RunGraphRequest::InitAsDefaultInstance() {
  _is_default_instance_ = true;
  exec_opts_ = const_cast< ::tensorflow::ExecutorOpts*>(&::tensorflow::ExecutorOpts::default_instance());
}

RunGraphRequest::RunGraphRequest(const RunGraphRequest& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.RunGraphRequest)
}

void RunGraphRequest::SharedCtor() {
    _is_default_instance_ = false;
  ::google::protobuf::internal::GetEmptyString();
  _cached_size_ = 0;
  graph_handle_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  step_id_ = GOOGLE_LONGLONG(0);
  exec_opts_ = NULL;
}

RunGraphRequest::~RunGraphRequest() {
  // @@protoc_insertion_point(destructor:tensorflow.RunGraphRequest)
  SharedDtor();
}

void RunGraphRequest::SharedDtor() {
  graph_handle_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (this != default_instance_) {
    delete exec_opts_;
  }
}

void RunGraphRequest::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* RunGraphRequest::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return RunGraphRequest_descriptor_;
}

const RunGraphRequest& RunGraphRequest::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fworker_2eproto();
  return *default_instance_;
}

RunGraphRequest* RunGraphRequest::default_instance_ = NULL;

RunGraphRequest* RunGraphRequest::New(::google::protobuf::Arena* arena) const {
  RunGraphRequest* n = new RunGraphRequest;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void RunGraphRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.RunGraphRequest)
  graph_handle_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  step_id_ = GOOGLE_LONGLONG(0);
  if (GetArenaNoVirtual() == NULL && exec_opts_ != NULL) delete exec_opts_;
  exec_opts_ = NULL;
  send_.Clear();
  recv_key_.Clear();
}

bool RunGraphRequest::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.RunGraphRequest)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional string graph_handle = 1;
      case 1: {
        if (tag == 10) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_graph_handle()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->graph_handle().data(), this->graph_handle().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.RunGraphRequest.graph_handle"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(16)) goto parse_step_id;
        break;
      }

      // optional int64 step_id = 2;
      case 2: {
        if (tag == 16) {
         parse_step_id:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 input, &step_id_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(26)) goto parse_send;
        break;
      }

      // repeated .tensorflow.NamedTensor send = 3;
      case 3: {
        if (tag == 26) {
         parse_send:
          DO_(input->IncrementRecursionDepth());
         parse_loop_send:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_send()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(26)) goto parse_loop_send;
        input->UnsafeDecrementRecursionDepth();
        if (input->ExpectTag(34)) goto parse_recv_key;
        break;
      }

      // repeated string recv_key = 4;
      case 4: {
        if (tag == 34) {
         parse_recv_key:
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->add_recv_key()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->recv_key(this->recv_key_size() - 1).data(),
            this->recv_key(this->recv_key_size() - 1).length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.RunGraphRequest.recv_key"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(34)) goto parse_recv_key;
        if (input->ExpectTag(42)) goto parse_exec_opts;
        break;
      }

      // optional .tensorflow.ExecutorOpts exec_opts = 5;
      case 5: {
        if (tag == 42) {
         parse_exec_opts:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_exec_opts()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.RunGraphRequest)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.RunGraphRequest)
  return false;
#undef DO_
}

void RunGraphRequest::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.RunGraphRequest)
  // optional string graph_handle = 1;
  if (this->graph_handle().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->graph_handle().data(), this->graph_handle().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.RunGraphRequest.graph_handle");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      1, this->graph_handle(), output);
  }

  // optional int64 step_id = 2;
  if (this->step_id() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt64(2, this->step_id(), output);
  }

  // repeated .tensorflow.NamedTensor send = 3;
  for (unsigned int i = 0, n = this->send_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      3, this->send(i), output);
  }

  // repeated string recv_key = 4;
  for (int i = 0; i < this->recv_key_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->recv_key(i).data(), this->recv_key(i).length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.RunGraphRequest.recv_key");
    ::google::protobuf::internal::WireFormatLite::WriteString(
      4, this->recv_key(i), output);
  }

  // optional .tensorflow.ExecutorOpts exec_opts = 5;
  if (this->has_exec_opts()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      5, *this->exec_opts_, output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.RunGraphRequest)
}

::google::protobuf::uint8* RunGraphRequest::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.RunGraphRequest)
  // optional string graph_handle = 1;
  if (this->graph_handle().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->graph_handle().data(), this->graph_handle().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.RunGraphRequest.graph_handle");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        1, this->graph_handle(), target);
  }

  // optional int64 step_id = 2;
  if (this->step_id() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt64ToArray(2, this->step_id(), target);
  }

  // repeated .tensorflow.NamedTensor send = 3;
  for (unsigned int i = 0, n = this->send_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        3, this->send(i), target);
  }

  // repeated string recv_key = 4;
  for (int i = 0; i < this->recv_key_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->recv_key(i).data(), this->recv_key(i).length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.RunGraphRequest.recv_key");
    target = ::google::protobuf::internal::WireFormatLite::
      WriteStringToArray(4, this->recv_key(i), target);
  }

  // optional .tensorflow.ExecutorOpts exec_opts = 5;
  if (this->has_exec_opts()) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        5, *this->exec_opts_, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.RunGraphRequest)
  return target;
}

int RunGraphRequest::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.RunGraphRequest)
  int total_size = 0;

  // optional string graph_handle = 1;
  if (this->graph_handle().size() > 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->graph_handle());
  }

  // optional int64 step_id = 2;
  if (this->step_id() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int64Size(
        this->step_id());
  }

  // optional .tensorflow.ExecutorOpts exec_opts = 5;
  if (this->has_exec_opts()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->exec_opts_);
  }

  // repeated .tensorflow.NamedTensor send = 3;
  total_size += 1 * this->send_size();
  for (int i = 0; i < this->send_size(); i++) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        this->send(i));
  }

  // repeated string recv_key = 4;
  total_size += 1 * this->recv_key_size();
  for (int i = 0; i < this->recv_key_size(); i++) {
    total_size += ::google::protobuf::internal::WireFormatLite::StringSize(
      this->recv_key(i));
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void RunGraphRequest::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.RunGraphRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const RunGraphRequest* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const RunGraphRequest>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.RunGraphRequest)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.RunGraphRequest)
    MergeFrom(*source);
  }
}

void RunGraphRequest::MergeFrom(const RunGraphRequest& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.RunGraphRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  send_.MergeFrom(from.send_);
  recv_key_.MergeFrom(from.recv_key_);
  if (from.graph_handle().size() > 0) {

    graph_handle_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.graph_handle_);
  }
  if (from.step_id() != 0) {
    set_step_id(from.step_id());
  }
  if (from.has_exec_opts()) {
    mutable_exec_opts()->::tensorflow::ExecutorOpts::MergeFrom(from.exec_opts());
  }
}

void RunGraphRequest::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.RunGraphRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void RunGraphRequest::CopyFrom(const RunGraphRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.RunGraphRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool RunGraphRequest::IsInitialized() const {

  return true;
}

void RunGraphRequest::Swap(RunGraphRequest* other) {
  if (other == this) return;
  InternalSwap(other);
}
void RunGraphRequest::InternalSwap(RunGraphRequest* other) {
  graph_handle_.Swap(&other->graph_handle_);
  std::swap(step_id_, other->step_id_);
  std::swap(exec_opts_, other->exec_opts_);
  send_.UnsafeArenaSwap(&other->send_);
  recv_key_.UnsafeArenaSwap(&other->recv_key_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata RunGraphRequest::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = RunGraphRequest_descriptor_;
  metadata.reflection = RunGraphRequest_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// RunGraphRequest

// optional string graph_handle = 1;
void RunGraphRequest::clear_graph_handle() {
  graph_handle_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 const ::std::string& RunGraphRequest::graph_handle() const {
  // @@protoc_insertion_point(field_get:tensorflow.RunGraphRequest.graph_handle)
  return graph_handle_.GetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void RunGraphRequest::set_graph_handle(const ::std::string& value) {
  
  graph_handle_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:tensorflow.RunGraphRequest.graph_handle)
}
 void RunGraphRequest::set_graph_handle(const char* value) {
  
  graph_handle_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:tensorflow.RunGraphRequest.graph_handle)
}
 void RunGraphRequest::set_graph_handle(const char* value, size_t size) {
  
  graph_handle_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:tensorflow.RunGraphRequest.graph_handle)
}
 ::std::string* RunGraphRequest::mutable_graph_handle() {
  
  // @@protoc_insertion_point(field_mutable:tensorflow.RunGraphRequest.graph_handle)
  return graph_handle_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 ::std::string* RunGraphRequest::release_graph_handle() {
  // @@protoc_insertion_point(field_release:tensorflow.RunGraphRequest.graph_handle)
  
  return graph_handle_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void RunGraphRequest::set_allocated_graph_handle(::std::string* graph_handle) {
  if (graph_handle != NULL) {
    
  } else {
    
  }
  graph_handle_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), graph_handle);
  // @@protoc_insertion_point(field_set_allocated:tensorflow.RunGraphRequest.graph_handle)
}

// optional int64 step_id = 2;
void RunGraphRequest::clear_step_id() {
  step_id_ = GOOGLE_LONGLONG(0);
}
 ::google::protobuf::int64 RunGraphRequest::step_id() const {
  // @@protoc_insertion_point(field_get:tensorflow.RunGraphRequest.step_id)
  return step_id_;
}
 void RunGraphRequest::set_step_id(::google::protobuf::int64 value) {
  
  step_id_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.RunGraphRequest.step_id)
}

// optional .tensorflow.ExecutorOpts exec_opts = 5;
bool RunGraphRequest::has_exec_opts() const {
  return !_is_default_instance_ && exec_opts_ != NULL;
}
void RunGraphRequest::clear_exec_opts() {
  if (GetArenaNoVirtual() == NULL && exec_opts_ != NULL) delete exec_opts_;
  exec_opts_ = NULL;
}
const ::tensorflow::ExecutorOpts& RunGraphRequest::exec_opts() const {
  // @@protoc_insertion_point(field_get:tensorflow.RunGraphRequest.exec_opts)
  return exec_opts_ != NULL ? *exec_opts_ : *default_instance_->exec_opts_;
}
::tensorflow::ExecutorOpts* RunGraphRequest::mutable_exec_opts() {
  
  if (exec_opts_ == NULL) {
    exec_opts_ = new ::tensorflow::ExecutorOpts;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.RunGraphRequest.exec_opts)
  return exec_opts_;
}
::tensorflow::ExecutorOpts* RunGraphRequest::release_exec_opts() {
  // @@protoc_insertion_point(field_release:tensorflow.RunGraphRequest.exec_opts)
  
  ::tensorflow::ExecutorOpts* temp = exec_opts_;
  exec_opts_ = NULL;
  return temp;
}
void RunGraphRequest::set_allocated_exec_opts(::tensorflow::ExecutorOpts* exec_opts) {
  delete exec_opts_;
  exec_opts_ = exec_opts;
  if (exec_opts) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.RunGraphRequest.exec_opts)
}

// repeated .tensorflow.NamedTensor send = 3;
int RunGraphRequest::send_size() const {
  return send_.size();
}
void RunGraphRequest::clear_send() {
  send_.Clear();
}
const ::tensorflow::NamedTensor& RunGraphRequest::send(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.RunGraphRequest.send)
  return send_.Get(index);
}
::tensorflow::NamedTensor* RunGraphRequest::mutable_send(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.RunGraphRequest.send)
  return send_.Mutable(index);
}
::tensorflow::NamedTensor* RunGraphRequest::add_send() {
  // @@protoc_insertion_point(field_add:tensorflow.RunGraphRequest.send)
  return send_.Add();
}
::google::protobuf::RepeatedPtrField< ::tensorflow::NamedTensor >*
RunGraphRequest::mutable_send() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.RunGraphRequest.send)
  return &send_;
}
const ::google::protobuf::RepeatedPtrField< ::tensorflow::NamedTensor >&
RunGraphRequest::send() const {
  // @@protoc_insertion_point(field_list:tensorflow.RunGraphRequest.send)
  return send_;
}

// repeated string recv_key = 4;
int RunGraphRequest::recv_key_size() const {
  return recv_key_.size();
}
void RunGraphRequest::clear_recv_key() {
  recv_key_.Clear();
}
 const ::std::string& RunGraphRequest::recv_key(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.RunGraphRequest.recv_key)
  return recv_key_.Get(index);
}
 ::std::string* RunGraphRequest::mutable_recv_key(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.RunGraphRequest.recv_key)
  return recv_key_.Mutable(index);
}
 void RunGraphRequest::set_recv_key(int index, const ::std::string& value) {
  // @@protoc_insertion_point(field_set:tensorflow.RunGraphRequest.recv_key)
  recv_key_.Mutable(index)->assign(value);
}
 void RunGraphRequest::set_recv_key(int index, const char* value) {
  recv_key_.Mutable(index)->assign(value);
  // @@protoc_insertion_point(field_set_char:tensorflow.RunGraphRequest.recv_key)
}
 void RunGraphRequest::set_recv_key(int index, const char* value, size_t size) {
  recv_key_.Mutable(index)->assign(
    reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:tensorflow.RunGraphRequest.recv_key)
}
 ::std::string* RunGraphRequest::add_recv_key() {
  // @@protoc_insertion_point(field_add_mutable:tensorflow.RunGraphRequest.recv_key)
  return recv_key_.Add();
}
 void RunGraphRequest::add_recv_key(const ::std::string& value) {
  recv_key_.Add()->assign(value);
  // @@protoc_insertion_point(field_add:tensorflow.RunGraphRequest.recv_key)
}
 void RunGraphRequest::add_recv_key(const char* value) {
  recv_key_.Add()->assign(value);
  // @@protoc_insertion_point(field_add_char:tensorflow.RunGraphRequest.recv_key)
}
 void RunGraphRequest::add_recv_key(const char* value, size_t size) {
  recv_key_.Add()->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_add_pointer:tensorflow.RunGraphRequest.recv_key)
}
 const ::google::protobuf::RepeatedPtrField< ::std::string>&
RunGraphRequest::recv_key() const {
  // @@protoc_insertion_point(field_list:tensorflow.RunGraphRequest.recv_key)
  return recv_key_;
}
 ::google::protobuf::RepeatedPtrField< ::std::string>*
RunGraphRequest::mutable_recv_key() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.RunGraphRequest.recv_key)
  return &recv_key_;
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int RunGraphResponse::kRecvFieldNumber;
const int RunGraphResponse::kStepStatsFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

RunGraphResponse::RunGraphResponse()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.RunGraphResponse)
}

void RunGraphResponse::InitAsDefaultInstance() {
  _is_default_instance_ = true;
  step_stats_ = const_cast< ::tensorflow::StepStats*>(&::tensorflow::StepStats::default_instance());
}

RunGraphResponse::RunGraphResponse(const RunGraphResponse& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.RunGraphResponse)
}

void RunGraphResponse::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  step_stats_ = NULL;
}

RunGraphResponse::~RunGraphResponse() {
  // @@protoc_insertion_point(destructor:tensorflow.RunGraphResponse)
  SharedDtor();
}

void RunGraphResponse::SharedDtor() {
  if (this != default_instance_) {
    delete step_stats_;
  }
}

void RunGraphResponse::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* RunGraphResponse::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return RunGraphResponse_descriptor_;
}

const RunGraphResponse& RunGraphResponse::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fworker_2eproto();
  return *default_instance_;
}

RunGraphResponse* RunGraphResponse::default_instance_ = NULL;

RunGraphResponse* RunGraphResponse::New(::google::protobuf::Arena* arena) const {
  RunGraphResponse* n = new RunGraphResponse;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void RunGraphResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.RunGraphResponse)
  if (GetArenaNoVirtual() == NULL && step_stats_ != NULL) delete step_stats_;
  step_stats_ = NULL;
  recv_.Clear();
}

bool RunGraphResponse::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.RunGraphResponse)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // repeated .tensorflow.NamedTensor recv = 1;
      case 1: {
        if (tag == 10) {
          DO_(input->IncrementRecursionDepth());
         parse_loop_recv:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_recv()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(10)) goto parse_loop_recv;
        input->UnsafeDecrementRecursionDepth();
        if (input->ExpectTag(18)) goto parse_step_stats;
        break;
      }

      // optional .tensorflow.StepStats step_stats = 2;
      case 2: {
        if (tag == 18) {
         parse_step_stats:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_step_stats()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.RunGraphResponse)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.RunGraphResponse)
  return false;
#undef DO_
}

void RunGraphResponse::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.RunGraphResponse)
  // repeated .tensorflow.NamedTensor recv = 1;
  for (unsigned int i = 0, n = this->recv_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, this->recv(i), output);
  }

  // optional .tensorflow.StepStats step_stats = 2;
  if (this->has_step_stats()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, *this->step_stats_, output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.RunGraphResponse)
}

::google::protobuf::uint8* RunGraphResponse::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.RunGraphResponse)
  // repeated .tensorflow.NamedTensor recv = 1;
  for (unsigned int i = 0, n = this->recv_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        1, this->recv(i), target);
  }

  // optional .tensorflow.StepStats step_stats = 2;
  if (this->has_step_stats()) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        2, *this->step_stats_, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.RunGraphResponse)
  return target;
}

int RunGraphResponse::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.RunGraphResponse)
  int total_size = 0;

  // optional .tensorflow.StepStats step_stats = 2;
  if (this->has_step_stats()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->step_stats_);
  }

  // repeated .tensorflow.NamedTensor recv = 1;
  total_size += 1 * this->recv_size();
  for (int i = 0; i < this->recv_size(); i++) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        this->recv(i));
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void RunGraphResponse::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.RunGraphResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const RunGraphResponse* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const RunGraphResponse>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.RunGraphResponse)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.RunGraphResponse)
    MergeFrom(*source);
  }
}

void RunGraphResponse::MergeFrom(const RunGraphResponse& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.RunGraphResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  recv_.MergeFrom(from.recv_);
  if (from.has_step_stats()) {
    mutable_step_stats()->::tensorflow::StepStats::MergeFrom(from.step_stats());
  }
}

void RunGraphResponse::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.RunGraphResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void RunGraphResponse::CopyFrom(const RunGraphResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.RunGraphResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool RunGraphResponse::IsInitialized() const {

  return true;
}

void RunGraphResponse::Swap(RunGraphResponse* other) {
  if (other == this) return;
  InternalSwap(other);
}
void RunGraphResponse::InternalSwap(RunGraphResponse* other) {
  recv_.UnsafeArenaSwap(&other->recv_);
  std::swap(step_stats_, other->step_stats_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata RunGraphResponse::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = RunGraphResponse_descriptor_;
  metadata.reflection = RunGraphResponse_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// RunGraphResponse

// repeated .tensorflow.NamedTensor recv = 1;
int RunGraphResponse::recv_size() const {
  return recv_.size();
}
void RunGraphResponse::clear_recv() {
  recv_.Clear();
}
const ::tensorflow::NamedTensor& RunGraphResponse::recv(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.RunGraphResponse.recv)
  return recv_.Get(index);
}
::tensorflow::NamedTensor* RunGraphResponse::mutable_recv(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.RunGraphResponse.recv)
  return recv_.Mutable(index);
}
::tensorflow::NamedTensor* RunGraphResponse::add_recv() {
  // @@protoc_insertion_point(field_add:tensorflow.RunGraphResponse.recv)
  return recv_.Add();
}
::google::protobuf::RepeatedPtrField< ::tensorflow::NamedTensor >*
RunGraphResponse::mutable_recv() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.RunGraphResponse.recv)
  return &recv_;
}
const ::google::protobuf::RepeatedPtrField< ::tensorflow::NamedTensor >&
RunGraphResponse::recv() const {
  // @@protoc_insertion_point(field_list:tensorflow.RunGraphResponse.recv)
  return recv_;
}

// optional .tensorflow.StepStats step_stats = 2;
bool RunGraphResponse::has_step_stats() const {
  return !_is_default_instance_ && step_stats_ != NULL;
}
void RunGraphResponse::clear_step_stats() {
  if (GetArenaNoVirtual() == NULL && step_stats_ != NULL) delete step_stats_;
  step_stats_ = NULL;
}
const ::tensorflow::StepStats& RunGraphResponse::step_stats() const {
  // @@protoc_insertion_point(field_get:tensorflow.RunGraphResponse.step_stats)
  return step_stats_ != NULL ? *step_stats_ : *default_instance_->step_stats_;
}
::tensorflow::StepStats* RunGraphResponse::mutable_step_stats() {
  
  if (step_stats_ == NULL) {
    step_stats_ = new ::tensorflow::StepStats;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.RunGraphResponse.step_stats)
  return step_stats_;
}
::tensorflow::StepStats* RunGraphResponse::release_step_stats() {
  // @@protoc_insertion_point(field_release:tensorflow.RunGraphResponse.step_stats)
  
  ::tensorflow::StepStats* temp = step_stats_;
  step_stats_ = NULL;
  return temp;
}
void RunGraphResponse::set_allocated_step_stats(::tensorflow::StepStats* step_stats) {
  delete step_stats_;
  step_stats_ = step_stats;
  if (step_stats) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.RunGraphResponse.step_stats)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int CleanupGraphRequest::kStepIdFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

CleanupGraphRequest::CleanupGraphRequest()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.CleanupGraphRequest)
}

void CleanupGraphRequest::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

CleanupGraphRequest::CleanupGraphRequest(const CleanupGraphRequest& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.CleanupGraphRequest)
}

void CleanupGraphRequest::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  step_id_ = GOOGLE_LONGLONG(0);
}

CleanupGraphRequest::~CleanupGraphRequest() {
  // @@protoc_insertion_point(destructor:tensorflow.CleanupGraphRequest)
  SharedDtor();
}

void CleanupGraphRequest::SharedDtor() {
  if (this != default_instance_) {
  }
}

void CleanupGraphRequest::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* CleanupGraphRequest::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return CleanupGraphRequest_descriptor_;
}

const CleanupGraphRequest& CleanupGraphRequest::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fworker_2eproto();
  return *default_instance_;
}

CleanupGraphRequest* CleanupGraphRequest::default_instance_ = NULL;

CleanupGraphRequest* CleanupGraphRequest::New(::google::protobuf::Arena* arena) const {
  CleanupGraphRequest* n = new CleanupGraphRequest;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void CleanupGraphRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.CleanupGraphRequest)
  step_id_ = GOOGLE_LONGLONG(0);
}

bool CleanupGraphRequest::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.CleanupGraphRequest)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional int64 step_id = 1;
      case 1: {
        if (tag == 8) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 input, &step_id_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.CleanupGraphRequest)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.CleanupGraphRequest)
  return false;
#undef DO_
}

void CleanupGraphRequest::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.CleanupGraphRequest)
  // optional int64 step_id = 1;
  if (this->step_id() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt64(1, this->step_id(), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.CleanupGraphRequest)
}

::google::protobuf::uint8* CleanupGraphRequest::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.CleanupGraphRequest)
  // optional int64 step_id = 1;
  if (this->step_id() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt64ToArray(1, this->step_id(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.CleanupGraphRequest)
  return target;
}

int CleanupGraphRequest::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.CleanupGraphRequest)
  int total_size = 0;

  // optional int64 step_id = 1;
  if (this->step_id() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int64Size(
        this->step_id());
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void CleanupGraphRequest::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.CleanupGraphRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const CleanupGraphRequest* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const CleanupGraphRequest>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.CleanupGraphRequest)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.CleanupGraphRequest)
    MergeFrom(*source);
  }
}

void CleanupGraphRequest::MergeFrom(const CleanupGraphRequest& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.CleanupGraphRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  if (from.step_id() != 0) {
    set_step_id(from.step_id());
  }
}

void CleanupGraphRequest::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.CleanupGraphRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void CleanupGraphRequest::CopyFrom(const CleanupGraphRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.CleanupGraphRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool CleanupGraphRequest::IsInitialized() const {

  return true;
}

void CleanupGraphRequest::Swap(CleanupGraphRequest* other) {
  if (other == this) return;
  InternalSwap(other);
}
void CleanupGraphRequest::InternalSwap(CleanupGraphRequest* other) {
  std::swap(step_id_, other->step_id_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata CleanupGraphRequest::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = CleanupGraphRequest_descriptor_;
  metadata.reflection = CleanupGraphRequest_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// CleanupGraphRequest

// optional int64 step_id = 1;
void CleanupGraphRequest::clear_step_id() {
  step_id_ = GOOGLE_LONGLONG(0);
}
 ::google::protobuf::int64 CleanupGraphRequest::step_id() const {
  // @@protoc_insertion_point(field_get:tensorflow.CleanupGraphRequest.step_id)
  return step_id_;
}
 void CleanupGraphRequest::set_step_id(::google::protobuf::int64 value) {
  
  step_id_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.CleanupGraphRequest.step_id)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

CleanupGraphResponse::CleanupGraphResponse()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.CleanupGraphResponse)
}

void CleanupGraphResponse::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

CleanupGraphResponse::CleanupGraphResponse(const CleanupGraphResponse& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.CleanupGraphResponse)
}

void CleanupGraphResponse::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
}

CleanupGraphResponse::~CleanupGraphResponse() {
  // @@protoc_insertion_point(destructor:tensorflow.CleanupGraphResponse)
  SharedDtor();
}

void CleanupGraphResponse::SharedDtor() {
  if (this != default_instance_) {
  }
}

void CleanupGraphResponse::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* CleanupGraphResponse::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return CleanupGraphResponse_descriptor_;
}

const CleanupGraphResponse& CleanupGraphResponse::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fworker_2eproto();
  return *default_instance_;
}

CleanupGraphResponse* CleanupGraphResponse::default_instance_ = NULL;

CleanupGraphResponse* CleanupGraphResponse::New(::google::protobuf::Arena* arena) const {
  CleanupGraphResponse* n = new CleanupGraphResponse;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void CleanupGraphResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.CleanupGraphResponse)
}

bool CleanupGraphResponse::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.CleanupGraphResponse)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
  handle_unusual:
    if (tag == 0 ||
        ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
        ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
      goto success;
    }
    DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.CleanupGraphResponse)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.CleanupGraphResponse)
  return false;
#undef DO_
}

void CleanupGraphResponse::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.CleanupGraphResponse)
  // @@protoc_insertion_point(serialize_end:tensorflow.CleanupGraphResponse)
}

::google::protobuf::uint8* CleanupGraphResponse::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.CleanupGraphResponse)
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.CleanupGraphResponse)
  return target;
}

int CleanupGraphResponse::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.CleanupGraphResponse)
  int total_size = 0;

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void CleanupGraphResponse::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.CleanupGraphResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const CleanupGraphResponse* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const CleanupGraphResponse>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.CleanupGraphResponse)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.CleanupGraphResponse)
    MergeFrom(*source);
  }
}

void CleanupGraphResponse::MergeFrom(const CleanupGraphResponse& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.CleanupGraphResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
}

void CleanupGraphResponse::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.CleanupGraphResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void CleanupGraphResponse::CopyFrom(const CleanupGraphResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.CleanupGraphResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool CleanupGraphResponse::IsInitialized() const {

  return true;
}

void CleanupGraphResponse::Swap(CleanupGraphResponse* other) {
  if (other == this) return;
  InternalSwap(other);
}
void CleanupGraphResponse::InternalSwap(CleanupGraphResponse* other) {
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata CleanupGraphResponse::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = CleanupGraphResponse_descriptor_;
  metadata.reflection = CleanupGraphResponse_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// CleanupGraphResponse

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int RecvTensorRequest::kStepIdFieldNumber;
const int RecvTensorRequest::kRendezvousKeyFieldNumber;
const int RecvTensorRequest::kDmaOkFieldNumber;
const int RecvTensorRequest::kClientBusAdjacencyFieldNumber;
const int RecvTensorRequest::kServerBusAdjacencyFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

RecvTensorRequest::RecvTensorRequest()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.RecvTensorRequest)
}

void RecvTensorRequest::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

RecvTensorRequest::RecvTensorRequest(const RecvTensorRequest& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.RecvTensorRequest)
}

void RecvTensorRequest::SharedCtor() {
    _is_default_instance_ = false;
  ::google::protobuf::internal::GetEmptyString();
  _cached_size_ = 0;
  step_id_ = GOOGLE_LONGLONG(0);
  rendezvous_key_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  dma_ok_ = false;
  client_bus_adjacency_ = 0;
  server_bus_adjacency_ = 0;
}

RecvTensorRequest::~RecvTensorRequest() {
  // @@protoc_insertion_point(destructor:tensorflow.RecvTensorRequest)
  SharedDtor();
}

void RecvTensorRequest::SharedDtor() {
  rendezvous_key_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (this != default_instance_) {
  }
}

void RecvTensorRequest::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* RecvTensorRequest::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return RecvTensorRequest_descriptor_;
}

const RecvTensorRequest& RecvTensorRequest::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fworker_2eproto();
  return *default_instance_;
}

RecvTensorRequest* RecvTensorRequest::default_instance_ = NULL;

RecvTensorRequest* RecvTensorRequest::New(::google::protobuf::Arena* arena) const {
  RecvTensorRequest* n = new RecvTensorRequest;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void RecvTensorRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.RecvTensorRequest)
#if defined(__clang__)
#define ZR_HELPER_(f) \
  _Pragma("clang diagnostic push") \
  _Pragma("clang diagnostic ignored \"-Winvalid-offsetof\"") \
  __builtin_offsetof(RecvTensorRequest, f) \
  _Pragma("clang diagnostic pop")
#else
#define ZR_HELPER_(f) reinterpret_cast<char*>(\
  &reinterpret_cast<RecvTensorRequest*>(16)->f)
#endif

#define ZR_(first, last) do {\
  ::memset(&first, 0,\
           ZR_HELPER_(last) - ZR_HELPER_(first) + sizeof(last));\
} while (0)

  ZR_(dma_ok_, server_bus_adjacency_);
  step_id_ = GOOGLE_LONGLONG(0);
  rendezvous_key_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());

#undef ZR_HELPER_
#undef ZR_

}

bool RecvTensorRequest::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.RecvTensorRequest)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional int64 step_id = 1;
      case 1: {
        if (tag == 8) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 input, &step_id_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_rendezvous_key;
        break;
      }

      // optional string rendezvous_key = 2;
      case 2: {
        if (tag == 18) {
         parse_rendezvous_key:
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_rendezvous_key()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->rendezvous_key().data(), this->rendezvous_key().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.RecvTensorRequest.rendezvous_key"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(24)) goto parse_dma_ok;
        break;
      }

      // optional bool dma_ok = 3;
      case 3: {
        if (tag == 24) {
         parse_dma_ok:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &dma_ok_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(32)) goto parse_client_bus_adjacency;
        break;
      }

      // optional .tensorflow.BusAdjacency client_bus_adjacency = 4;
      case 4: {
        if (tag == 32) {
         parse_client_bus_adjacency:
          int value;
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   int, ::google::protobuf::internal::WireFormatLite::TYPE_ENUM>(
                 input, &value)));
          set_client_bus_adjacency(static_cast< ::tensorflow::BusAdjacency >(value));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(40)) goto parse_server_bus_adjacency;
        break;
      }

      // optional .tensorflow.BusAdjacency server_bus_adjacency = 5;
      case 5: {
        if (tag == 40) {
         parse_server_bus_adjacency:
          int value;
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   int, ::google::protobuf::internal::WireFormatLite::TYPE_ENUM>(
                 input, &value)));
          set_server_bus_adjacency(static_cast< ::tensorflow::BusAdjacency >(value));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.RecvTensorRequest)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.RecvTensorRequest)
  return false;
#undef DO_
}

void RecvTensorRequest::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.RecvTensorRequest)
  // optional int64 step_id = 1;
  if (this->step_id() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt64(1, this->step_id(), output);
  }

  // optional string rendezvous_key = 2;
  if (this->rendezvous_key().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->rendezvous_key().data(), this->rendezvous_key().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.RecvTensorRequest.rendezvous_key");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      2, this->rendezvous_key(), output);
  }

  // optional bool dma_ok = 3;
  if (this->dma_ok() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(3, this->dma_ok(), output);
  }

  // optional .tensorflow.BusAdjacency client_bus_adjacency = 4;
  if (this->client_bus_adjacency() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteEnum(
      4, this->client_bus_adjacency(), output);
  }

  // optional .tensorflow.BusAdjacency server_bus_adjacency = 5;
  if (this->server_bus_adjacency() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteEnum(
      5, this->server_bus_adjacency(), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.RecvTensorRequest)
}

::google::protobuf::uint8* RecvTensorRequest::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.RecvTensorRequest)
  // optional int64 step_id = 1;
  if (this->step_id() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt64ToArray(1, this->step_id(), target);
  }

  // optional string rendezvous_key = 2;
  if (this->rendezvous_key().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->rendezvous_key().data(), this->rendezvous_key().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.RecvTensorRequest.rendezvous_key");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        2, this->rendezvous_key(), target);
  }

  // optional bool dma_ok = 3;
  if (this->dma_ok() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(3, this->dma_ok(), target);
  }

  // optional .tensorflow.BusAdjacency client_bus_adjacency = 4;
  if (this->client_bus_adjacency() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteEnumToArray(
      4, this->client_bus_adjacency(), target);
  }

  // optional .tensorflow.BusAdjacency server_bus_adjacency = 5;
  if (this->server_bus_adjacency() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteEnumToArray(
      5, this->server_bus_adjacency(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.RecvTensorRequest)
  return target;
}

int RecvTensorRequest::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.RecvTensorRequest)
  int total_size = 0;

  // optional int64 step_id = 1;
  if (this->step_id() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int64Size(
        this->step_id());
  }

  // optional string rendezvous_key = 2;
  if (this->rendezvous_key().size() > 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->rendezvous_key());
  }

  // optional bool dma_ok = 3;
  if (this->dma_ok() != 0) {
    total_size += 1 + 1;
  }

  // optional .tensorflow.BusAdjacency client_bus_adjacency = 4;
  if (this->client_bus_adjacency() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::EnumSize(this->client_bus_adjacency());
  }

  // optional .tensorflow.BusAdjacency server_bus_adjacency = 5;
  if (this->server_bus_adjacency() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::EnumSize(this->server_bus_adjacency());
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void RecvTensorRequest::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.RecvTensorRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const RecvTensorRequest* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const RecvTensorRequest>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.RecvTensorRequest)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.RecvTensorRequest)
    MergeFrom(*source);
  }
}

void RecvTensorRequest::MergeFrom(const RecvTensorRequest& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.RecvTensorRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  if (from.step_id() != 0) {
    set_step_id(from.step_id());
  }
  if (from.rendezvous_key().size() > 0) {

    rendezvous_key_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.rendezvous_key_);
  }
  if (from.dma_ok() != 0) {
    set_dma_ok(from.dma_ok());
  }
  if (from.client_bus_adjacency() != 0) {
    set_client_bus_adjacency(from.client_bus_adjacency());
  }
  if (from.server_bus_adjacency() != 0) {
    set_server_bus_adjacency(from.server_bus_adjacency());
  }
}

void RecvTensorRequest::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.RecvTensorRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void RecvTensorRequest::CopyFrom(const RecvTensorRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.RecvTensorRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool RecvTensorRequest::IsInitialized() const {

  return true;
}

void RecvTensorRequest::Swap(RecvTensorRequest* other) {
  if (other == this) return;
  InternalSwap(other);
}
void RecvTensorRequest::InternalSwap(RecvTensorRequest* other) {
  std::swap(step_id_, other->step_id_);
  rendezvous_key_.Swap(&other->rendezvous_key_);
  std::swap(dma_ok_, other->dma_ok_);
  std::swap(client_bus_adjacency_, other->client_bus_adjacency_);
  std::swap(server_bus_adjacency_, other->server_bus_adjacency_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata RecvTensorRequest::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = RecvTensorRequest_descriptor_;
  metadata.reflection = RecvTensorRequest_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// RecvTensorRequest

// optional int64 step_id = 1;
void RecvTensorRequest::clear_step_id() {
  step_id_ = GOOGLE_LONGLONG(0);
}
 ::google::protobuf::int64 RecvTensorRequest::step_id() const {
  // @@protoc_insertion_point(field_get:tensorflow.RecvTensorRequest.step_id)
  return step_id_;
}
 void RecvTensorRequest::set_step_id(::google::protobuf::int64 value) {
  
  step_id_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.RecvTensorRequest.step_id)
}

// optional string rendezvous_key = 2;
void RecvTensorRequest::clear_rendezvous_key() {
  rendezvous_key_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 const ::std::string& RecvTensorRequest::rendezvous_key() const {
  // @@protoc_insertion_point(field_get:tensorflow.RecvTensorRequest.rendezvous_key)
  return rendezvous_key_.GetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void RecvTensorRequest::set_rendezvous_key(const ::std::string& value) {
  
  rendezvous_key_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:tensorflow.RecvTensorRequest.rendezvous_key)
}
 void RecvTensorRequest::set_rendezvous_key(const char* value) {
  
  rendezvous_key_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:tensorflow.RecvTensorRequest.rendezvous_key)
}
 void RecvTensorRequest::set_rendezvous_key(const char* value, size_t size) {
  
  rendezvous_key_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:tensorflow.RecvTensorRequest.rendezvous_key)
}
 ::std::string* RecvTensorRequest::mutable_rendezvous_key() {
  
  // @@protoc_insertion_point(field_mutable:tensorflow.RecvTensorRequest.rendezvous_key)
  return rendezvous_key_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 ::std::string* RecvTensorRequest::release_rendezvous_key() {
  // @@protoc_insertion_point(field_release:tensorflow.RecvTensorRequest.rendezvous_key)
  
  return rendezvous_key_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void RecvTensorRequest::set_allocated_rendezvous_key(::std::string* rendezvous_key) {
  if (rendezvous_key != NULL) {
    
  } else {
    
  }
  rendezvous_key_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), rendezvous_key);
  // @@protoc_insertion_point(field_set_allocated:tensorflow.RecvTensorRequest.rendezvous_key)
}

// optional bool dma_ok = 3;
void RecvTensorRequest::clear_dma_ok() {
  dma_ok_ = false;
}
 bool RecvTensorRequest::dma_ok() const {
  // @@protoc_insertion_point(field_get:tensorflow.RecvTensorRequest.dma_ok)
  return dma_ok_;
}
 void RecvTensorRequest::set_dma_ok(bool value) {
  
  dma_ok_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.RecvTensorRequest.dma_ok)
}

// optional .tensorflow.BusAdjacency client_bus_adjacency = 4;
void RecvTensorRequest::clear_client_bus_adjacency() {
  client_bus_adjacency_ = 0;
}
 ::tensorflow::BusAdjacency RecvTensorRequest::client_bus_adjacency() const {
  // @@protoc_insertion_point(field_get:tensorflow.RecvTensorRequest.client_bus_adjacency)
  return static_cast< ::tensorflow::BusAdjacency >(client_bus_adjacency_);
}
 void RecvTensorRequest::set_client_bus_adjacency(::tensorflow::BusAdjacency value) {
  
  client_bus_adjacency_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.RecvTensorRequest.client_bus_adjacency)
}

// optional .tensorflow.BusAdjacency server_bus_adjacency = 5;
void RecvTensorRequest::clear_server_bus_adjacency() {
  server_bus_adjacency_ = 0;
}
 ::tensorflow::BusAdjacency RecvTensorRequest::server_bus_adjacency() const {
  // @@protoc_insertion_point(field_get:tensorflow.RecvTensorRequest.server_bus_adjacency)
  return static_cast< ::tensorflow::BusAdjacency >(server_bus_adjacency_);
}
 void RecvTensorRequest::set_server_bus_adjacency(::tensorflow::BusAdjacency value) {
  
  server_bus_adjacency_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.RecvTensorRequest.server_bus_adjacency)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int RecvTensorResponse::kTensorFieldNumber;
const int RecvTensorResponse::kIsDeadFieldNumber;
const int RecvTensorResponse::kSendStartMicrosFieldNumber;
const int RecvTensorResponse::kTransportOptionsFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

RecvTensorResponse::RecvTensorResponse()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.RecvTensorResponse)
}

void RecvTensorResponse::InitAsDefaultInstance() {
  _is_default_instance_ = true;
  tensor_ = const_cast< ::tensorflow::TensorProto*>(&::tensorflow::TensorProto::default_instance());
  transport_options_ = const_cast< ::google::protobuf::Any*>(&::google::protobuf::Any::default_instance());
}

RecvTensorResponse::RecvTensorResponse(const RecvTensorResponse& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.RecvTensorResponse)
}

void RecvTensorResponse::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  tensor_ = NULL;
  is_dead_ = false;
  send_start_micros_ = GOOGLE_LONGLONG(0);
  transport_options_ = NULL;
}

RecvTensorResponse::~RecvTensorResponse() {
  // @@protoc_insertion_point(destructor:tensorflow.RecvTensorResponse)
  SharedDtor();
}

void RecvTensorResponse::SharedDtor() {
  if (this != default_instance_) {
    delete tensor_;
    delete transport_options_;
  }
}

void RecvTensorResponse::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* RecvTensorResponse::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return RecvTensorResponse_descriptor_;
}

const RecvTensorResponse& RecvTensorResponse::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fworker_2eproto();
  return *default_instance_;
}

RecvTensorResponse* RecvTensorResponse::default_instance_ = NULL;

RecvTensorResponse* RecvTensorResponse::New(::google::protobuf::Arena* arena) const {
  RecvTensorResponse* n = new RecvTensorResponse;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void RecvTensorResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.RecvTensorResponse)
  if (GetArenaNoVirtual() == NULL && tensor_ != NULL) delete tensor_;
  tensor_ = NULL;
  is_dead_ = false;
  send_start_micros_ = GOOGLE_LONGLONG(0);
  if (GetArenaNoVirtual() == NULL && transport_options_ != NULL) delete transport_options_;
  transport_options_ = NULL;
}

bool RecvTensorResponse::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.RecvTensorResponse)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional .tensorflow.TensorProto tensor = 1;
      case 1: {
        if (tag == 10) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_tensor()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(16)) goto parse_is_dead;
        break;
      }

      // optional bool is_dead = 2;
      case 2: {
        if (tag == 16) {
         parse_is_dead:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &is_dead_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(24)) goto parse_send_start_micros;
        break;
      }

      // optional int64 send_start_micros = 3;
      case 3: {
        if (tag == 24) {
         parse_send_start_micros:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 input, &send_start_micros_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(34)) goto parse_transport_options;
        break;
      }

      // optional .google.protobuf.Any transport_options = 4;
      case 4: {
        if (tag == 34) {
         parse_transport_options:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_transport_options()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.RecvTensorResponse)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.RecvTensorResponse)
  return false;
#undef DO_
}

void RecvTensorResponse::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.RecvTensorResponse)
  // optional .tensorflow.TensorProto tensor = 1;
  if (this->has_tensor()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, *this->tensor_, output);
  }

  // optional bool is_dead = 2;
  if (this->is_dead() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(2, this->is_dead(), output);
  }

  // optional int64 send_start_micros = 3;
  if (this->send_start_micros() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt64(3, this->send_start_micros(), output);
  }

  // optional .google.protobuf.Any transport_options = 4;
  if (this->has_transport_options()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      4, *this->transport_options_, output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.RecvTensorResponse)
}

::google::protobuf::uint8* RecvTensorResponse::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.RecvTensorResponse)
  // optional .tensorflow.TensorProto tensor = 1;
  if (this->has_tensor()) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        1, *this->tensor_, target);
  }

  // optional bool is_dead = 2;
  if (this->is_dead() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(2, this->is_dead(), target);
  }

  // optional int64 send_start_micros = 3;
  if (this->send_start_micros() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt64ToArray(3, this->send_start_micros(), target);
  }

  // optional .google.protobuf.Any transport_options = 4;
  if (this->has_transport_options()) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        4, *this->transport_options_, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.RecvTensorResponse)
  return target;
}

int RecvTensorResponse::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.RecvTensorResponse)
  int total_size = 0;

  // optional .tensorflow.TensorProto tensor = 1;
  if (this->has_tensor()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->tensor_);
  }

  // optional bool is_dead = 2;
  if (this->is_dead() != 0) {
    total_size += 1 + 1;
  }

  // optional int64 send_start_micros = 3;
  if (this->send_start_micros() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int64Size(
        this->send_start_micros());
  }

  // optional .google.protobuf.Any transport_options = 4;
  if (this->has_transport_options()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->transport_options_);
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void RecvTensorResponse::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.RecvTensorResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const RecvTensorResponse* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const RecvTensorResponse>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.RecvTensorResponse)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.RecvTensorResponse)
    MergeFrom(*source);
  }
}

void RecvTensorResponse::MergeFrom(const RecvTensorResponse& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.RecvTensorResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  if (from.has_tensor()) {
    mutable_tensor()->::tensorflow::TensorProto::MergeFrom(from.tensor());
  }
  if (from.is_dead() != 0) {
    set_is_dead(from.is_dead());
  }
  if (from.send_start_micros() != 0) {
    set_send_start_micros(from.send_start_micros());
  }
  if (from.has_transport_options()) {
    mutable_transport_options()->::google::protobuf::Any::MergeFrom(from.transport_options());
  }
}

void RecvTensorResponse::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.RecvTensorResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void RecvTensorResponse::CopyFrom(const RecvTensorResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.RecvTensorResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool RecvTensorResponse::IsInitialized() const {

  return true;
}

void RecvTensorResponse::Swap(RecvTensorResponse* other) {
  if (other == this) return;
  InternalSwap(other);
}
void RecvTensorResponse::InternalSwap(RecvTensorResponse* other) {
  std::swap(tensor_, other->tensor_);
  std::swap(is_dead_, other->is_dead_);
  std::swap(send_start_micros_, other->send_start_micros_);
  std::swap(transport_options_, other->transport_options_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata RecvTensorResponse::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = RecvTensorResponse_descriptor_;
  metadata.reflection = RecvTensorResponse_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// RecvTensorResponse

// optional .tensorflow.TensorProto tensor = 1;
bool RecvTensorResponse::has_tensor() const {
  return !_is_default_instance_ && tensor_ != NULL;
}
void RecvTensorResponse::clear_tensor() {
  if (GetArenaNoVirtual() == NULL && tensor_ != NULL) delete tensor_;
  tensor_ = NULL;
}
const ::tensorflow::TensorProto& RecvTensorResponse::tensor() const {
  // @@protoc_insertion_point(field_get:tensorflow.RecvTensorResponse.tensor)
  return tensor_ != NULL ? *tensor_ : *default_instance_->tensor_;
}
::tensorflow::TensorProto* RecvTensorResponse::mutable_tensor() {
  
  if (tensor_ == NULL) {
    tensor_ = new ::tensorflow::TensorProto;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.RecvTensorResponse.tensor)
  return tensor_;
}
::tensorflow::TensorProto* RecvTensorResponse::release_tensor() {
  // @@protoc_insertion_point(field_release:tensorflow.RecvTensorResponse.tensor)
  
  ::tensorflow::TensorProto* temp = tensor_;
  tensor_ = NULL;
  return temp;
}
void RecvTensorResponse::set_allocated_tensor(::tensorflow::TensorProto* tensor) {
  delete tensor_;
  tensor_ = tensor;
  if (tensor) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.RecvTensorResponse.tensor)
}

// optional bool is_dead = 2;
void RecvTensorResponse::clear_is_dead() {
  is_dead_ = false;
}
 bool RecvTensorResponse::is_dead() const {
  // @@protoc_insertion_point(field_get:tensorflow.RecvTensorResponse.is_dead)
  return is_dead_;
}
 void RecvTensorResponse::set_is_dead(bool value) {
  
  is_dead_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.RecvTensorResponse.is_dead)
}

// optional int64 send_start_micros = 3;
void RecvTensorResponse::clear_send_start_micros() {
  send_start_micros_ = GOOGLE_LONGLONG(0);
}
 ::google::protobuf::int64 RecvTensorResponse::send_start_micros() const {
  // @@protoc_insertion_point(field_get:tensorflow.RecvTensorResponse.send_start_micros)
  return send_start_micros_;
}
 void RecvTensorResponse::set_send_start_micros(::google::protobuf::int64 value) {
  
  send_start_micros_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.RecvTensorResponse.send_start_micros)
}

// optional .google.protobuf.Any transport_options = 4;
bool RecvTensorResponse::has_transport_options() const {
  return !_is_default_instance_ && transport_options_ != NULL;
}
void RecvTensorResponse::clear_transport_options() {
  if (GetArenaNoVirtual() == NULL && transport_options_ != NULL) delete transport_options_;
  transport_options_ = NULL;
}
const ::google::protobuf::Any& RecvTensorResponse::transport_options() const {
  // @@protoc_insertion_point(field_get:tensorflow.RecvTensorResponse.transport_options)
  return transport_options_ != NULL ? *transport_options_ : *default_instance_->transport_options_;
}
::google::protobuf::Any* RecvTensorResponse::mutable_transport_options() {
  
  if (transport_options_ == NULL) {
    transport_options_ = new ::google::protobuf::Any;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.RecvTensorResponse.transport_options)
  return transport_options_;
}
::google::protobuf::Any* RecvTensorResponse::release_transport_options() {
  // @@protoc_insertion_point(field_release:tensorflow.RecvTensorResponse.transport_options)
  
  ::google::protobuf::Any* temp = transport_options_;
  transport_options_ = NULL;
  return temp;
}
void RecvTensorResponse::set_allocated_transport_options(::google::protobuf::Any* transport_options) {
  delete transport_options_;
  transport_options_ = transport_options;
  if (transport_options) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.RecvTensorResponse.transport_options)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int LoggingRequest::kRpcLoggingFieldNumber;
const int LoggingRequest::kClearFieldNumber;
const int LoggingRequest::kFetchStepIdFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

LoggingRequest::LoggingRequest()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.LoggingRequest)
}

void LoggingRequest::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

LoggingRequest::LoggingRequest(const LoggingRequest& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.LoggingRequest)
}

void LoggingRequest::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  rpc_logging_ = false;
  clear_ = false;
}

LoggingRequest::~LoggingRequest() {
  // @@protoc_insertion_point(destructor:tensorflow.LoggingRequest)
  SharedDtor();
}

void LoggingRequest::SharedDtor() {
  if (this != default_instance_) {
  }
}

void LoggingRequest::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* LoggingRequest::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return LoggingRequest_descriptor_;
}

const LoggingRequest& LoggingRequest::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fworker_2eproto();
  return *default_instance_;
}

LoggingRequest* LoggingRequest::default_instance_ = NULL;

LoggingRequest* LoggingRequest::New(::google::protobuf::Arena* arena) const {
  LoggingRequest* n = new LoggingRequest;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void LoggingRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.LoggingRequest)
#if defined(__clang__)
#define ZR_HELPER_(f) \
  _Pragma("clang diagnostic push") \
  _Pragma("clang diagnostic ignored \"-Winvalid-offsetof\"") \
  __builtin_offsetof(LoggingRequest, f) \
  _Pragma("clang diagnostic pop")
#else
#define ZR_HELPER_(f) reinterpret_cast<char*>(\
  &reinterpret_cast<LoggingRequest*>(16)->f)
#endif

#define ZR_(first, last) do {\
  ::memset(&first, 0,\
           ZR_HELPER_(last) - ZR_HELPER_(first) + sizeof(last));\
} while (0)

  ZR_(rpc_logging_, clear_);

#undef ZR_HELPER_
#undef ZR_

  fetch_step_id_.Clear();
}

bool LoggingRequest::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.LoggingRequest)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional bool rpc_logging = 1;
      case 1: {
        if (tag == 8) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &rpc_logging_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(16)) goto parse_clear;
        break;
      }

      // optional bool clear = 2;
      case 2: {
        if (tag == 16) {
         parse_clear:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &clear_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(26)) goto parse_fetch_step_id;
        break;
      }

      // repeated int64 fetch_step_id = 3;
      case 3: {
        if (tag == 26) {
         parse_fetch_step_id:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPackedPrimitive<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 input, this->mutable_fetch_step_id())));
        } else if (tag == 24) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadRepeatedPrimitiveNoInline<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 1, 26, input, this->mutable_fetch_step_id())));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.LoggingRequest)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.LoggingRequest)
  return false;
#undef DO_
}

void LoggingRequest::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.LoggingRequest)
  // optional bool rpc_logging = 1;
  if (this->rpc_logging() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(1, this->rpc_logging(), output);
  }

  // optional bool clear = 2;
  if (this->clear() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(2, this->clear(), output);
  }

  // repeated int64 fetch_step_id = 3;
  if (this->fetch_step_id_size() > 0) {
    ::google::protobuf::internal::WireFormatLite::WriteTag(3, ::google::protobuf::internal::WireFormatLite::WIRETYPE_LENGTH_DELIMITED, output);
    output->WriteVarint32(_fetch_step_id_cached_byte_size_);
  }
  for (int i = 0; i < this->fetch_step_id_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::WriteInt64NoTag(
      this->fetch_step_id(i), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.LoggingRequest)
}

::google::protobuf::uint8* LoggingRequest::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.LoggingRequest)
  // optional bool rpc_logging = 1;
  if (this->rpc_logging() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(1, this->rpc_logging(), target);
  }

  // optional bool clear = 2;
  if (this->clear() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(2, this->clear(), target);
  }

  // repeated int64 fetch_step_id = 3;
  if (this->fetch_step_id_size() > 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteTagToArray(
      3,
      ::google::protobuf::internal::WireFormatLite::WIRETYPE_LENGTH_DELIMITED,
      target);
    target = ::google::protobuf::io::CodedOutputStream::WriteVarint32ToArray(
      _fetch_step_id_cached_byte_size_, target);
  }
  for (int i = 0; i < this->fetch_step_id_size(); i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteInt64NoTagToArray(this->fetch_step_id(i), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.LoggingRequest)
  return target;
}

int LoggingRequest::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.LoggingRequest)
  int total_size = 0;

  // optional bool rpc_logging = 1;
  if (this->rpc_logging() != 0) {
    total_size += 1 + 1;
  }

  // optional bool clear = 2;
  if (this->clear() != 0) {
    total_size += 1 + 1;
  }

  // repeated int64 fetch_step_id = 3;
  {
    int data_size = 0;
    for (int i = 0; i < this->fetch_step_id_size(); i++) {
      data_size += ::google::protobuf::internal::WireFormatLite::
        Int64Size(this->fetch_step_id(i));
    }
    if (data_size > 0) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::Int32Size(data_size);
    }
    GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
    _fetch_step_id_cached_byte_size_ = data_size;
    GOOGLE_SAFE_CONCURRENT_WRITES_END();
    total_size += data_size;
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void LoggingRequest::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.LoggingRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const LoggingRequest* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const LoggingRequest>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.LoggingRequest)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.LoggingRequest)
    MergeFrom(*source);
  }
}

void LoggingRequest::MergeFrom(const LoggingRequest& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.LoggingRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  fetch_step_id_.MergeFrom(from.fetch_step_id_);
  if (from.rpc_logging() != 0) {
    set_rpc_logging(from.rpc_logging());
  }
  if (from.clear() != 0) {
    set_clear(from.clear());
  }
}

void LoggingRequest::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.LoggingRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void LoggingRequest::CopyFrom(const LoggingRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.LoggingRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool LoggingRequest::IsInitialized() const {

  return true;
}

void LoggingRequest::Swap(LoggingRequest* other) {
  if (other == this) return;
  InternalSwap(other);
}
void LoggingRequest::InternalSwap(LoggingRequest* other) {
  std::swap(rpc_logging_, other->rpc_logging_);
  std::swap(clear_, other->clear_);
  fetch_step_id_.UnsafeArenaSwap(&other->fetch_step_id_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata LoggingRequest::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = LoggingRequest_descriptor_;
  metadata.reflection = LoggingRequest_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// LoggingRequest

// optional bool rpc_logging = 1;
void LoggingRequest::clear_rpc_logging() {
  rpc_logging_ = false;
}
 bool LoggingRequest::rpc_logging() const {
  // @@protoc_insertion_point(field_get:tensorflow.LoggingRequest.rpc_logging)
  return rpc_logging_;
}
 void LoggingRequest::set_rpc_logging(bool value) {
  
  rpc_logging_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.LoggingRequest.rpc_logging)
}

// optional bool clear = 2;
void LoggingRequest::clear_clear() {
  clear_ = false;
}
 bool LoggingRequest::clear() const {
  // @@protoc_insertion_point(field_get:tensorflow.LoggingRequest.clear)
  return clear_;
}
 void LoggingRequest::set_clear(bool value) {
  
  clear_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.LoggingRequest.clear)
}

// repeated int64 fetch_step_id = 3;
int LoggingRequest::fetch_step_id_size() const {
  return fetch_step_id_.size();
}
void LoggingRequest::clear_fetch_step_id() {
  fetch_step_id_.Clear();
}
 ::google::protobuf::int64 LoggingRequest::fetch_step_id(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.LoggingRequest.fetch_step_id)
  return fetch_step_id_.Get(index);
}
 void LoggingRequest::set_fetch_step_id(int index, ::google::protobuf::int64 value) {
  fetch_step_id_.Set(index, value);
  // @@protoc_insertion_point(field_set:tensorflow.LoggingRequest.fetch_step_id)
}
 void LoggingRequest::add_fetch_step_id(::google::protobuf::int64 value) {
  fetch_step_id_.Add(value);
  // @@protoc_insertion_point(field_add:tensorflow.LoggingRequest.fetch_step_id)
}
 const ::google::protobuf::RepeatedField< ::google::protobuf::int64 >&
LoggingRequest::fetch_step_id() const {
  // @@protoc_insertion_point(field_list:tensorflow.LoggingRequest.fetch_step_id)
  return fetch_step_id_;
}
 ::google::protobuf::RepeatedField< ::google::protobuf::int64 >*
LoggingRequest::mutable_fetch_step_id() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.LoggingRequest.fetch_step_id)
  return &fetch_step_id_;
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int LabeledStepStats::kStepIdFieldNumber;
const int LabeledStepStats::kStepStatsFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

LabeledStepStats::LabeledStepStats()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.LabeledStepStats)
}

void LabeledStepStats::InitAsDefaultInstance() {
  _is_default_instance_ = true;
  step_stats_ = const_cast< ::tensorflow::StepStats*>(&::tensorflow::StepStats::default_instance());
}

LabeledStepStats::LabeledStepStats(const LabeledStepStats& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.LabeledStepStats)
}

void LabeledStepStats::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  step_id_ = GOOGLE_LONGLONG(0);
  step_stats_ = NULL;
}

LabeledStepStats::~LabeledStepStats() {
  // @@protoc_insertion_point(destructor:tensorflow.LabeledStepStats)
  SharedDtor();
}

void LabeledStepStats::SharedDtor() {
  if (this != default_instance_) {
    delete step_stats_;
  }
}

void LabeledStepStats::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* LabeledStepStats::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return LabeledStepStats_descriptor_;
}

const LabeledStepStats& LabeledStepStats::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fworker_2eproto();
  return *default_instance_;
}

LabeledStepStats* LabeledStepStats::default_instance_ = NULL;

LabeledStepStats* LabeledStepStats::New(::google::protobuf::Arena* arena) const {
  LabeledStepStats* n = new LabeledStepStats;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void LabeledStepStats::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.LabeledStepStats)
  step_id_ = GOOGLE_LONGLONG(0);
  if (GetArenaNoVirtual() == NULL && step_stats_ != NULL) delete step_stats_;
  step_stats_ = NULL;
}

bool LabeledStepStats::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.LabeledStepStats)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional int64 step_id = 1;
      case 1: {
        if (tag == 8) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 input, &step_id_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_step_stats;
        break;
      }

      // optional .tensorflow.StepStats step_stats = 2;
      case 2: {
        if (tag == 18) {
         parse_step_stats:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_step_stats()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.LabeledStepStats)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.LabeledStepStats)
  return false;
#undef DO_
}

void LabeledStepStats::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.LabeledStepStats)
  // optional int64 step_id = 1;
  if (this->step_id() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt64(1, this->step_id(), output);
  }

  // optional .tensorflow.StepStats step_stats = 2;
  if (this->has_step_stats()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, *this->step_stats_, output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.LabeledStepStats)
}

::google::protobuf::uint8* LabeledStepStats::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.LabeledStepStats)
  // optional int64 step_id = 1;
  if (this->step_id() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt64ToArray(1, this->step_id(), target);
  }

  // optional .tensorflow.StepStats step_stats = 2;
  if (this->has_step_stats()) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        2, *this->step_stats_, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.LabeledStepStats)
  return target;
}

int LabeledStepStats::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.LabeledStepStats)
  int total_size = 0;

  // optional int64 step_id = 1;
  if (this->step_id() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int64Size(
        this->step_id());
  }

  // optional .tensorflow.StepStats step_stats = 2;
  if (this->has_step_stats()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->step_stats_);
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void LabeledStepStats::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.LabeledStepStats)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const LabeledStepStats* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const LabeledStepStats>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.LabeledStepStats)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.LabeledStepStats)
    MergeFrom(*source);
  }
}

void LabeledStepStats::MergeFrom(const LabeledStepStats& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.LabeledStepStats)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  if (from.step_id() != 0) {
    set_step_id(from.step_id());
  }
  if (from.has_step_stats()) {
    mutable_step_stats()->::tensorflow::StepStats::MergeFrom(from.step_stats());
  }
}

void LabeledStepStats::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.LabeledStepStats)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void LabeledStepStats::CopyFrom(const LabeledStepStats& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.LabeledStepStats)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool LabeledStepStats::IsInitialized() const {

  return true;
}

void LabeledStepStats::Swap(LabeledStepStats* other) {
  if (other == this) return;
  InternalSwap(other);
}
void LabeledStepStats::InternalSwap(LabeledStepStats* other) {
  std::swap(step_id_, other->step_id_);
  std::swap(step_stats_, other->step_stats_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata LabeledStepStats::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = LabeledStepStats_descriptor_;
  metadata.reflection = LabeledStepStats_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// LabeledStepStats

// optional int64 step_id = 1;
void LabeledStepStats::clear_step_id() {
  step_id_ = GOOGLE_LONGLONG(0);
}
 ::google::protobuf::int64 LabeledStepStats::step_id() const {
  // @@protoc_insertion_point(field_get:tensorflow.LabeledStepStats.step_id)
  return step_id_;
}
 void LabeledStepStats::set_step_id(::google::protobuf::int64 value) {
  
  step_id_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.LabeledStepStats.step_id)
}

// optional .tensorflow.StepStats step_stats = 2;
bool LabeledStepStats::has_step_stats() const {
  return !_is_default_instance_ && step_stats_ != NULL;
}
void LabeledStepStats::clear_step_stats() {
  if (GetArenaNoVirtual() == NULL && step_stats_ != NULL) delete step_stats_;
  step_stats_ = NULL;
}
const ::tensorflow::StepStats& LabeledStepStats::step_stats() const {
  // @@protoc_insertion_point(field_get:tensorflow.LabeledStepStats.step_stats)
  return step_stats_ != NULL ? *step_stats_ : *default_instance_->step_stats_;
}
::tensorflow::StepStats* LabeledStepStats::mutable_step_stats() {
  
  if (step_stats_ == NULL) {
    step_stats_ = new ::tensorflow::StepStats;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.LabeledStepStats.step_stats)
  return step_stats_;
}
::tensorflow::StepStats* LabeledStepStats::release_step_stats() {
  // @@protoc_insertion_point(field_release:tensorflow.LabeledStepStats.step_stats)
  
  ::tensorflow::StepStats* temp = step_stats_;
  step_stats_ = NULL;
  return temp;
}
void LabeledStepStats::set_allocated_step_stats(::tensorflow::StepStats* step_stats) {
  delete step_stats_;
  step_stats_ = step_stats;
  if (step_stats) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.LabeledStepStats.step_stats)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int LoggingResponse::kStepFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

LoggingResponse::LoggingResponse()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.LoggingResponse)
}

void LoggingResponse::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

LoggingResponse::LoggingResponse(const LoggingResponse& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.LoggingResponse)
}

void LoggingResponse::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
}

LoggingResponse::~LoggingResponse() {
  // @@protoc_insertion_point(destructor:tensorflow.LoggingResponse)
  SharedDtor();
}

void LoggingResponse::SharedDtor() {
  if (this != default_instance_) {
  }
}

void LoggingResponse::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* LoggingResponse::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return LoggingResponse_descriptor_;
}

const LoggingResponse& LoggingResponse::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fworker_2eproto();
  return *default_instance_;
}

LoggingResponse* LoggingResponse::default_instance_ = NULL;

LoggingResponse* LoggingResponse::New(::google::protobuf::Arena* arena) const {
  LoggingResponse* n = new LoggingResponse;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void LoggingResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.LoggingResponse)
  step_.Clear();
}

bool LoggingResponse::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.LoggingResponse)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // repeated .tensorflow.LabeledStepStats step = 1;
      case 1: {
        if (tag == 10) {
          DO_(input->IncrementRecursionDepth());
         parse_loop_step:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_step()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(10)) goto parse_loop_step;
        input->UnsafeDecrementRecursionDepth();
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.LoggingResponse)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.LoggingResponse)
  return false;
#undef DO_
}

void LoggingResponse::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.LoggingResponse)
  // repeated .tensorflow.LabeledStepStats step = 1;
  for (unsigned int i = 0, n = this->step_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, this->step(i), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.LoggingResponse)
}

::google::protobuf::uint8* LoggingResponse::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.LoggingResponse)
  // repeated .tensorflow.LabeledStepStats step = 1;
  for (unsigned int i = 0, n = this->step_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        1, this->step(i), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.LoggingResponse)
  return target;
}

int LoggingResponse::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.LoggingResponse)
  int total_size = 0;

  // repeated .tensorflow.LabeledStepStats step = 1;
  total_size += 1 * this->step_size();
  for (int i = 0; i < this->step_size(); i++) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        this->step(i));
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void LoggingResponse::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.LoggingResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const LoggingResponse* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const LoggingResponse>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.LoggingResponse)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.LoggingResponse)
    MergeFrom(*source);
  }
}

void LoggingResponse::MergeFrom(const LoggingResponse& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.LoggingResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  step_.MergeFrom(from.step_);
}

void LoggingResponse::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.LoggingResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void LoggingResponse::CopyFrom(const LoggingResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.LoggingResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool LoggingResponse::IsInitialized() const {

  return true;
}

void LoggingResponse::Swap(LoggingResponse* other) {
  if (other == this) return;
  InternalSwap(other);
}
void LoggingResponse::InternalSwap(LoggingResponse* other) {
  step_.UnsafeArenaSwap(&other->step_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata LoggingResponse::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = LoggingResponse_descriptor_;
  metadata.reflection = LoggingResponse_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// LoggingResponse

// repeated .tensorflow.LabeledStepStats step = 1;
int LoggingResponse::step_size() const {
  return step_.size();
}
void LoggingResponse::clear_step() {
  step_.Clear();
}
const ::tensorflow::LabeledStepStats& LoggingResponse::step(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.LoggingResponse.step)
  return step_.Get(index);
}
::tensorflow::LabeledStepStats* LoggingResponse::mutable_step(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.LoggingResponse.step)
  return step_.Mutable(index);
}
::tensorflow::LabeledStepStats* LoggingResponse::add_step() {
  // @@protoc_insertion_point(field_add:tensorflow.LoggingResponse.step)
  return step_.Add();
}
::google::protobuf::RepeatedPtrField< ::tensorflow::LabeledStepStats >*
LoggingResponse::mutable_step() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.LoggingResponse.step)
  return &step_;
}
const ::google::protobuf::RepeatedPtrField< ::tensorflow::LabeledStepStats >&
LoggingResponse::step() const {
  // @@protoc_insertion_point(field_list:tensorflow.LoggingResponse.step)
  return step_;
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int TraceOpts::kDurationFieldNumber;
const int TraceOpts::kUseStepProfilerFieldNumber;
const int TraceOpts::kUseKernelProfilerFieldNumber;
const int TraceOpts::kUseExtendedProfilerFieldNumber;
const int TraceOpts::kUseGpuProfilerFieldNumber;
const int TraceOpts::kUseSampleProfilerFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

TraceOpts::TraceOpts()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.TraceOpts)
}

void TraceOpts::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

TraceOpts::TraceOpts(const TraceOpts& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.TraceOpts)
}

void TraceOpts::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  duration_ = 0;
  use_step_profiler_ = false;
  use_kernel_profiler_ = false;
  use_extended_profiler_ = false;
  use_gpu_profiler_ = false;
  use_sample_profiler_ = false;
}

TraceOpts::~TraceOpts() {
  // @@protoc_insertion_point(destructor:tensorflow.TraceOpts)
  SharedDtor();
}

void TraceOpts::SharedDtor() {
  if (this != default_instance_) {
  }
}

void TraceOpts::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* TraceOpts::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return TraceOpts_descriptor_;
}

const TraceOpts& TraceOpts::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fworker_2eproto();
  return *default_instance_;
}

TraceOpts* TraceOpts::default_instance_ = NULL;

TraceOpts* TraceOpts::New(::google::protobuf::Arena* arena) const {
  TraceOpts* n = new TraceOpts;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void TraceOpts::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.TraceOpts)
#if defined(__clang__)
#define ZR_HELPER_(f) \
  _Pragma("clang diagnostic push") \
  _Pragma("clang diagnostic ignored \"-Winvalid-offsetof\"") \
  __builtin_offsetof(TraceOpts, f) \
  _Pragma("clang diagnostic pop")
#else
#define ZR_HELPER_(f) reinterpret_cast<char*>(\
  &reinterpret_cast<TraceOpts*>(16)->f)
#endif

#define ZR_(first, last) do {\
  ::memset(&first, 0,\
           ZR_HELPER_(last) - ZR_HELPER_(first) + sizeof(last));\
} while (0)

  ZR_(duration_, use_sample_profiler_);

#undef ZR_HELPER_
#undef ZR_

}

bool TraceOpts::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.TraceOpts)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional double duration = 1;
      case 1: {
        if (tag == 9) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   double, ::google::protobuf::internal::WireFormatLite::TYPE_DOUBLE>(
                 input, &duration_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(16)) goto parse_use_step_profiler;
        break;
      }

      // optional bool use_step_profiler = 2;
      case 2: {
        if (tag == 16) {
         parse_use_step_profiler:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &use_step_profiler_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(24)) goto parse_use_kernel_profiler;
        break;
      }

      // optional bool use_kernel_profiler = 3;
      case 3: {
        if (tag == 24) {
         parse_use_kernel_profiler:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &use_kernel_profiler_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(32)) goto parse_use_extended_profiler;
        break;
      }

      // optional bool use_extended_profiler = 4;
      case 4: {
        if (tag == 32) {
         parse_use_extended_profiler:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &use_extended_profiler_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(40)) goto parse_use_gpu_profiler;
        break;
      }

      // optional bool use_gpu_profiler = 5;
      case 5: {
        if (tag == 40) {
         parse_use_gpu_profiler:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &use_gpu_profiler_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(48)) goto parse_use_sample_profiler;
        break;
      }

      // optional bool use_sample_profiler = 6;
      case 6: {
        if (tag == 48) {
         parse_use_sample_profiler:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &use_sample_profiler_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.TraceOpts)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.TraceOpts)
  return false;
#undef DO_
}

void TraceOpts::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.TraceOpts)
  // optional double duration = 1;
  if (this->duration() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteDouble(1, this->duration(), output);
  }

  // optional bool use_step_profiler = 2;
  if (this->use_step_profiler() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(2, this->use_step_profiler(), output);
  }

  // optional bool use_kernel_profiler = 3;
  if (this->use_kernel_profiler() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(3, this->use_kernel_profiler(), output);
  }

  // optional bool use_extended_profiler = 4;
  if (this->use_extended_profiler() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(4, this->use_extended_profiler(), output);
  }

  // optional bool use_gpu_profiler = 5;
  if (this->use_gpu_profiler() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(5, this->use_gpu_profiler(), output);
  }

  // optional bool use_sample_profiler = 6;
  if (this->use_sample_profiler() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(6, this->use_sample_profiler(), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.TraceOpts)
}

::google::protobuf::uint8* TraceOpts::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.TraceOpts)
  // optional double duration = 1;
  if (this->duration() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteDoubleToArray(1, this->duration(), target);
  }

  // optional bool use_step_profiler = 2;
  if (this->use_step_profiler() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(2, this->use_step_profiler(), target);
  }

  // optional bool use_kernel_profiler = 3;
  if (this->use_kernel_profiler() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(3, this->use_kernel_profiler(), target);
  }

  // optional bool use_extended_profiler = 4;
  if (this->use_extended_profiler() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(4, this->use_extended_profiler(), target);
  }

  // optional bool use_gpu_profiler = 5;
  if (this->use_gpu_profiler() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(5, this->use_gpu_profiler(), target);
  }

  // optional bool use_sample_profiler = 6;
  if (this->use_sample_profiler() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(6, this->use_sample_profiler(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.TraceOpts)
  return target;
}

int TraceOpts::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.TraceOpts)
  int total_size = 0;

  // optional double duration = 1;
  if (this->duration() != 0) {
    total_size += 1 + 8;
  }

  // optional bool use_step_profiler = 2;
  if (this->use_step_profiler() != 0) {
    total_size += 1 + 1;
  }

  // optional bool use_kernel_profiler = 3;
  if (this->use_kernel_profiler() != 0) {
    total_size += 1 + 1;
  }

  // optional bool use_extended_profiler = 4;
  if (this->use_extended_profiler() != 0) {
    total_size += 1 + 1;
  }

  // optional bool use_gpu_profiler = 5;
  if (this->use_gpu_profiler() != 0) {
    total_size += 1 + 1;
  }

  // optional bool use_sample_profiler = 6;
  if (this->use_sample_profiler() != 0) {
    total_size += 1 + 1;
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void TraceOpts::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.TraceOpts)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const TraceOpts* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const TraceOpts>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.TraceOpts)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.TraceOpts)
    MergeFrom(*source);
  }
}

void TraceOpts::MergeFrom(const TraceOpts& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.TraceOpts)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  if (from.duration() != 0) {
    set_duration(from.duration());
  }
  if (from.use_step_profiler() != 0) {
    set_use_step_profiler(from.use_step_profiler());
  }
  if (from.use_kernel_profiler() != 0) {
    set_use_kernel_profiler(from.use_kernel_profiler());
  }
  if (from.use_extended_profiler() != 0) {
    set_use_extended_profiler(from.use_extended_profiler());
  }
  if (from.use_gpu_profiler() != 0) {
    set_use_gpu_profiler(from.use_gpu_profiler());
  }
  if (from.use_sample_profiler() != 0) {
    set_use_sample_profiler(from.use_sample_profiler());
  }
}

void TraceOpts::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.TraceOpts)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void TraceOpts::CopyFrom(const TraceOpts& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.TraceOpts)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool TraceOpts::IsInitialized() const {

  return true;
}

void TraceOpts::Swap(TraceOpts* other) {
  if (other == this) return;
  InternalSwap(other);
}
void TraceOpts::InternalSwap(TraceOpts* other) {
  std::swap(duration_, other->duration_);
  std::swap(use_step_profiler_, other->use_step_profiler_);
  std::swap(use_kernel_profiler_, other->use_kernel_profiler_);
  std::swap(use_extended_profiler_, other->use_extended_profiler_);
  std::swap(use_gpu_profiler_, other->use_gpu_profiler_);
  std::swap(use_sample_profiler_, other->use_sample_profiler_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata TraceOpts::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = TraceOpts_descriptor_;
  metadata.reflection = TraceOpts_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// TraceOpts

// optional double duration = 1;
void TraceOpts::clear_duration() {
  duration_ = 0;
}
 double TraceOpts::duration() const {
  // @@protoc_insertion_point(field_get:tensorflow.TraceOpts.duration)
  return duration_;
}
 void TraceOpts::set_duration(double value) {
  
  duration_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.TraceOpts.duration)
}

// optional bool use_step_profiler = 2;
void TraceOpts::clear_use_step_profiler() {
  use_step_profiler_ = false;
}
 bool TraceOpts::use_step_profiler() const {
  // @@protoc_insertion_point(field_get:tensorflow.TraceOpts.use_step_profiler)
  return use_step_profiler_;
}
 void TraceOpts::set_use_step_profiler(bool value) {
  
  use_step_profiler_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.TraceOpts.use_step_profiler)
}

// optional bool use_kernel_profiler = 3;
void TraceOpts::clear_use_kernel_profiler() {
  use_kernel_profiler_ = false;
}
 bool TraceOpts::use_kernel_profiler() const {
  // @@protoc_insertion_point(field_get:tensorflow.TraceOpts.use_kernel_profiler)
  return use_kernel_profiler_;
}
 void TraceOpts::set_use_kernel_profiler(bool value) {
  
  use_kernel_profiler_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.TraceOpts.use_kernel_profiler)
}

// optional bool use_extended_profiler = 4;
void TraceOpts::clear_use_extended_profiler() {
  use_extended_profiler_ = false;
}
 bool TraceOpts::use_extended_profiler() const {
  // @@protoc_insertion_point(field_get:tensorflow.TraceOpts.use_extended_profiler)
  return use_extended_profiler_;
}
 void TraceOpts::set_use_extended_profiler(bool value) {
  
  use_extended_profiler_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.TraceOpts.use_extended_profiler)
}

// optional bool use_gpu_profiler = 5;
void TraceOpts::clear_use_gpu_profiler() {
  use_gpu_profiler_ = false;
}
 bool TraceOpts::use_gpu_profiler() const {
  // @@protoc_insertion_point(field_get:tensorflow.TraceOpts.use_gpu_profiler)
  return use_gpu_profiler_;
}
 void TraceOpts::set_use_gpu_profiler(bool value) {
  
  use_gpu_profiler_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.TraceOpts.use_gpu_profiler)
}

// optional bool use_sample_profiler = 6;
void TraceOpts::clear_use_sample_profiler() {
  use_sample_profiler_ = false;
}
 bool TraceOpts::use_sample_profiler() const {
  // @@protoc_insertion_point(field_get:tensorflow.TraceOpts.use_sample_profiler)
  return use_sample_profiler_;
}
 void TraceOpts::set_use_sample_profiler(bool value) {
  
  use_sample_profiler_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.TraceOpts.use_sample_profiler)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int TracingRequest::kOptionsFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

TracingRequest::TracingRequest()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.TracingRequest)
}

void TracingRequest::InitAsDefaultInstance() {
  _is_default_instance_ = true;
  options_ = const_cast< ::tensorflow::TraceOpts*>(&::tensorflow::TraceOpts::default_instance());
}

TracingRequest::TracingRequest(const TracingRequest& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.TracingRequest)
}

void TracingRequest::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  options_ = NULL;
}

TracingRequest::~TracingRequest() {
  // @@protoc_insertion_point(destructor:tensorflow.TracingRequest)
  SharedDtor();
}

void TracingRequest::SharedDtor() {
  if (this != default_instance_) {
    delete options_;
  }
}

void TracingRequest::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* TracingRequest::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return TracingRequest_descriptor_;
}

const TracingRequest& TracingRequest::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fworker_2eproto();
  return *default_instance_;
}

TracingRequest* TracingRequest::default_instance_ = NULL;

TracingRequest* TracingRequest::New(::google::protobuf::Arena* arena) const {
  TracingRequest* n = new TracingRequest;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void TracingRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.TracingRequest)
  if (GetArenaNoVirtual() == NULL && options_ != NULL) delete options_;
  options_ = NULL;
}

bool TracingRequest::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.TracingRequest)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional .tensorflow.TraceOpts options = 1;
      case 1: {
        if (tag == 10) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_options()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.TracingRequest)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.TracingRequest)
  return false;
#undef DO_
}

void TracingRequest::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.TracingRequest)
  // optional .tensorflow.TraceOpts options = 1;
  if (this->has_options()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, *this->options_, output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.TracingRequest)
}

::google::protobuf::uint8* TracingRequest::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.TracingRequest)
  // optional .tensorflow.TraceOpts options = 1;
  if (this->has_options()) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        1, *this->options_, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.TracingRequest)
  return target;
}

int TracingRequest::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.TracingRequest)
  int total_size = 0;

  // optional .tensorflow.TraceOpts options = 1;
  if (this->has_options()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->options_);
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void TracingRequest::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.TracingRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const TracingRequest* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const TracingRequest>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.TracingRequest)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.TracingRequest)
    MergeFrom(*source);
  }
}

void TracingRequest::MergeFrom(const TracingRequest& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.TracingRequest)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  if (from.has_options()) {
    mutable_options()->::tensorflow::TraceOpts::MergeFrom(from.options());
  }
}

void TracingRequest::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.TracingRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void TracingRequest::CopyFrom(const TracingRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.TracingRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool TracingRequest::IsInitialized() const {

  return true;
}

void TracingRequest::Swap(TracingRequest* other) {
  if (other == this) return;
  InternalSwap(other);
}
void TracingRequest::InternalSwap(TracingRequest* other) {
  std::swap(options_, other->options_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata TracingRequest::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = TracingRequest_descriptor_;
  metadata.reflection = TracingRequest_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// TracingRequest

// optional .tensorflow.TraceOpts options = 1;
bool TracingRequest::has_options() const {
  return !_is_default_instance_ && options_ != NULL;
}
void TracingRequest::clear_options() {
  if (GetArenaNoVirtual() == NULL && options_ != NULL) delete options_;
  options_ = NULL;
}
const ::tensorflow::TraceOpts& TracingRequest::options() const {
  // @@protoc_insertion_point(field_get:tensorflow.TracingRequest.options)
  return options_ != NULL ? *options_ : *default_instance_->options_;
}
::tensorflow::TraceOpts* TracingRequest::mutable_options() {
  
  if (options_ == NULL) {
    options_ = new ::tensorflow::TraceOpts;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.TracingRequest.options)
  return options_;
}
::tensorflow::TraceOpts* TracingRequest::release_options() {
  // @@protoc_insertion_point(field_release:tensorflow.TracingRequest.options)
  
  ::tensorflow::TraceOpts* temp = options_;
  options_ = NULL;
  return temp;
}
void TracingRequest::set_allocated_options(::tensorflow::TraceOpts* options) {
  delete options_;
  options_ = options;
  if (options) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.TracingRequest.options)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

TracingResponse::TracingResponse()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.TracingResponse)
}

void TracingResponse::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

TracingResponse::TracingResponse(const TracingResponse& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.TracingResponse)
}

void TracingResponse::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
}

TracingResponse::~TracingResponse() {
  // @@protoc_insertion_point(destructor:tensorflow.TracingResponse)
  SharedDtor();
}

void TracingResponse::SharedDtor() {
  if (this != default_instance_) {
  }
}

void TracingResponse::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* TracingResponse::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return TracingResponse_descriptor_;
}

const TracingResponse& TracingResponse::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fworker_2eproto();
  return *default_instance_;
}

TracingResponse* TracingResponse::default_instance_ = NULL;

TracingResponse* TracingResponse::New(::google::protobuf::Arena* arena) const {
  TracingResponse* n = new TracingResponse;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void TracingResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.TracingResponse)
}

bool TracingResponse::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.TracingResponse)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
  handle_unusual:
    if (tag == 0 ||
        ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
        ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
      goto success;
    }
    DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.TracingResponse)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.TracingResponse)
  return false;
#undef DO_
}

void TracingResponse::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.TracingResponse)
  // @@protoc_insertion_point(serialize_end:tensorflow.TracingResponse)
}

::google::protobuf::uint8* TracingResponse::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.TracingResponse)
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.TracingResponse)
  return target;
}

int TracingResponse::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.TracingResponse)
  int total_size = 0;

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void TracingResponse::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.TracingResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const TracingResponse* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const TracingResponse>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.TracingResponse)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.TracingResponse)
    MergeFrom(*source);
  }
}

void TracingResponse::MergeFrom(const TracingResponse& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.TracingResponse)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
}

void TracingResponse::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.TracingResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void TracingResponse::CopyFrom(const TracingResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.TracingResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool TracingResponse::IsInitialized() const {

  return true;
}

void TracingResponse::Swap(TracingResponse* other) {
  if (other == this) return;
  InternalSwap(other);
}
void TracingResponse::InternalSwap(TracingResponse* other) {
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata TracingResponse::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = TracingResponse_descriptor_;
  metadata.reflection = TracingResponse_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// TracingResponse

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// @@protoc_insertion_point(namespace_scope)

}  // namespace tensorflow

// @@protoc_insertion_point(global_scope)
